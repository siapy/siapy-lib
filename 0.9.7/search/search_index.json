{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to SiaPy","text":"<p> Spectral imaging analysis for Python (SiaPy) is a tool for efficient processing of spectral images </p> <p> </p> <p>Source Code: https://github.com/siapy/siapy-lib</p> <p>Bug Report / Feature Request: https://github.com/siapy/siapy-lib/issues/new/choose</p> <p>Documentation: https://siapy.github.io/siapy-lib/</p>"},{"location":"#overview","title":"\ud83d\udcda Overview","text":"<p>SiaPy is a versatile Python library designed for processing and analyzing spectral images. It is particularly useful for scientific and academic purposes, but it also serves well for quick prototyping.</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Image Processing: Easily read, display, and manipulate spectral image data.</li> <li>Data Analysis: Perform in-depth analysis of spectral signatures using advanced analytical techniques.</li> <li>Machine Learning Integration: Select image regions for training models and segment images using pre-trained models.</li> <li>Camera Co-registration: Align multiple cameras and compute transformations across different camera spaces.</li> <li>Radiometric Conversion: Convert radiance to reflectance using reference panels.</li> </ul> <p>To make some of the functionality more easily accessible, a command line interface (CLI) is also provided. See siapy-cli. However, the full functionality can be exploited by using the library directly.</p>"},{"location":"#installation","title":"\ud83d\udca1 Installation","text":"<p>To install the siapy library, use the following command:</p> <pre><code>pip install siapy\n</code></pre> <p>For detailed information and additional options, please refer to the instructions.</p>"},{"location":"#examples","title":"\ud83d\udcbb Examples","text":"<pre><code>from pathlib import Path\nfrom siapy.entities import SpectralImageSet\n\ndata_dir = \"~/data\"\n\nheader_paths = sorted(Path(data_dir).rglob(\"*.hdr\"))\nimage_paths = sorted(Path(data_dir).rglob(\"*.img\"))\n\nimageset = SpectralImageSet.spy_open(\n    header_paths=header_paths,\n    image_paths=image_paths,\n)\nprint(imageset)\n</code></pre> <p>For an overview of the key concepts and functionalities of the SiaPy library, please refer to the documentation. Additionally, explore the use cases that demonstrate the library's capabilities here.</p>"},{"location":"#contribution-guidelines","title":"\ud83d\udd0d Contribution guidelines","text":"<p>We always welcome small improvements or fixes. If you\u2019re considering making more significant contributions to the source code, please contact us via email.</p> <p>Contributing to SiaPy isn\u2019t limited to coding. You can also:</p> <ul> <li>Help us manage and resolve issues, both new and existing.</li> <li>Create tutorials, presentations, and other educational resources.</li> <li>Propose new features.</li> </ul> <p>Not sure where to start or how your skills might fit in? Don\u2019t hesitate to reach out! You can contact us via email, or connect with us directly on GitHub by opening a new issue or commenting on an existing one.</p> <p>If you\u2019re new to open-source contributions, check out our guide for helpful tips on getting started.</p>"},{"location":"#issues-and-new-features","title":"\ud83d\udd50 Issues and new features","text":"<p>Encountered a problem with the library? Please report it by creating an issue on GitHub.</p> <p>Interested in fixing an issue or enhancing the library\u2019s functionality? Fork the repository, make your changes, and submit a pull request on GitHub.</p> <p>Have a question? First, ensure that the setup process was completed successfully and resolve any related issues. If you\u2019ve pulled in newer code, you might need to delete and recreate your SiaPy environment to ensure all the necessary packages are correctly installed.</p>"},{"location":"#license","title":"\ud83e\udd1d License","text":"<p>This project is licensed under the MIT License. See LICENSE for more details.</p>"},{"location":"changelog/","title":"Release Notes","text":""},{"location":"changelog/#097-2025-06-19","title":"0.9.7 (2025-06-19)","text":""},{"location":"changelog/#documentation","title":"Documentation","text":"<ul> <li>add image utilities and update mkdocs navigation for better documentation structure (29b2ae1)</li> <li>add plotting utilities for interactive pixel and area selection, and update documentation (e28c830)</li> <li>add transformation examples and update documentation for image processing (97a0144)</li> <li>enhance docstrings across image classes for improved clarity and usability (e5c1a56)</li> <li>enhance docstrings for target generation functions and tabular dataset class for improved clarity and usability (c6cc3e6)</li> <li>remove obsolete configs documentation and enhance module docstrings for clarity (9858402)</li> </ul>"},{"location":"changelog/#096-2025-06-18","title":"0.9.6 (2025-06-18)","text":""},{"location":"changelog/#documentation_1","title":"Documentation","text":"<ul> <li>add cross-validation and hold-out scorer examples to optimizers documentation (606dc29)</li> <li>add features module with automated feature engineering and spectral indices computation (950bdaf)</li> <li>add optimizers documentation and example for hyperparameter optimization (4471b1a)</li> <li>improve comments for clarity in features_06.py (c6bb864)</li> <li>remove unused logger import from spectral_image_04.py (8c8b6f9)</li> <li>update features documentation and add example for automated spectral indices classification (6dda2ee)</li> <li>update optimizers documentation and add example for trial parameters setup (20b73c8)</li> <li>update optimizers documentation to include scorers and evaluation functions (231b8bd)</li> </ul>"},{"location":"changelog/#095-2025-05-07","title":"0.9.5 (2025-05-07)","text":""},{"location":"changelog/#documentation_2","title":"Documentation","text":"<ul> <li>add datasets module documentation and example usage (ec2d469)</li> <li>enhance SpectralImage documentation with GeometricShapes usage examples (f7c82cc)</li> </ul>"},{"location":"changelog/#094-2025-05-06","title":"0.9.4 (2025-05-06)","text":""},{"location":"changelog/#bug-fixes","title":"Bug Fixes","text":"<ul> <li>update codespell skip patterns to include SVG files (c1f3cac)</li> </ul>"},{"location":"changelog/#documentation_3","title":"Documentation","text":"<ul> <li>add data conversion methods for SpectralImage in documentation (92c09c0)</li> <li>add entities schematics and relationships image (be4527d)</li> <li>enhance contributing guidelines and API design principles overview (407a786)</li> </ul>"},{"location":"changelog/#093-2025-04-29","title":"0.9.3 (2025-04-29)","text":""},{"location":"changelog/#bug-fixes_1","title":"Bug Fixes","text":"<ul> <li>implement equality comparison method and add corresponding tests (9c19f07)</li> </ul>"},{"location":"changelog/#documentation_4","title":"Documentation","text":"<ul> <li>add API documentation links for Pixels, Signals, Signatures, Shape, SpectralImage, and SpectralImageSet classes (45fce51)</li> <li>add API documentation notes for core components in overview.md (e2ae548)</li> <li>enhance case study documentation with additional notes and formatting improvements (602494b)</li> <li>enhance documentation for Signals and Signatures classes with initialization examples (703adbf)</li> <li>reorganize and enhance SpectralImage section with initialization options (8929a4c)</li> <li>Replace PNG diagram with SVG format for entities schematics and remove the old PNG file. (6d5783f)</li> <li>restructure CONTRIBUTING.md to enhance clarity and organization (d25cdfb)</li> </ul>"},{"location":"changelog/#092-2025-04-27","title":"0.9.2 (2025-04-27)","text":""},{"location":"changelog/#documentation_5","title":"Documentation","text":"<ul> <li>add example scripts for Shape and SpectralImageSet classes (4a0fcf7)</li> <li>add examples for Pixels and Signatures classes in documentation (28f8093)</li> <li>add Geometric Shapes documentation and update navigation structure (85cd79b)</li> <li>enhance Pixels class documentation and add example usage (f77d376)</li> <li>expand entities documentation with design principles and add schematic diagram (1005e2b)</li> <li>update entities documentation and add spectral image examples (a416e82)</li> <li>update links in README for documentation and contribution guidelines (10ffb5d)</li> </ul>"},{"location":"changelog/#091-2025-04-25","title":"0.9.1 (2025-04-25)","text":""},{"location":"changelog/#documentation_6","title":"Documentation","text":"<ul> <li>add case study and external sources documentation; remove outdated examples and update mkdocs navigation (5d41305)</li> <li>add design philosophy section to CONTRIBUTING.md and clean up README.md (9372940)</li> <li>add detailed entities and overview documentation for spectral image processing (d29536f)</li> <li>update case study documentation; remove overview section and enhance data overview (0aa8430)</li> </ul>"},{"location":"changelog/#090-2025-04-24","title":"0.9.0 (2025-04-24)","text":""},{"location":"changelog/#features","title":"Features","text":"<ul> <li>add rasterio image handling functions for saving and creating images with metadata support (7e0841e)</li> <li>add validate_signal_input function and from_signals_and_pixels method for improved input handling (aaa4378)</li> </ul>"},{"location":"changelog/#081-2025-04-19","title":"0.8.1 (2025-04-19)","text":""},{"location":"changelog/#documentation_7","title":"Documentation","text":"<ul> <li>update imageset initialization method in README (7c579b4)</li> </ul>"},{"location":"changelog/#080-2025-04-18","title":"0.8.0 (2025-04-18)","text":""},{"location":"changelog/#features_1","title":"Features","text":"<ul> <li>add copy method for Signatures class with deep copy functionality (12bca2f)</li> <li>add MockImage class and corresponding tests; integrate with SpectralImage (ff6d2f2)</li> <li>enhance get_signatures_within_convex_hull function to include points intersecting with the hull; add comprehensive tests for various shapes (8fa14ea)</li> <li>implement get_signatures_within_convex_hull function and add tests (05c603c)</li> <li>implement length and item access methods for Signals and Signatures classes (447c3c2)</li> <li>refactor get_signatures_within_convex_hull function and update related tests; improve signature extraction logic (9a25824)</li> </ul>"},{"location":"changelog/#bug-fixes_2","title":"Bug Fixes","text":"<ul> <li>correct index assertion in test_geometric_shapes_index_with_start_stop (82c51f4)</li> <li>remove unnecessary wavelength coordinate assertion in test_to_xarray (16e1bd1)</li> <li>update xarray output tests to validate new coordinate structure (0e20fc6)</li> </ul>"},{"location":"changelog/#dependencies","title":"Dependencies","text":"<ul> <li>pdm update (fca230a)</li> </ul>"},{"location":"changelog/#documentation_8","title":"Documentation","text":"<ul> <li>add documentation for Helpers and Mock Image; update mkdocs navigation (a78fc78)</li> </ul>"},{"location":"changelog/#072-2025-04-10","title":"0.7.2 (2025-04-10)","text":""},{"location":"changelog/#bug-fixes_3","title":"Bug Fixes","text":"<ul> <li>Refactor image handling and typing annotations across the codebase (551dc15)</li> </ul>"},{"location":"changelog/#071-2025-04-09","title":"0.7.1 (2025-04-09)","text":""},{"location":"changelog/#bug-fixes_4","title":"Bug Fixes","text":"<ul> <li>update mkdocs.yml to enable version selector for mike plugin and correct inventories key (44e8c85)</li> </ul>"},{"location":"changelog/#documentation_9","title":"Documentation","text":"<ul> <li>update documentation deployment commands to use 'mike' instead of 'mkdocs' (1fa65b6)</li> </ul>"},{"location":"changelog/#070-2025-04-09","title":"0.7.0 (2025-04-09)","text":""},{"location":"changelog/#features_2","title":"Features","text":"<ul> <li>add to_xarray method to ImageBase and implementations in RasterioLibImage and SpectralLibImage; enhance tests for new functionality (0663f75)</li> <li>enhance Pixels and Signatures classes with repr methods; remove SignaturesFilter class and update related tests (19d212f)</li> <li>enhance Shape class with get_pixels from convex hull (fefeca2)</li> <li>introduce Shape class and ShapeGeometryEnum for geometric representations (8e33634)</li> <li>refactor shape handling; replace Shapefile with Shape and add tests (381028d)</li> <li>shape handling and pixel coordinates (f7d48c9)</li> <li>update pixel class; add validators for initialization (2bd2710)</li> <li>update SpectralImageSet methods to use spy_open; add rasterio_o\u2026 (ad3aaaf)</li> <li>update SpectralImageSet methods to use spy_open; add rasterio_open method and corresponding tests (b61c2e8)</li> </ul>"},{"location":"changelog/#bug-fixes_5","title":"Bug Fixes","text":"<ul> <li>add missing XarrayType to the public API in types.py (eab41ee)</li> <li>add row and column properties to RasterioLibImage class; enhance tests for new properties (a871485)</li> <li>implement rasterio_open method in SpectralImage class; add corresponding tests (2b0e82f)</li> <li>update pre-commit installation command to include all hook types (41faf02)</li> </ul>"},{"location":"changelog/#dependencies_1","title":"Dependencies","text":"<ul> <li>update pdm.lock and add shapely dependency in pyproject.toml (534e639)</li> </ul>"},{"location":"changelog/#documentation_10","title":"Documentation","text":"<ul> <li>enhance copilot instructions with additional naming conventions (0d7600d)</li> <li>update documentation structure by removing obsolete shapefiles and shapes entries, and adding shape details (5677b4f)</li> </ul>"},{"location":"changelog/#060-2025-03-22","title":"0.6.0 (2025-03-22)","text":""},{"location":"changelog/#features_3","title":"Features","text":"<ul> <li>add compress-data target to Makefile and enhance compression script with versioning (910f7e9)</li> <li>add script to compress test data and generate checksum (865ea02)</li> <li>add Shapefile entity with loading and geometry handling capabilities; update exceptions for filepath validation (20bd3fc)</li> <li>add SpectralLibImage support and update image loading methods (04e4b72)</li> <li>add TestDataManager class for managing test data downloads and verification; enhance compress-data script with git tagging (d00b0da)</li> <li>implement RasterioLibImage for raster file handling; update ImageBase interface and add tests (a6df199)</li> <li>implementation of spectral images base class (d333c44)</li> <li>integrate xarray support in rasterio and spectral libraries (37bac16)</li> </ul>"},{"location":"changelog/#bug-fixes_6","title":"Bug Fixes","text":"<ul> <li>correct spelling of \"coordinate\" in Coordinates class annotations (bb26fef)</li> <li>improve error handling in SpectralLibImage.open method (4cec71e)</li> <li>improve test data integrity verification and extraction process in data_manager.py (9817bd2)</li> <li>include docs/examples/src in linting and formatting scripts (3889e81)</li> <li>optimize image processing in RasterioLibImage and update nan handling in SpectralLibImage (2ffb19b)</li> <li>remove Git LFS checkout option from workflow and integrate test data integrity verification in pytest configuration (e3ad547)</li> <li>update pre-commit configuration to include tests directory for linting (c26cdd0)</li> <li>update Python version in workflow configurations from 3.10 to 3.12 (381ed36)</li> <li>update Python version in workflow configurations from 3.10 to 3.12 (3e4287c)</li> <li>update Python version in workflow configurations from 3.10 to 3.12 (db90263)</li> <li>update Python version range in pdm.lock to support 3.10 and below 3.13 (80187de)</li> <li>update type hint for open method in ImageBase class; remove TypeVar (4234dc5)</li> </ul>"},{"location":"changelog/#dependencies_2","title":"Dependencies","text":"<ul> <li>add geopandas, rasterio, and xarray as dependencies in pyproject.toml (1c7cfde)</li> <li>add types-shapely dependency for improved type checking in linting (88f0070)</li> <li>remove unused lint dependencies from pdm.lock and pyproject.toml (53b00e1)</li> <li>update configuration files for improved performance -- pdm update (4f060d4)</li> <li>update dependencies and add new testing packages in pdm.lock and pyproject.toml (da716ed)</li> </ul>"},{"location":"changelog/#documentation_11","title":"Documentation","text":"<ul> <li>reorganize API documentation structure for images and shapefiles (52e6446)</li> </ul>"},{"location":"changelog/#059-2025-01-15","title":"0.5.9 (2025-01-15)","text":""},{"location":"changelog/#bug-fixes_7","title":"Bug Fixes","text":"<ul> <li>rename fit_params to params in Scorer and cross_validation functions (4ce6a76)</li> </ul>"},{"location":"changelog/#dependencies_3","title":"Dependencies","text":"<ul> <li>update configuration files for improved linting and formatting (ecdc54b)</li> </ul>"},{"location":"changelog/#documentation_12","title":"Documentation","text":"<ul> <li>add overview and key features to README.md (1b1fd70)</li> </ul>"},{"location":"changelog/#058-2024-12-23","title":"0.5.8 (2024-12-23)","text":""},{"location":"changelog/#documentation_13","title":"Documentation","text":"<ul> <li>add use cases documentation for SiaPy library and update navigation (333bb9d)</li> <li>enhance examples with visualization scripts and update navigation (42fc4b0)</li> <li>update README with installation instructions and add example usage (5180335)</li> <li>update use cases documentation to clarify code repository links (b205431)</li> </ul>"},{"location":"changelog/#057-2024-12-20","title":"0.5.7 (2024-12-20)","text":""},{"location":"changelog/#documentation_14","title":"Documentation","text":"<ul> <li>add example for loading and processing a spectral image set (2564e88)</li> <li>add example script for loading and using SpectralImage (24d5a4b)</li> <li>add examples for loading and processing spectral images (3261665)</li> <li>enhance examples for loading and processing spectral images (09600b0)</li> <li>update data directory paths in example scripts and add transformations examples (d2e924f)</li> <li>update introduction.md with correct Zenodo link and improve formatting (15349d6)</li> </ul>"},{"location":"changelog/#056-2024-12-20","title":"0.5.6 (2024-12-20)","text":""},{"location":"changelog/#dependencies_4","title":"Dependencies","text":"<ul> <li>update dependencies and metadata in pdm.lock and pyproject.toml (0ceea41)</li> </ul>"},{"location":"changelog/#documentation_15","title":"Documentation","text":"<ul> <li>introduction.md (a6faef3)</li> </ul>"},{"location":"changelog/#055-2024-10-10","title":"0.5.5 (2024-10-10)","text":""},{"location":"changelog/#bug-fixes_8","title":"Bug Fixes","text":"<ul> <li>Update n_jobs default value to use all processors (e768b93)</li> </ul>"},{"location":"changelog/#054-2024-09-18","title":"0.5.4 (2024-09-18)","text":""},{"location":"changelog/#bug-fixes_9","title":"Bug Fixes","text":"<ul> <li>Refactor, add and correct type annotations (12ffa05)</li> </ul>"},{"location":"changelog/#documentation_16","title":"Documentation","text":"<ul> <li>Add core.exceptions API documentation and update mkdocs.yml (ca37d04)</li> </ul>"},{"location":"changelog/#053-2024-09-17","title":"0.5.3 (2024-09-17)","text":""},{"location":"changelog/#dependencies_5","title":"Dependencies","text":"<ul> <li>pdm update (5fcea60)</li> <li>To indicate that your library supports type checking (72425aa)</li> </ul>"},{"location":"changelog/#052-2024-09-03","title":"0.5.2 (2024-09-03)","text":""},{"location":"changelog/#performance-improvements","title":"Performance Improvements","text":"<ul> <li>Refactor code to improve performance in test_to_signatures_perf (39cf7a2)</li> </ul>"},{"location":"changelog/#documentation_17","title":"Documentation","text":"<ul> <li>funding update (bfdbc65)</li> <li>Update funding configuration file (bfdbc65)</li> </ul>"},{"location":"changelog/#051-2024-08-28","title":"0.5.1 (2024-08-28)","text":""},{"location":"changelog/#bug-fixes_10","title":"Bug Fixes","text":"<ul> <li>Comment out cache-related code in docs.yml workflow --temporary fix (51a8e11)</li> <li>Remove unused siapy version file and update installation instructions (8e966e3)</li> </ul>"},{"location":"changelog/#050-2024-08-28","title":"0.5.0 (2024-08-28)","text":""},{"location":"changelog/#features_4","title":"Features","text":"<ul> <li>Add load_from_parquet and save_to_parquet methods to Pixels class (9d106cb)</li> <li>Add load_from_parquet and save_to_parquet methods to Signals class (47ccb2c)</li> <li>Add load_from_parquet and save_to_parquet methods to Signatures class (ce30e67)</li> </ul>"},{"location":"changelog/#bug-fixes_11","title":"Bug Fixes","text":"<ul> <li>Update save_to_parquet method to include index in the saved file (36981a5)</li> <li>Update typing annotations in from_paths (c827862)</li> </ul>"},{"location":"changelog/#documentation_18","title":"Documentation","text":"<ul> <li>Update installation instructions with additional package managers (bf238a3)</li> </ul>"},{"location":"changelog/#049-2024-08-22","title":"0.4.9 (2024-08-22)","text":""},{"location":"changelog/#documentation_19","title":"Documentation","text":"<ul> <li>Update installation instructions and troubleshooting section (f5378c1)</li> </ul>"},{"location":"changelog/#048-2024-08-22","title":"0.4.8 (2024-08-22)","text":""},{"location":"changelog/#reverts","title":"Reverts","text":"<ul> <li>fix codespell config (fd2854e)</li> </ul>"},{"location":"changelog/#documentation_20","title":"Documentation","text":"<ul> <li>change path to logo image (b316fc0)</li> <li>Update page title in mkdocs.yml (aa1b221)</li> </ul>"},{"location":"changelog/#047-2024-08-20","title":"0.4.7 (2024-08-20)","text":""},{"location":"changelog/#bug-fixes_12","title":"Bug Fixes","text":"<ul> <li>Update license to MIT License in docs directly (4ee1772)</li> </ul>"},{"location":"changelog/#046-2024-08-20","title":"0.4.6 (2024-08-20)","text":""},{"location":"changelog/#documentation_21","title":"Documentation","text":"<ul> <li>Update links in README and mkdocs.yml (dead861)</li> </ul>"},{"location":"changelog/#045-2024-08-20","title":"0.4.5 (2024-08-20)","text":""},{"location":"changelog/#bug-fixes_13","title":"Bug Fixes","text":"<ul> <li>deploying MkDocs action fail fix (35e5a7b)</li> </ul>"},{"location":"changelog/#044-2024-08-20","title":"0.4.4 (2024-08-20)","text":""},{"location":"changelog/#documentation_22","title":"Documentation","text":"<ul> <li>Add new API documentation files (19fe2cc)</li> <li>index docs page update with default readme file (eb6703b)</li> </ul>"},{"location":"changelog/#043-2024-08-20","title":"0.4.3 (2024-08-20)","text":""},{"location":"changelog/#dependencies_6","title":"Dependencies","text":"<ul> <li>Update dependencies for documentation improvements (8d98dc1)</li> </ul>"},{"location":"changelog/#documentation_23","title":"Documentation","text":"<ul> <li>Make docs for dev (#111) (8fc65f1)</li> <li>Update site_url in mkdocs.yml (1fcb70d)</li> </ul>"},{"location":"changelog/#042-2024-08-18","title":"0.4.2 (2024-08-18)","text":""},{"location":"changelog/#documentation_24","title":"Documentation","text":"<ul> <li>logo image path changed (76d8850)</li> </ul>"},{"location":"changelog/#041-2024-08-12","title":"0.4.1 (2024-08-12)","text":""},{"location":"changelog/#bug-fixes_14","title":"Bug Fixes","text":"<ul> <li>mypy fix (0b421fe)</li> </ul>"},{"location":"changelog/#dependencies_7","title":"Dependencies","text":"<ul> <li>pdm update (a49ef58)</li> </ul>"},{"location":"changelog/#documentation_25","title":"Documentation","text":"<ul> <li>Update copyright year to 2024 (672274f)</li> </ul>"},{"location":"changelog/#040-2024-08-10","title":"0.4.0 (2024-08-10)","text":""},{"location":"changelog/#features_5","title":"Features","text":"<ul> <li>Add spectral indices computation and calculation functions (3ef8c63)</li> <li>Features generation implemented - automatic and spectral indices (16365e0)</li> </ul>"},{"location":"changelog/#bug-fixes_15","title":"Bug Fixes","text":"<ul> <li>include (6d7e9e5)</li> <li>Remove unnecessary dataclass decorator brackets (28143f3)</li> <li>stubs for spyndex, mlxtend, and autofeat (f89a22a)</li> </ul>"},{"location":"changelog/#dependencies_8","title":"Dependencies","text":"<ul> <li>Update dependencies to include spyndex, mlxtend, and autofeat (edd4978)</li> </ul>"},{"location":"changelog/#034-2024-07-26","title":"0.3.4 (2024-07-26)","text":""},{"location":"changelog/#bug-fixes_16","title":"Bug Fixes","text":"<ul> <li>Create Target base class (cf7194d)</li> <li>set default direction for optimization to 'minimize' (5a402fd)</li> <li>Update evaluators.py with type annotations and error handling (b1a4010)</li> <li>Update study config defaults to set direction to 'minimize' (347a2bb)</li> </ul>"},{"location":"changelog/#dependencies_9","title":"Dependencies","text":"<ul> <li>Update pyproject.toml with optuna&gt;=3.6.1 dependency (1faac14)</li> </ul>"},{"location":"changelog/#documentation_26","title":"Documentation","text":"<ul> <li>Update default branch name to 'main' and adjust merge instructions (42b0e29)</li> </ul>"},{"location":"changelog/#033-2024-07-16","title":"0.3.3 (2024-07-16)","text":""},{"location":"changelog/#bug-fixes_17","title":"Bug Fixes","text":"<ul> <li>Add shape_type property to Shape class; fix tests (0fccc9a)</li> </ul>"},{"location":"changelog/#032-2024-07-08","title":"0.3.2 (2024-07-08)","text":""},{"location":"changelog/#bug-fixes_18","title":"Bug Fixes","text":"<ul> <li>Update mypy configuration to ignore missing imports for sklearn module (15ad789)</li> </ul>"},{"location":"changelog/#031-2024-07-08","title":"0.3.1 (2024-07-08)","text":""},{"location":"changelog/#bug-fixes_19","title":"Bug Fixes","text":"<ul> <li>Update gitignore to include tests/data directory and ignore E501 in flake8 configuration (3664bd1)</li> </ul>"},{"location":"changelog/#030-2024-07-06","title":"0.3.0 (2024-07-06)","text":""},{"location":"changelog/#features_6","title":"Features","text":"<ul> <li>Add camera_id property and images_by_camera_id method to SpectralImageSet (c7814dc)</li> </ul>"},{"location":"changelog/#bug-fixes_20","title":"Bug Fixes","text":"<ul> <li>add scope to fixtures. (9e2befd)</li> <li>Update indent_style and indent_size in .editorconfig (a3288dc)</li> </ul>"},{"location":"changelog/#024-2024-07-04","title":"0.2.4 (2024-07-04)","text":""},{"location":"changelog/#documentation_27","title":"Documentation","text":"<ul> <li>moved files from .github -&gt; repo root (b1a3989)</li> <li>security put in place (8585538)</li> </ul>"},{"location":"changelog/#023-2024-07-01","title":"0.2.3 (2024-07-01)","text":""},{"location":"changelog/#documentation_28","title":"Documentation","text":"<ul> <li>fixed annotations, added citation file (baa3628)</li> </ul>"},{"location":"changelog/#022-2024-06-30","title":"0.2.2 (2024-06-30)","text":""},{"location":"changelog/#bug-fixes_21","title":"Bug Fixes","text":"<ul> <li>adapt codespell settings to siapy project (70649e4)</li> <li>fixed test; linter add; dependencies upgrated (a8e8e8b)</li> <li>pyptoject.toml rename and add additional files to source pdm build (951f3f7)</li> <li>success flag added back and run_id (4e62181)</li> <li>Update codespell settings to exclude unnecessary directories (383792b)</li> </ul>"},{"location":"changelog/#documentation_29","title":"Documentation","text":"<ul> <li>conventional commits type description (d4f05bd)</li> <li>remove initial contributing readme (afd7e0b)</li> </ul>"},{"location":"changelog/#021-2024-06-29","title":"0.2.1 (2024-06-29)","text":""},{"location":"changelog/#bug-fixes_22","title":"Bug Fixes","text":"<ul> <li>added missing docs files (4cd628b)</li> </ul>"},{"location":"changelog/#020-2024-06-29","title":"0.2.0 (2024-06-29)","text":""},{"location":"changelog/#features_7","title":"Features","text":"<ul> <li>Add method to get a shape by name in GeometricShapes (1583a8d)</li> <li>Add pixel selection functionality and lasso tool for image plotting (fabc43b)</li> <li>Add scikit-image dependency for image processing and add image transformations. (a464ef7)</li> <li>Add Shape class for geometric shapes in SpectralImage (e1456c6)</li> <li>Add support for saving images with different data types and metadata (5d6d09c)</li> <li>Add test for transformation function and affine matrix generation (c9aa4e3)</li> <li>Add u(), v(), and to_numpy() methods to Pixels entity (e4aa9e2)</li> <li>Improve SpectralImage class by removing redundant code and optimizing image processing, test added (ea859f7)</li> <li>Move Corregistrator class to its own file and update imports (5286365)</li> <li>Refactor code to use preserve_range=True in image rotation and rescaling functions, implemented merge_by_spectral (217032b)</li> <li>Refactor Corregistrator class and add Pixels entity (59aafb0)</li> <li>Refactor GeometricShapes class to use a separate class for managing shapes, test added (5f32e0e)</li> <li>Refactor SignaturesFilter to allow filtering rows and columns (7d9e03c)</li> <li>Refactor SignaturesFilter to allow filtering rows and columns (ae2be44)</li> <li>separated validator functons. implemented test for image transformation (9fe2c1a)</li> </ul>"},{"location":"changelog/#bug-fixes_23","title":"Bug Fixes","text":"<ul> <li>Refactor code to use Path instead of ConvexHull for FreeDraw convex hull calculation, shapes tests added (2ddd253)</li> <li>rename plotting -&gt; plot (ac9a906)</li> <li>tests renamed to prepend the name of the directory (f91fe45)</li> </ul>"},{"location":"changelog/#documentation_30","title":"Documentation","text":"<ul> <li>templates (89e0a48)</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#design-philosophy","title":"Design philosophy","text":"<p><code>SiaPy</code> is built with several key design principles:</p> <ol> <li>Type Safety: Comprehensive type hints throughout the codebase</li> <li>Modular Design: Composable components that can be used independently</li> <li>Consistent APIs: Uniform interface patterns across the library</li> <li>Pythonic Interfaces: Following Python best practices and conventions</li> <li>Error Handling: Structured exception hierarchy for clear error reporting</li> </ol>"},{"location":"contributing/#code-standard","title":"Code standard","text":""},{"location":"contributing/#dependency-management","title":"Dependency management","text":"<p>This project uses PDM for dependency management and packaging.</p>"},{"location":"contributing/#highlights","title":"Highlights","text":"<ul> <li>Automatic virtual environment management: Automatically manages the application environment.</li> <li>Dependency resolution: Automatically resolve any dependency version conflicts using the <code>pip</code> dependency resolver.</li> <li>Dependency separation: Supports separate lists of optional dependencies in the pyproject.toml. Production installs can skip optional dependencies for speed.</li> <li>Builds: Features for easily building the project into a Python package and publishing the package to PyPI.</li> </ul>"},{"location":"contributing/#key-commands","title":"Key commands","text":"Command Description <code>pdm init</code> Initialize a new project <code>pdm add PACKAGE_NAME</code> Add a package to the project dependencies <code>pdm install</code> Install dependencies from pyproject.toml <code>pdm list</code> Show a list of installed packages <code>pdm run COMMAND</code> Run a command within the PDM environment <code>pdm shell</code> Activate the PDM environment, similar to activating a virtualenv <code>pdm sync</code> Synchronize the project's dependencies"},{"location":"contributing/#testing-with-pytest","title":"Testing with pytest","text":"<p>Tests are located in the tests directory. The project uses pytest as its testing framework, with configuration stored in pyproject.toml.</p>"},{"location":"contributing/#key-features","title":"Key features","text":"Feature Description Documentation <code>capfd</code> Capture stdout/stderr output Capturing output <code>fixtures</code> Reusable test components Fixtures <code>monkeypatch</code> Modify behavior during tests Monkeypatching <code>parametrize</code> Run tests with different inputs Parametrization <code>tmp_path</code>/<code>tmp_dir</code> Create temporary test files Temporary directories"},{"location":"contributing/#code-quality","title":"Code quality","text":""},{"location":"contributing/#style-and-format","title":"Style and format","text":"<p>Python code is formatted with Ruff. Ruff configuration is stored in pyproject.toml.</p>"},{"location":"contributing/#static-type-checking","title":"Static type checking","text":"<p>To learn type annotation basics, see the Python typing module docs and Python type annotations how-to. Type annotations are not used at runtime. The standard library <code>typing</code> module includes a <code>TYPE_CHECKING</code> constant that is <code>False</code> at runtime, but <code>True</code> when conducting static type checking prior to runtime. Type imports are included under <code>if TYPE_CHECKING:</code> conditions so that they are not imported at runtime. Mypy is used for type-checking and it's configuration is included in pyproject.toml.</p>"},{"location":"contributing/#spell-check","title":"Spell check","text":"<p>Spell check is performed with CSpell. Configuration is stored in pyproject.toml.</p>"},{"location":"contributing/#scripts","title":"Scripts","text":"<p>The project provides several helpful commands through the <code>make</code> utility, which mostly calls scripts from the scripts folder. You can run these from the project root directory.</p> <p>To view all available commands with descriptions, run:</p> <pre><code>make help\n</code></pre> <p>Available commands include:</p> Command Description <code>make install</code> Install the package, dependencies, and pre-commit for local development <code>make format</code> Auto-format python source files <code>make lint</code> Lint python source files <code>make test</code> Run all tests <code>make flt</code> Run format, lint, and test in sequence <code>make testcov</code> Run tests and generate a coverage report <code>make codespell</code> Use Codespell to do spellchecking <code>make refresh-lockfiles</code> Sync lockfiles with requirements files <code>make rebuild-lockfiles</code> Rebuild lockfiles from scratch, updating all dependencies <code>make clean</code> Clear local caches and build artifacts <code>make generate-docs</code> Generate the documentation <code>make serve-docs</code> Serve the documentation locally <code>make serve-docs-mike</code> Serve the documentation using mike <code>make update-branches</code> Update local git branches after successful PR <code>make version</code> Check the current project version <code>make compress-data</code> Compress the data files <p>Most commands use PDM (Python package and dependency manager) internally, which will be checked for installation with <code>.pdm</code> and <code>.pre-commit</code> helper tasks.</p>"},{"location":"contributing/#development","title":"Development","text":""},{"location":"contributing/#quick-design-pattern-guide","title":"Quick design pattern guide","text":"<p>For consistent code quality across the project, refer to copilot-instructions, which concisely describes key design patterns.</p>"},{"location":"contributing/#git","title":"Git","text":"<p>Why use Git? Git enables creation of multiple versions of a code repository called branches, with the ability to track and undo changes in detail.</p> <p>Contribute by following:</p> <ul> <li>Install Git by downloading from the website, or with a package manager like Homebrew.</li> <li>Configure Git to connect to GitHub with SSH.</li> <li>Fork this repo.</li> <li>Create a branch in your fork.</li> <li>Commit your changes with a properly-formatted Git commit message.</li> <li>Create a pull request (PR) to incorporate your changes into the upstream project you forked.</li> </ul>"},{"location":"contributing/#branch-structure","title":"Branch structure","text":"Branch Purpose Protection Rules <code>main</code> Stable production code \u2022 Signed commits required\u2022 No force pushing\u2022 Status checks required\u2022 Admin included <code>develop</code> Integration branch \u2022 Signed commits required\u2022 Force pushing allowed\u2022 Admin included"},{"location":"contributing/#workflow-rules","title":"Workflow rules","text":"<ul> <li>The default branch is <code>main</code></li> <li>Feature branches must target <code>develop</code> for pull requests</li> <li>Only PRs from <code>develop</code> may be merged into <code>main</code></li> <li>Status checks must pass on <code>develop</code> before merging to <code>main</code></li> </ul>"},{"location":"contributing/#commit-structure","title":"Commit structure","text":"<p>Follow the Conventional Commits specification for commit messages. This standardizes the commit history and facilitates automatic generation of the changelog. Ensure your commit messages clearly describe the changes made and follow the format <code>type(scope?): subject</code>, where <code>scope</code> is optional.</p> <p>Type must be one of the following:</p> <ul> <li><code>feat</code>: A new feature</li> <li><code>fix</code>: A bug fix</li> <li><code>perf</code>: A code change that improves performance</li> <li><code>deps</code>: Dependency updates</li> <li><code>revert</code>: Reverts a previous commit</li> <li><code>docs</code>: Documentation only changes</li> <li><code>style</code>: Changes that do not affect the meaning of the code (white-space, formatting, missing semi-colons, etc), hidden</li> <li><code>chore</code>: Miscellaneous chores, hidden</li> <li><code>refactor</code>: A code change that neither fixes a bug nor adds a feature, hidden</li> <li><code>test</code>: Adding missing tests or correcting existing tests, hidden</li> <li><code>build</code>: Changes that affect the build system or external dependencies (example scopes: gulp, broccoli, npm), hidden</li> <li><code>ci</code>: Changes to our CI configuration files and scripts (example scopes: Travis, Circle, BrowserStack, SauceLabs), hidden</li> </ul>"},{"location":"contributing/#github-actions-workflows","title":"GitHub actions workflows","text":"<p>GitHub Actions is a continuous integration/continuous deployment (CI/CD) service that runs on GitHub repos. Actions are grouped into workflows and stored in .github/workflows.</p>"},{"location":"contributing/#releases","title":"Releases","text":"<p>The CI pipeline automatically creates release based on conventional commit messages.</p> <p>Release version numbers are determined by analyzing commit types:</p> <ul> <li><code>feat</code>: Increments minor version (1.0.0 \u2192 1.1.0)</li> <li><code>fix</code>: Increments patch version (1.0.0 \u2192 1.0.1)</li> <li><code>feat</code> with <code>BREAKING CHANGE</code>: Increments major version (1.0.0 \u2192 2.0.0)</li> </ul> <p>The following guidelines are considered:</p> <ul> <li>SemVer guidelines when choosing a version number. Note that PEP 440 Python version specifiers and SemVer version specifiers differ, particularly with regard to specifying prereleases. Use syntax compatible with both.</li> <li>The PEP 440 default (like <code>1.0.0a0</code>) is different from SemVer.</li> <li>An alternative form of the Python prerelease syntax permitted in PEP 440 (like <code>1.0.0-alpha.0</code>) is compatible with SemVer, and this form should be used when tagging releases.</li> <li>Examples of acceptable tag names: <code>1.0.0</code>, <code>1.0.0-alpha.0</code>, <code>1.0.0-beta.1</code></li> <li>Push to <code>develop</code> and verify all CI checks pass.</li> <li>Fast-forward merge to <code>main</code>, push, and verify all CI checks pass.</li> </ul>"},{"location":"contributing/#summary","title":"Summary","text":"<p>PRs welcome!</p> <ul> <li>Consider starting a discussion to see if there's interest in what you want to do.</li> <li>Submit PRs from feature branches on forks to the <code>develop</code> branch.</li> <li>Ensure PRs pass all CI checks.</li> <li>Maintain high test coverage (&gt;80%).</li> </ul>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#prerequisites","title":"Prerequisites","text":"<p>Before installing <code>siapy</code> library, ensure you have the following prerequisites:</p> <ul> <li>Python 3.10 or higher</li> <li><code>pip</code> (Python package installer) or any other installer (e.g. pdm, uv, poetry)</li> </ul>"},{"location":"install/#installation","title":"Installation","text":"<p>Installation is as simple as:</p> <pre><code>pip install siapy\n</code></pre>"},{"location":"install/#alternative-installation-methods","title":"Alternative Installation Methods","text":"<p>Python package and dependency managers</p> <p>You can also install siapy using other popular Python package and dependency managers:</p> <ul> <li>PDM:</li> </ul> <pre><code>pdm add siapy\n</code></pre> <ul> <li>Poetry:</li> </ul> <pre><code>poetry add siapy\n</code></pre> <ul> <li>uv:</li> </ul> <pre><code>uv add siapy\n</code></pre> <p>Manually</p> <p>If you prefer to install from the source, you can clone the repository and install it manually:</p> <pre><code>git clone https://github.com/siapy/siapy-lib.git\ncd siapy\nmake install\n</code></pre>"},{"location":"install/#verify-installation","title":"Verify Installation","text":"<p>To verify that siapy has been installed correctly, you can run:</p> <pre><code>python -c \"import siapy; print(siapy.__version__)\"\n</code></pre>"},{"location":"install/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter any issues during installation, consider the following solutions:</p> <ul> <li>Ensure that you have the correct version of Python installed.</li> <li>Check for any missing dependencies and install them manually.</li> <li>Upgrade pip to the latest version:</li> </ul> <pre><code>pip install --upgrade pip\n</code></pre> <p>For further assistance, please refer to the documentation or open an issue on GitHub.</p>"},{"location":"permit/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2025 SiaPy, Agricultural institute of Slovenia</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"api/core/exceptions/","title":"Exceptions","text":""},{"location":"api/core/exceptions/#siapy.core.exceptions","title":"siapy.core.exceptions","text":"<p>Exceptions for SiaPy library.</p> <p>This module defines custom exceptions used throughout the SiaPy library to handle errors related to file handling, input validation, processing, and configuration.</p>"},{"location":"api/core/exceptions/#siapy.core.exceptions.SiapyError","title":"SiapyError","text":"<pre><code>SiapyError(message: str, name: str = 'SiaPy')\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Base exception for SiaPy library.</p> <p>This is the base exception class for all custom exceptions in the SiaPy library. All other SiaPy exceptions inherit from this class.</p> <p>This is the base initialization method for all SiaPy custom exceptions. It stores the error message and component name for detailed error reporting.</p> PARAMETER DESCRIPTION <code>message</code> <p>The error message describing what went wrong.</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>The name of the library/component raising the error. Defaults to \"SiaPy\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'SiaPy'</code> </p> Example <pre><code>from siapy.core.exceptions import SiapyError\n\nraise SiapyError(\"Something went wrong\", \"MyComponent\")\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, message: str, name: str = \"SiaPy\") -&gt; None:\n    \"\"\"Initialize SiapyError exception.\n\n    This is the base initialization method for all SiaPy custom exceptions.\n    It stores the error message and component name for detailed error reporting.\n\n    Args:\n        message: The error message describing what went wrong.\n        name: The name of the library/component raising the error. Defaults to \"SiaPy\".\n\n    Example:\n        ```python\n        from siapy.core.exceptions import SiapyError\n\n        raise SiapyError(\"Something went wrong\", \"MyComponent\")\n        ```\n    \"\"\"\n    self.message: str = message\n    self.name: str = name\n    super().__init__(self.message, self.name)\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.SiapyError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.SiapyError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidFilepathError","title":"InvalidFilepathError","text":"<pre><code>InvalidFilepathError(filename: str | Path)\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised when a required file is not found.</p> <p>This exception is raised when attempting to access a file that does not exist or when a provided file path is invalid.</p> <p>Creates an exception for when a required file cannot be found or accessed. The filename is converted to string format for consistent error messaging.</p> PARAMETER DESCRIPTION <code>filename</code> <p>The path to the file that was not found. Can be a string or Path object.</p> <p> TYPE: <code>str | Path</code> </p> Example <pre><code>from siapy.core.exceptions import InvalidFilepathError\nfrom pathlib import Path\n\n# Using string path\nraise InvalidFilepathError(\"/path/to/missing/file.txt\")\n\n# Using Path object\nraise InvalidFilepathError(Path(\"missing_file.txt\"))\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, filename: str | Path) -&gt; None:\n    \"\"\"Initialize InvalidFilepathError exception.\n\n    Creates an exception for when a required file cannot be found or accessed.\n    The filename is converted to string format for consistent error messaging.\n\n    Args:\n        filename: The path to the file that was not found. Can be a string or Path object.\n\n    Example:\n        ```python\n        from siapy.core.exceptions import InvalidFilepathError\n        from pathlib import Path\n\n        # Using string path\n        raise InvalidFilepathError(\"/path/to/missing/file.txt\")\n\n        # Using Path object\n        raise InvalidFilepathError(Path(\"missing_file.txt\"))\n        ```\n    \"\"\"\n    self.filename: str = str(filename)\n    super().__init__(f\"File not found: {filename}\")\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidFilepathError.filename","title":"filename  <code>instance-attribute</code>","text":"<pre><code>filename: str = str(filename)\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidFilepathError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidFilepathError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidInputError","title":"InvalidInputError","text":"<pre><code>InvalidInputError(\n    input_value: Any, message: str = \"Invalid input\"\n)\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised for invalid input.</p> <p>This exception is raised when the provided input value does not meet the expected criteria or validation rules.</p> <p>Creates an exception for when input validation fails. The input value is stored for debugging purposes and included in the error message.</p> PARAMETER DESCRIPTION <code>input_value</code> <p>The invalid input value that caused the error.</p> <p> TYPE: <code>Any</code> </p> <code>message</code> <p>Custom error message. Defaults to \"Invalid input\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Invalid input'</code> </p> Example <pre><code>from siapy.core.exceptions import InvalidInputError\n\n# With default message\nraise InvalidInputError(-5)\n\n# With custom message\nraise InvalidInputError(-5, \"Value must be non-negative\")\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, input_value: Any, message: str = \"Invalid input\") -&gt; None:\n    \"\"\"Initialize InvalidInputError exception.\n\n    Creates an exception for when input validation fails. The input value is stored\n    for debugging purposes and included in the error message.\n\n    Args:\n        input_value: The invalid input value that caused the error.\n        message: Custom error message. Defaults to \"Invalid input\".\n\n    Example:\n        ```python\n        from siapy.core.exceptions import InvalidInputError\n\n        # With default message\n        raise InvalidInputError(-5)\n\n        # With custom message\n        raise InvalidInputError(-5, \"Value must be non-negative\")\n        ```\n    \"\"\"\n    self.input_value: Any = input_value\n    self.message: str = message\n    super().__init__(f\"{message}: {input_value}\")\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidInputError.input_value","title":"input_value  <code>instance-attribute</code>","text":"<pre><code>input_value: Any = input_value\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidInputError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidInputError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidTypeError","title":"InvalidTypeError","text":"<pre><code>InvalidTypeError(\n    input_value: Any,\n    allowed_types: type | tuple[type, ...],\n    message: str = \"Invalid type\",\n)\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised for invalid type.</p> <p>This exception is raised when a value has an incorrect type that doesn't match the expected or allowed types for a particular operation.</p> <p>Creates an exception for type validation failures. Stores the actual value, its type, and the allowed types for comprehensive error reporting.</p> PARAMETER DESCRIPTION <code>input_value</code> <p>The value with the invalid type.</p> <p> TYPE: <code>Any</code> </p> <code>allowed_types</code> <p>The type or tuple of types that are allowed for this value.</p> <p> TYPE: <code>type | tuple[type, ...]</code> </p> <code>message</code> <p>Custom error message. Defaults to \"Invalid type\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Invalid type'</code> </p> Example <pre><code>from siapy.core.exceptions import InvalidTypeError\n\n# Single allowed type\nraise InvalidTypeError(\"text\", int, \"Expected integer\")\n\n# Multiple allowed types\nraise InvalidTypeError(\"text\", (int, float), \"Expected numeric type\")\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(\n    self,\n    input_value: Any,\n    allowed_types: type | tuple[type, ...],\n    message: str = \"Invalid type\",\n) -&gt; None:\n    \"\"\"Initialize InvalidTypeError exception.\n\n    Creates an exception for type validation failures. Stores the actual value,\n    its type, and the allowed types for comprehensive error reporting.\n\n    Args:\n        input_value: The value with the invalid type.\n        allowed_types: The type or tuple of types that are allowed for this value.\n        message: Custom error message. Defaults to \"Invalid type\".\n\n    Example:\n        ```python\n        from siapy.core.exceptions import InvalidTypeError\n\n        # Single allowed type\n        raise InvalidTypeError(\"text\", int, \"Expected integer\")\n\n        # Multiple allowed types\n        raise InvalidTypeError(\"text\", (int, float), \"Expected numeric type\")\n        ```\n    \"\"\"\n    self.input_value: Any = input_value\n    self.input_type: Any = type(input_value)\n    self.allowed_types: type | tuple[type, ...] = allowed_types\n    self.message: str = message\n    super().__init__(f\"{message}: {input_value} (type: {self.input_type}). Allowed types: {allowed_types}\")\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidTypeError.input_value","title":"input_value  <code>instance-attribute</code>","text":"<pre><code>input_value: Any = input_value\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidTypeError.input_type","title":"input_type  <code>instance-attribute</code>","text":"<pre><code>input_type: Any = type(input_value)\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidTypeError.allowed_types","title":"allowed_types  <code>instance-attribute</code>","text":"<pre><code>allowed_types: type | tuple[type, ...] = allowed_types\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidTypeError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.InvalidTypeError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.ProcessingError","title":"ProcessingError","text":"<pre><code>ProcessingError(\n    message: str = \"An error occurred during processing\",\n)\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised for errors during processing.</p> <p>This exception is raised when an error occurs during data processing operations, such as image processing, data transformation, or computational tasks.</p> <p>Creates an exception for when errors occur during data processing operations. This is a general-purpose exception for computational or transformation failures.</p> PARAMETER DESCRIPTION <code>message</code> <p>Error message describing the processing failure. Defaults to \"An error occurred during processing\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'An error occurred during processing'</code> </p> Example <pre><code>from siapy.core.exceptions import ProcessingError\n\n# With default message\nraise ProcessingError()\n\n# With custom message\nraise ProcessingError(\"Failed to process image data\")\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, message: str = \"An error occurred during processing\") -&gt; None:\n    \"\"\"Initialize ProcessingError exception.\n\n    Creates an exception for when errors occur during data processing operations.\n    This is a general-purpose exception for computational or transformation failures.\n\n    Args:\n        message: Error message describing the processing failure.\n            Defaults to \"An error occurred during processing\".\n\n    Example:\n        ```python\n        from siapy.core.exceptions import ProcessingError\n\n        # With default message\n        raise ProcessingError()\n\n        # With custom message\n        raise ProcessingError(\"Failed to process image data\")\n        ```\n    \"\"\"\n    self.message: str = message\n    super().__init__(message)\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.ProcessingError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.ProcessingError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.ConfigurationError","title":"ConfigurationError","text":"<pre><code>ConfigurationError(message: str = 'Configuration error')\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised for configuration errors.</p> <p>This exception is raised when there are issues with configuration settings, invalid configuration parameters, or missing required configuration values.</p> <p>Creates an exception for configuration-related issues such as invalid settings, missing required parameters, or malformed configuration data.</p> PARAMETER DESCRIPTION <code>message</code> <p>Error message describing the configuration issue. Defaults to \"Configuration error\".</p> <p> TYPE: <code>str</code> DEFAULT: <code>'Configuration error'</code> </p> Example <pre><code>from siapy.core.exceptions import ConfigurationError\n\n# With default message\nraise ConfigurationError()\n\n# With custom message\nraise ConfigurationError(\"Missing required parameter 'api_key'\")\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, message: str = \"Configuration error\") -&gt; None:\n    \"\"\"Initialize ConfigurationError exception.\n\n    Creates an exception for configuration-related issues such as invalid settings,\n    missing required parameters, or malformed configuration data.\n\n    Args:\n        message: Error message describing the configuration issue.\n            Defaults to \"Configuration error\".\n\n    Example:\n        ```python\n        from siapy.core.exceptions import ConfigurationError\n\n        # With default message\n        raise ConfigurationError()\n\n        # With custom message\n        raise ConfigurationError(\"Missing required parameter 'api_key'\")\n        ```\n    \"\"\"\n    self.message: str = message\n    super().__init__(message)\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.ConfigurationError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.ConfigurationError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.MethodNotImplementedError","title":"MethodNotImplementedError","text":"<pre><code>MethodNotImplementedError(\n    class_name: str, method_name: str\n)\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised for not implemented methods.</p> <p>This exception is raised when a method that should be implemented in a subclass has not been implemented, typically in abstract base classes or interfaces.</p> <p>Creates an exception for when a required method has not been implemented, typically in abstract base classes or interface implementations.</p> PARAMETER DESCRIPTION <code>class_name</code> <p>The name of the class where the method is not implemented.</p> <p> TYPE: <code>str</code> </p> <code>method_name</code> <p>The name of the method that is not implemented.</p> <p> TYPE: <code>str</code> </p> Example <pre><code>from siapy.core.exceptions import MethodNotImplementedError\n\nclass AbstractProcessor:\n    def process(self):\n        raise MethodNotImplementedError(\"AbstractProcessor\", \"process\")\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, class_name: str, method_name: str) -&gt; None:\n    \"\"\"Initialize MethodNotImplementedError exception.\n\n    Creates an exception for when a required method has not been implemented,\n    typically in abstract base classes or interface implementations.\n\n    Args:\n        class_name: The name of the class where the method is not implemented.\n        method_name: The name of the method that is not implemented.\n\n    Example:\n        ```python\n        from siapy.core.exceptions import MethodNotImplementedError\n\n        class AbstractProcessor:\n            def process(self):\n                raise MethodNotImplementedError(\"AbstractProcessor\", \"process\")\n        ```\n    \"\"\"\n    self.class_name: str = class_name\n    self.method_name: str = method_name\n    super().__init__(f\"Method '{method_name}' not implemented in class '{class_name}'\")\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.MethodNotImplementedError.class_name","title":"class_name  <code>instance-attribute</code>","text":"<pre><code>class_name: str = class_name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.MethodNotImplementedError.method_name","title":"method_name  <code>instance-attribute</code>","text":"<pre><code>method_name: str = method_name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.MethodNotImplementedError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.MethodNotImplementedError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.DirectInitializationError","title":"DirectInitializationError","text":"<pre><code>DirectInitializationError(class_: type)\n</code></pre> <p>               Bases: <code>SiapyError</code></p> <p>Exception raised when a class method is required to create an instance.</p> <p>This exception is raised when attempting to directly instantiate a class that requires the use of specific class methods for proper initialization.</p> <p>Creates an exception for when a class requires the use of specific class methods for instantiation rather than direct initialization. Automatically discovers available class methods to suggest in the error message.</p> PARAMETER DESCRIPTION <code>class_</code> <p>The class type that cannot be directly initialized.</p> <p> TYPE: <code>type</code> </p> RAISES DESCRIPTION <code>ImportError</code> <p>If the required utility function cannot be imported.</p> Example <pre><code>from siapy.core.exceptions import DirectInitializationError\n\nclass SpecialClass:\n    def __init__(self):\n        raise DirectInitializationError(SpecialClass)\n\n    @classmethod\n    def from_file(cls, filepath):\n        return cls.__new__(cls)\n</code></pre> Source code in <code>siapy/core/exceptions.py</code> <pre><code>def __init__(self, class_: type) -&gt; None:\n    \"\"\"Initialize DirectInitializationError exception.\n\n    Creates an exception for when a class requires the use of specific class methods\n    for instantiation rather than direct initialization. Automatically discovers\n    available class methods to suggest in the error message.\n\n    Args:\n        class_: The class type that cannot be directly initialized.\n\n    Raises:\n        ImportError: If the required utility function cannot be imported.\n\n    Example:\n        ```python\n        from siapy.core.exceptions import DirectInitializationError\n\n        class SpecialClass:\n            def __init__(self):\n                raise DirectInitializationError(SpecialClass)\n\n            @classmethod\n            def from_file(cls, filepath):\n                return cls.__new__(cls)\n        ```\n    \"\"\"\n    from siapy.utils.general import get_classmethods\n\n    self.class_name: str = class_.__class__.__name__\n    self.class_methods: list[str] = get_classmethods(class_)\n    super().__init__(\n        f\"Use any of the @classmethod to create a new instance of '{self.class_name}': {self.class_methods}\"\n    )\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.DirectInitializationError.class_name","title":"class_name  <code>instance-attribute</code>","text":"<pre><code>class_name: str = __name__\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.DirectInitializationError.class_methods","title":"class_methods  <code>instance-attribute</code>","text":"<pre><code>class_methods: list[str] = get_classmethods(class_)\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.DirectInitializationError.message","title":"message  <code>instance-attribute</code>","text":"<pre><code>message: str = message\n</code></pre>"},{"location":"api/core/exceptions/#siapy.core.exceptions.DirectInitializationError.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str = name\n</code></pre>"},{"location":"api/core/logger/","title":"Logger","text":""},{"location":"api/core/logger/#siapy.core.logger","title":"siapy.core.logger","text":"<p>Logging configuration for SiaPy library.</p> <p>This module provides a centralized logger instance for the entire SiaPy library. All modules should use this logger for consistent logging behavior.</p>"},{"location":"api/core/logger/#siapy.core.logger.logger","title":"logger  <code>module-attribute</code>","text":"<pre><code>logger = getLogger('siapy')\n</code></pre>"},{"location":"api/core/types/","title":"Types","text":""},{"location":"api/core/types/#siapy.core.types","title":"siapy.core.types","text":"<p>Type definitions and aliases for SiaPy library.</p> <p>This module defines common type aliases used throughout the SiaPy library for spectral images, arrays, and data containers to ensure type safety and consistency across the codebase.</p>"},{"location":"api/core/types/#siapy.core.types.SpectralLibType","title":"SpectralLibType  <code>module-attribute</code>","text":"<pre><code>SpectralLibType = BilFile | BipFile | BsqFile\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.XarrayType","title":"XarrayType  <code>module-attribute</code>","text":"<pre><code>XarrayType = DataArray | Dataset\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.ImageType","title":"ImageType  <code>module-attribute</code>","text":"<pre><code>ImageType = (\n    SpectralImage[Any] | NDArray[floating[Any]] | Image\n)\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.ImageSizeType","title":"ImageSizeType  <code>module-attribute</code>","text":"<pre><code>ImageSizeType = int | tuple[int, ...]\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.ImageDataType","title":"ImageDataType  <code>module-attribute</code>","text":"<pre><code>ImageDataType = (\n    uint8\n    | int16\n    | int32\n    | float32\n    | float64\n    | complex64\n    | complex128\n    | uint16\n    | uint32\n    | int64\n    | uint64\n)\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.ImageContainerType","title":"ImageContainerType  <code>module-attribute</code>","text":"<pre><code>ImageContainerType = SpectralImage[Any] | SpectralImageSet\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.ArrayLike1dType","title":"ArrayLike1dType  <code>module-attribute</code>","text":"<pre><code>ArrayLike1dType = (\n    NDArray[floating[Any]]\n    | Series\n    | Sequence[Any]\n    | ArrayLike\n)\n</code></pre>"},{"location":"api/core/types/#siapy.core.types.ArrayLike2dType","title":"ArrayLike2dType  <code>module-attribute</code>","text":"<pre><code>ArrayLike2dType = (\n    NDArray[floating[Any]]\n    | DataFrame\n    | Sequence[Any]\n    | ArrayLike\n)\n</code></pre>"},{"location":"api/datasets/helpers/","title":"Helpers","text":""},{"location":"api/datasets/helpers/#siapy.datasets.helpers","title":"siapy.datasets.helpers","text":""},{"location":"api/datasets/helpers/#siapy.datasets.helpers.generate_classification_target","title":"generate_classification_target","text":"<pre><code>generate_classification_target(\n    dataframe: DataFrame, column_names: str | list[str]\n) -&gt; ClassificationTarget\n</code></pre> <p>Generate a classification target from DataFrame columns.</p> <p>Creates a classification target by combining one or more DataFrame columns into encoded labels suitable for machine learning classification tasks. Multiple columns are combined using a '__' delimiter and then factorized into numeric values.</p> PARAMETER DESCRIPTION <code>dataframe</code> <p>The input DataFrame containing the target data.</p> <p> TYPE: <code>DataFrame</code> </p> <code>column_names</code> <p>Name(s) of the column(s) to use for generating the classification target. Can be a single column name as string or multiple column names as list.</p> <p> TYPE: <code>str | list[str]</code> </p> RETURNS DESCRIPTION <code>ClassificationTarget</code> <p>A ClassificationTarget object containing the original labels, encoded numeric values, and the encoding mapping.</p> Example <pre><code>import pandas as pd\nfrom siapy.datasets.helpers import generate_classification_target\n\ndf = pd.DataFrame({\n    'category': ['A', 'B', 'A', 'C'],\n    'subcategory': ['X', 'Y', 'X', 'Z']\n})\n\n# Single column\ntarget = generate_classification_target(df, 'category')\n\n# Multiple columns\ntarget = generate_classification_target(df, ['category', 'subcategory'])\n</code></pre> Source code in <code>siapy/datasets/helpers.py</code> <pre><code>def generate_classification_target(\n    dataframe: pd.DataFrame,\n    column_names: str | list[str],\n) -&gt; \"ClassificationTarget\":\n    \"\"\"Generate a classification target from DataFrame columns.\n\n    Creates a classification target by combining one or more DataFrame columns into\n    encoded labels suitable for machine learning classification tasks. Multiple columns\n    are combined using a '__' delimiter and then factorized into numeric values.\n\n    Args:\n        dataframe: The input DataFrame containing the target data.\n        column_names: Name(s) of the column(s) to use for generating the classification target.\n            Can be a single column name as string or multiple column names as list.\n\n    Returns:\n        A ClassificationTarget object containing the original labels, encoded numeric values, and the encoding mapping.\n\n    Example:\n        ```python\n        import pandas as pd\n        from siapy.datasets.helpers import generate_classification_target\n\n        df = pd.DataFrame({\n            'category': ['A', 'B', 'A', 'C'],\n            'subcategory': ['X', 'Y', 'X', 'Z']\n        })\n\n        # Single column\n        target = generate_classification_target(df, 'category')\n\n        # Multiple columns\n        target = generate_classification_target(df, ['category', 'subcategory'])\n        ```\n    \"\"\"\n    from .schemas import (\n        ClassificationTarget,  # Local import to avoid circular dependency\n    )\n\n    if isinstance(column_names, str):\n        column_names = [column_names]\n    # create one column labels from multiple columns\n    label = dataframe[column_names].apply(tuple, axis=1)\n    # Convert tuples to strings with '__' delimiter\n    label = label.apply(lambda x: \"__\".join(x))\n    # encode to numbers\n    encoded_np, encoding_np = pd.factorize(label)\n    encoded = pd.Series(encoded_np, name=\"encoded\")\n    encoding = pd.Series(encoding_np, name=\"encoding\")\n    return ClassificationTarget(label=label, value=encoded, encoding=encoding)\n</code></pre>"},{"location":"api/datasets/helpers/#siapy.datasets.helpers.generate_regression_target","title":"generate_regression_target","text":"<pre><code>generate_regression_target(\n    dataframe: DataFrame, column_name: str\n) -&gt; RegressionTarget\n</code></pre> <p>Generate a regression target from a DataFrame column.</p> <p>Creates a regression target from a single DataFrame column for use in machine learning regression tasks.</p> PARAMETER DESCRIPTION <code>dataframe</code> <p>The input DataFrame containing the target data.</p> <p> TYPE: <code>DataFrame</code> </p> <code>column_name</code> <p>Name of the column to use for generating the regression target.</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>RegressionTarget</code> <p>A RegressionTarget object containing the column name and values.</p> Example <pre><code>import pandas as pd\nfrom siapy.datasets.helpers import generate_regression_target\n\ndf = pd.DataFrame({\n    'temperature': [20.1, 25.3, 18.7, 22.9],\n    'humidity': [45.2, 60.8, 38.1, 52.3]\n})\n\ntarget = generate_regression_target(df, 'temperature')\n</code></pre> Source code in <code>siapy/datasets/helpers.py</code> <pre><code>def generate_regression_target(\n    dataframe: pd.DataFrame,\n    column_name: str,\n) -&gt; \"RegressionTarget\":\n    \"\"\"Generate a regression target from a DataFrame column.\n\n    Creates a regression target from a single DataFrame column for use in\n    machine learning regression tasks.\n\n    Args:\n        dataframe: The input DataFrame containing the target data.\n        column_name: Name of the column to use for generating the regression target.\n\n    Returns:\n        A RegressionTarget object containing the column name and values.\n\n    Example:\n        ```python\n        import pandas as pd\n        from siapy.datasets.helpers import generate_regression_target\n\n        df = pd.DataFrame({\n            'temperature': [20.1, 25.3, 18.7, 22.9],\n            'humidity': [45.2, 60.8, 38.1, 52.3]\n        })\n\n        target = generate_regression_target(df, 'temperature')\n        ```\n    \"\"\"\n    from .schemas import (\n        RegressionTarget,\n    )  # Local import to avoid circular dependency\n\n    return RegressionTarget(name=column_name, value=dataframe[column_name])\n</code></pre>"},{"location":"api/datasets/helpers/#siapy.datasets.helpers.merge_signals_from_multiple_cameras","title":"merge_signals_from_multiple_cameras","text":"<pre><code>merge_signals_from_multiple_cameras(\n    data: TabularDatasetData,\n) -&gt; None\n</code></pre> <p>Merge signals from multiple cameras into a unified dataset.</p> <p>This function combines spectral or imaging data collected from multiple camera sources into a single coherent dataset structure. The implementation details depend on the specific camera configuration and data format requirements.</p> PARAMETER DESCRIPTION <code>data</code> <p>The tabular dataset data containing signals from multiple cameras that need to be merged.</p> <p> TYPE: <code>TabularDatasetData</code> </p> RETURNS DESCRIPTION <code>None</code> <p>The function modifies the input data in-place.</p> <p> TYPE: <code>None</code> </p> Note <p>This function is currently not implemented and serves as a placeholder for future development of multi-camera signal merging capabilities.</p> Todo <p>Implement the actual merging logic based on camera specifications and data alignment requirements.</p> Source code in <code>siapy/datasets/helpers.py</code> <pre><code>def merge_signals_from_multiple_cameras(data: \"TabularDatasetData\") -&gt; None:\n    \"\"\"Merge signals from multiple cameras into a unified dataset.\n\n    This function combines spectral or imaging data collected from multiple camera\n    sources into a single coherent dataset structure. The implementation details\n    depend on the specific camera configuration and data format requirements.\n\n    Args:\n        data: The tabular dataset data containing signals from multiple cameras\n            that need to be merged.\n\n    Returns:\n        None: The function modifies the input data in-place.\n\n    Note:\n        This function is currently not implemented and serves as a placeholder\n        for future development of multi-camera signal merging capabilities.\n\n    Todo:\n        Implement the actual merging logic based on camera specifications\n        and data alignment requirements.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/datasets/schemas/","title":"Schemas","text":""},{"location":"api/datasets/schemas/#siapy.datasets.schemas","title":"siapy.datasets.schemas","text":""},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target","title":"Target","text":"<p>               Bases: <code>BaseModel</code>, <code>ABC</code></p> <p>Abstract base class for machine learning target variables.</p> <p>This class defines the interface for target variables used in machine learning datasets, supporting both classification and regression targets.</p>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: Series\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.from_dict","title":"from_dict  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; Target\n</code></pre> <p>Create a Target instance from a dictionary.</p> PARAMETER DESCRIPTION <code>data</code> <p>Dictionary containing target data with appropriate keys.</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>Target</code> <p>New Target instance created from the dictionary data.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\n@abstractmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"Target\":\n    \"\"\"Create a Target instance from a dictionary.\n\n    Args:\n        data: Dictionary containing target data with appropriate keys.\n\n    Returns:\n        New Target instance created from the dictionary data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.from_iterable","title":"from_iterable  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>from_iterable(data: Iterable[Any]) -&gt; Target\n</code></pre> <p>Create a Target instance from an iterable of values.</p> PARAMETER DESCRIPTION <code>data</code> <p>Iterable containing target values.</p> <p> TYPE: <code>Iterable[Any]</code> </p> RETURNS DESCRIPTION <code>Target</code> <p>New Target instance created from the iterable data.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\n@abstractmethod\ndef from_iterable(cls, data: Iterable[Any]) -&gt; \"Target\":\n    \"\"\"Create a Target instance from an iterable of values.\n\n    Args:\n        data: Iterable containing target values.\n\n    Returns:\n        New Target instance created from the iterable data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.to_dict","title":"to_dict  <code>abstractmethod</code>","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert the target to a dictionary representation.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Dictionary containing the target data.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@abstractmethod\ndef to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the target to a dictionary representation.\n\n    Returns:\n        Dictionary containing the target data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.to_dataframe","title":"to_dataframe  <code>abstractmethod</code>","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Convert the target to a pandas DataFrame.</p> RETURNS DESCRIPTION <code>DataFrame</code> <p>DataFrame representation of the target data.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@abstractmethod\ndef to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the target to a pandas DataFrame.\n\n    Returns:\n        DataFrame representation of the target data.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.Target.reset_index","title":"reset_index  <code>abstractmethod</code>","text":"<pre><code>reset_index() -&gt; Target\n</code></pre> <p>Reset the index of all internal pandas objects to a default integer index.</p> RETURNS DESCRIPTION <code>Target</code> <p>New Target instance with reset indices.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@abstractmethod\ndef reset_index(self) -&gt; \"Target\":\n    \"\"\"Reset the index of all internal pandas objects to a default integer index.\n\n    Returns:\n        New Target instance with reset indices.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget","title":"ClassificationTarget","text":"<p>               Bases: <code>Target</code></p> <p>Target variable for classification tasks.</p> <p>Represents categorical target variables with string labels, numerical values, and optional encoding information for machine learning classification tasks.</p>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.label","title":"label  <code>instance-attribute</code>","text":"<pre><code>label: Series\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: Series\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.encoding","title":"encoding  <code>instance-attribute</code>","text":"<pre><code>encoding: Series\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.from_iterable","title":"from_iterable  <code>classmethod</code>","text":"<pre><code>from_iterable(data: Iterable[Any]) -&gt; ClassificationTarget\n</code></pre> <p>Create a ClassificationTarget from an iterable of labels.</p> <p>Automatically generates numerical values and encoding for the provided labels.</p> PARAMETER DESCRIPTION <code>data</code> <p>Iterable containing classification labels.</p> <p> TYPE: <code>Iterable[Any]</code> </p> RETURNS DESCRIPTION <code>ClassificationTarget</code> <p>New ClassificationTarget instance with generated values and encoding.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\ndef from_iterable(cls, data: Iterable[Any]) -&gt; \"ClassificationTarget\":\n    \"\"\"Create a ClassificationTarget from an iterable of labels.\n\n    Automatically generates numerical values and encoding for the provided labels.\n\n    Args:\n        data: Iterable containing classification labels.\n\n    Returns:\n        New ClassificationTarget instance with generated values and encoding.\n    \"\"\"\n    label = pd.DataFrame(data, columns=[\"label\"])\n    return generate_classification_target(label, \"label\")\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; ClassificationTarget\n</code></pre> <p>Create a ClassificationTarget from a dictionary.</p> PARAMETER DESCRIPTION <code>data</code> <p>Dictionary with keys 'label', 'value', and 'encoding'. - label: List of string labels  - value: List of numerical values corresponding to labels  - encoding: List of encoding information for labels</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>ClassificationTarget</code> <p>New ClassificationTarget instance created from the dictionary.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"ClassificationTarget\":\n    \"\"\"Create a ClassificationTarget from a dictionary.\n\n    Args:\n        data: Dictionary with keys 'label', 'value', and 'encoding'.&lt;br&gt;\n            - label: List of string labels &lt;br&gt;\n            - value: List of numerical values corresponding to labels &lt;br&gt;\n            - encoding: List of encoding information for labels\n\n    Returns:\n        New ClassificationTarget instance created from the dictionary.\n    \"\"\"\n    label = pd.Series(data[\"label\"], name=\"label\")\n    value = pd.Series(data[\"value\"], name=\"value\")\n    encoding = pd.Series(data[\"encoding\"], name=\"encoding\")\n    return cls(label=label, value=value, encoding=encoding)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert the classification target to a dictionary.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Dictionary with keys 'label', 'value', and 'encoding' containing list representations of the respective pandas Series.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the classification target to a dictionary.\n\n    Returns:\n        Dictionary with keys 'label', 'value', and 'encoding' containing list representations of the respective pandas Series.\n    \"\"\"\n    return {\n        \"label\": self.label.to_list(),\n        \"value\": self.value.to_list(),\n        \"encoding\": self.encoding.to_list(),\n    }\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Convert the classification target to a pandas DataFrame.</p> RETURNS DESCRIPTION <code>DataFrame</code> <p>DataFrame containing 'value' and 'label' columns. The encoding information is not included in the DataFrame representation.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the classification target to a pandas DataFrame.\n\n    Returns:\n        DataFrame containing 'value' and 'label' columns. The encoding information is not included in the DataFrame representation.\n    \"\"\"\n    return pd.concat([self.value, self.label], axis=1)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.ClassificationTarget.reset_index","title":"reset_index","text":"<pre><code>reset_index() -&gt; ClassificationTarget\n</code></pre> <p>Reset indices of label and value Series to default integer index.</p> RETURNS DESCRIPTION <code>ClassificationTarget</code> <p>New ClassificationTarget instance with reset indices for label and value. The encoding Series is preserved as-is since it represents the overall encoding scheme rather than instance-specific data.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def reset_index(self) -&gt; \"ClassificationTarget\":\n    \"\"\"Reset indices of label and value Series to default integer index.\n\n    Returns:\n        New ClassificationTarget instance with reset indices for label and value. The encoding Series is preserved as-is since it represents the overall encoding scheme rather than instance-specific data.\n    \"\"\"\n    return ClassificationTarget(\n        label=self.label.reset_index(drop=True),\n        value=self.value.reset_index(drop=True),\n        encoding=self.encoding,\n    )\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget","title":"RegressionTarget","text":"<p>               Bases: <code>Target</code></p> <p>Target variable for regression tasks.</p> <p>Represents continuous numerical target variables for machine learning regression tasks with an optional descriptive name.</p>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.value","title":"value  <code>instance-attribute</code>","text":"<pre><code>value: Series\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.name","title":"name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>name: str = 'value'\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.from_iterable","title":"from_iterable  <code>classmethod</code>","text":"<pre><code>from_iterable(data: Iterable[Any]) -&gt; RegressionTarget\n</code></pre> <p>Create a RegressionTarget from an iterable of numerical values.</p> PARAMETER DESCRIPTION <code>data</code> <p>Iterable containing numerical regression target values.</p> <p> TYPE: <code>Iterable[Any]</code> </p> RETURNS DESCRIPTION <code>RegressionTarget</code> <p>New RegressionTarget instance with default name \"value\".</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\ndef from_iterable(cls, data: Iterable[Any]) -&gt; \"RegressionTarget\":\n    \"\"\"Create a RegressionTarget from an iterable of numerical values.\n\n    Args:\n        data: Iterable containing numerical regression target values.\n\n    Returns:\n        New RegressionTarget instance with default name \"value\".\n    \"\"\"\n    value = pd.DataFrame(data, columns=[\"value\"])\n    return generate_regression_target(value, \"value\")\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; RegressionTarget\n</code></pre> <p>Create a RegressionTarget from a dictionary.</p> PARAMETER DESCRIPTION <code>data</code> <p>Dictionary with required key 'value' and optional key 'name'. - value: List of numerical target values  - name: Optional descriptive name for the target variable</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>RegressionTarget</code> <p>New RegressionTarget instance. Uses \"value\" as default name if not provided in the dictionary.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"RegressionTarget\":\n    \"\"\"Create a RegressionTarget from a dictionary.\n\n    Args:\n        data: Dictionary with required key 'value' and optional key 'name'.&lt;br&gt;\n            - value: List of numerical target values &lt;br&gt;\n            - name: Optional descriptive name for the target variable\n\n    Returns:\n        New RegressionTarget instance. Uses \"value\" as default name if not provided in the dictionary.\n    \"\"\"\n    value = pd.Series(data[\"value\"], name=\"value\")\n    name = data[\"name\"] if \"name\" in data else \"value\"\n    return cls(value=value, name=name)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert the regression target to a dictionary.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Dictionary with keys 'value' and 'name' containing the list representation of values and the descriptive name.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the regression target to a dictionary.\n\n    Returns:\n        Dictionary with keys 'value' and 'name' containing the list representation of values and the descriptive name.\n    \"\"\"\n    return {\n        \"value\": self.value.to_list(),\n        \"name\": self.name,\n    }\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Convert the regression target to a pandas DataFrame.</p> RETURNS DESCRIPTION <code>DataFrame</code> <p>DataFrame containing a single column with the target values. The column name corresponds to the Series name, not the target name.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the regression target to a pandas DataFrame.\n\n    Returns:\n        DataFrame containing a single column with the target values. The column name corresponds to the Series name, not the target name.\n    \"\"\"\n    return pd.DataFrame(self.value)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.RegressionTarget.reset_index","title":"reset_index","text":"<pre><code>reset_index() -&gt; RegressionTarget\n</code></pre> <p>Reset the index of the value Series to a default integer index.</p> RETURNS DESCRIPTION <code>RegressionTarget</code> <p>New RegressionTarget instance with reset index for the value Series. The name is preserved.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def reset_index(self) -&gt; \"RegressionTarget\":\n    \"\"\"Reset the index of the value Series to a default integer index.\n\n    Returns:\n        New RegressionTarget instance with reset index for the value Series. The name is preserved.\n    \"\"\"\n    return RegressionTarget(value=self.value.reset_index(drop=True), name=self.name)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData","title":"TabularDatasetData  <code>dataclass</code>","text":"<pre><code>TabularDatasetData(\n    signatures: Signatures,\n    metadata: DataFrame,\n    target: Target | None = None,\n)\n</code></pre> <p>Container for tabular machine learning dataset components.</p> <p>Combines spectral signatures, metadata, and optional target variables into a unified dataset structure for machine learning workflows. Ensures data consistency through length validation and provides various data access patterns.</p>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.signatures","title":"signatures  <code>instance-attribute</code>","text":"<pre><code>signatures: Signatures\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.metadata","title":"metadata  <code>instance-attribute</code>","text":"<pre><code>metadata: DataFrame\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.target","title":"target  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>target: Target | None = None\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; TabularDatasetData\n</code></pre> <p>Create a TabularDatasetData instance from a dictionary.</p> PARAMETER DESCRIPTION <code>data</code> <p>Dictionary containing dataset components with keys:  - pixels: Dictionary for pixel data  - signals: Dictionary for signal data  - metadata: Dictionary for metadata  - target: Optional dictionary for target data</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>TabularDatasetData</code> <p>New TabularDatasetData instance created from the dictionary data.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"TabularDatasetData\":\n    \"\"\"Create a TabularDatasetData instance from a dictionary.\n\n    Args:\n        data: Dictionary containing dataset components with keys: &lt;br&gt;\n            - pixels: Dictionary for pixel data &lt;br&gt;\n            - signals: Dictionary for signal data &lt;br&gt;\n            - metadata: Dictionary for metadata &lt;br&gt;\n            - target: Optional dictionary for target data\n\n    Returns:\n        New TabularDatasetData instance created from the dictionary data.\n    \"\"\"\n    signatures = Signatures.from_dict({\"pixels\": data[\"pixels\"], \"signals\": data[\"signals\"]})\n    metadata = pd.DataFrame(data[\"metadata\"])\n    target = TabularDatasetData.target_from_dict(data.get(\"target\", None))\n    return cls(signatures=signatures, metadata=metadata, target=target)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.target_from_dict","title":"target_from_dict  <code>staticmethod</code>","text":"<pre><code>target_from_dict(\n    data: dict[str, Any] | None = None,\n) -&gt; Optional[Target]\n</code></pre> <p>Create an appropriate Target instance from a dictionary.</p> <p>Automatically determines whether to create a ClassificationTarget or RegressionTarget based on the keys present in the data dictionary.</p> PARAMETER DESCRIPTION <code>data</code> <p>Optional dictionary containing target data. If None, returns None.  Keys determine the target type:  - Classification: Requires keys compatible with ClassificationTarget  - Regression: Requires keys compatible with RegressionTarget </p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Optional[Target]</code> <p>ClassificationTarget, RegressionTarget, or None based on input data.</p> RAISES DESCRIPTION <code>InvalidInputError</code> <p>If the dictionary keys don't match any known target type.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>@staticmethod\ndef target_from_dict(data: dict[str, Any] | None = None) -&gt; Optional[Target]:\n    \"\"\"Create an appropriate Target instance from a dictionary.\n\n    Automatically determines whether to create a ClassificationTarget or\n    RegressionTarget based on the keys present in the data dictionary.\n\n    Args:\n        data: Optional dictionary containing target data. If None, returns None. &lt;br&gt;\n            Keys determine the target type: &lt;br&gt;\n            - Classification: Requires keys compatible with ClassificationTarget &lt;br&gt;\n            - Regression: Requires keys compatible with RegressionTarget &lt;br&gt;\n\n    Returns:\n        ClassificationTarget, RegressionTarget, or None based on input data.\n\n    Raises:\n        InvalidInputError: If the dictionary keys don't match any known target type.\n    \"\"\"\n    if data is None:\n        return None\n\n    regression_keys = set(RegressionTarget.model_fields.keys())\n    classification_keys = set(ClassificationTarget.model_fields.keys())\n    data_keys = set(data.keys())\n\n    if data_keys.issubset(regression_keys):\n        return RegressionTarget.from_dict(data)\n    elif data_keys.issubset(classification_keys):\n        return ClassificationTarget.from_dict(data)\n    else:\n        raise InvalidInputError(data, \"Invalid target dict.\")\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.set_attributes","title":"set_attributes","text":"<pre><code>set_attributes(\n    *,\n    signatures: Signatures | None = None,\n    metadata: DataFrame | None = None,\n    target: Target | None = None,\n) -&gt; TabularDatasetData\n</code></pre> <p>Create a new dataset with updated attributes.</p> <p>Creates a copy of the current dataset with specified attributes replaced. Unspecified attributes are copied from the current dataset.</p> PARAMETER DESCRIPTION <code>signatures</code> <p>Optional new Signatures to replace current signatures.</p> <p> TYPE: <code>Signatures | None</code> DEFAULT: <code>None</code> </p> <code>metadata</code> <p>Optional new DataFrame to replace current metadata.</p> <p> TYPE: <code>DataFrame | None</code> DEFAULT: <code>None</code> </p> <code>target</code> <p>Optional new Target to replace current target.</p> <p> TYPE: <code>Target | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>TabularDatasetData</code> <p>New TabularDatasetData instance with updated attributes.</p> Note <p>The returned dataset will be validated for length consistency.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def set_attributes(\n    self,\n    *,\n    signatures: Signatures | None = None,\n    metadata: pd.DataFrame | None = None,\n    target: Target | None = None,\n) -&gt; \"TabularDatasetData\":\n    \"\"\"Create a new dataset with updated attributes.\n\n    Creates a copy of the current dataset with specified attributes replaced.\n    Unspecified attributes are copied from the current dataset.\n\n    Args:\n        signatures: Optional new Signatures to replace current signatures.\n        metadata: Optional new DataFrame to replace current metadata.\n        target: Optional new Target to replace current target.\n\n    Returns:\n        New TabularDatasetData instance with updated attributes.\n\n    Note:\n        The returned dataset will be validated for length consistency.\n    \"\"\"\n    current_data = self.copy()\n    signatures = signatures if signatures is not None else current_data.signatures\n    metadata = metadata if metadata is not None else current_data.metadata\n    target = target if target is not None else current_data.target\n    return TabularDatasetData(signatures=signatures, metadata=metadata, target=target)\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> <p>Convert the dataset to a dictionary representation.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>Dictionary with keys 'pixels', 'signals', 'metadata', and 'target'. The target key contains None if no target is present.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert the dataset to a dictionary representation.\n\n    Returns:\n        Dictionary with keys 'pixels', 'signals', 'metadata', and 'target'. The target key contains None if no target is present.\n    \"\"\"\n    signatures_dict = self.signatures.to_dict()\n    return {\n        \"pixels\": signatures_dict[\"pixels\"],\n        \"signals\": signatures_dict[\"signals\"],\n        \"metadata\": self.metadata.to_dict(),\n        \"target\": self.target.to_dict() if self.target is not None else None,\n    }\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Convert the dataset to a single pandas DataFrame.</p> <p>Combines signatures, metadata, and target (if present) into a single DataFrame with all columns at the same level.</p> RETURNS DESCRIPTION <code>DataFrame</code> <p>DataFrame containing all dataset components as columns.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the dataset to a single pandas DataFrame.\n\n    Combines signatures, metadata, and target (if present) into a single\n    DataFrame with all columns at the same level.\n\n    Returns:\n        DataFrame containing all dataset components as columns.\n    \"\"\"\n    combined_df = pd.concat([self.signatures.to_dataframe(), self.metadata], axis=1)\n    if self.target is not None:\n        target_series = self.target.to_dataframe()\n        combined_df = pd.concat([combined_df, target_series], axis=1)\n    return combined_df\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.to_dataframe_multiindex","title":"to_dataframe_multiindex","text":"<pre><code>to_dataframe_multiindex() -&gt; DataFrame\n</code></pre> <p>Convert the dataset to a pandas DataFrame with MultiIndex columns.</p> <p>Creates a DataFrame where columns are organized hierarchically by category (pixel, signal, metadata, target) and field names within each category.</p> RETURNS DESCRIPTION <code>DataFrame</code> <p>DataFrame with MultiIndex columns having levels ['category', 'field'].</p> RAISES DESCRIPTION <code>InvalidInputError</code> <p>If target type is not ClassificationTarget or RegressionTarget.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def to_dataframe_multiindex(self) -&gt; pd.DataFrame:\n    \"\"\"Convert the dataset to a pandas DataFrame with MultiIndex columns.\n\n    Creates a DataFrame where columns are organized hierarchically by category\n    (pixel, signal, metadata, target) and field names within each category.\n\n    Returns:\n        DataFrame with MultiIndex columns having levels ['category', 'field'].\n\n    Raises:\n        InvalidInputError: If target type is not ClassificationTarget or RegressionTarget.\n    \"\"\"\n    signatures_df = self.signatures.to_dataframe_multiindex()\n\n    metadata_columns = pd.MultiIndex.from_tuples(\n        [(\"metadata\", col) for col in self.metadata.columns], names=[\"category\", \"field\"]\n    )\n    metadata_df = pd.DataFrame(self.metadata.values, columns=metadata_columns)\n\n    combined_df = pd.concat([signatures_df, metadata_df], axis=1)\n\n    if self.target is not None:\n        target_df = self.target.to_dataframe()\n        if isinstance(self.target, ClassificationTarget):\n            target_columns = pd.MultiIndex.from_tuples(\n                [(\"target\", col) for col in target_df.columns],\n                names=[\"category\", \"field\"],\n            )\n        elif isinstance(self.target, RegressionTarget):\n            target_columns = pd.MultiIndex.from_tuples(\n                [(\"target\", self.target.name)],\n                names=[\"category\", \"field\"],\n            )\n        else:\n            raise InvalidInputError(\n                self.target,\n                \"Invalid target type. Expected ClassificationTarget or RegressionTarget.\",\n            )\n        target_df = pd.DataFrame(target_df.values, columns=target_columns)\n        combined_df = pd.concat([combined_df, target_df], axis=1)\n\n    return combined_df\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.reset_index","title":"reset_index","text":"<pre><code>reset_index() -&gt; TabularDatasetData\n</code></pre> <p>Reset indices of all dataset components to default integer indices.</p> <p>Creates a new dataset with all pandas objects having their indices reset to consecutive integers starting from 0.</p> RETURNS DESCRIPTION <code>TabularDatasetData</code> <p>New TabularDatasetData instance with reset indices for all components.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def reset_index(self) -&gt; \"TabularDatasetData\":\n    \"\"\"Reset indices of all dataset components to default integer indices.\n\n    Creates a new dataset with all pandas objects having their indices\n    reset to consecutive integers starting from 0.\n\n    Returns:\n        New TabularDatasetData instance with reset indices for all components.\n    \"\"\"\n    return TabularDatasetData(\n        signatures=self.signatures.reset_index(),\n        metadata=self.metadata.reset_index(drop=True),\n        target=self.target.reset_index() if self.target is not None else None,\n    )\n</code></pre>"},{"location":"api/datasets/schemas/#siapy.datasets.schemas.TabularDatasetData.copy","title":"copy","text":"<pre><code>copy() -&gt; TabularDatasetData\n</code></pre> <p>Create a deep copy of the dataset.</p> <p>Creates a new TabularDatasetData instance with copied versions of all components, ensuring that modifications to the copy don't affect the original.</p> RETURNS DESCRIPTION <code>TabularDatasetData</code> <p>New TabularDatasetData instance that is a deep copy of the current dataset.</p> Source code in <code>siapy/datasets/schemas.py</code> <pre><code>def copy(self) -&gt; \"TabularDatasetData\":\n    \"\"\"Create a deep copy of the dataset.\n\n    Creates a new TabularDatasetData instance with copied versions of all\n    components, ensuring that modifications to the copy don't affect the original.\n\n    Returns:\n        New TabularDatasetData instance that is a deep copy of the current dataset.\n    \"\"\"\n    return TabularDatasetData(\n        signatures=self.signatures.copy(),\n        metadata=self.metadata.copy(),\n        target=self.target.model_copy() if self.target is not None else None,\n    )\n</code></pre>"},{"location":"api/datasets/tabular/","title":"Tabular","text":""},{"location":"api/datasets/tabular/#siapy.datasets.tabular","title":"siapy.datasets.tabular","text":""},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity","title":"MetaDataEntity","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.image_idx","title":"image_idx  <code>instance-attribute</code>","text":"<pre><code>image_idx: int\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.image_filepath","title":"image_filepath  <code>instance-attribute</code>","text":"<pre><code>image_filepath: Path\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.camera_id","title":"camera_id  <code>instance-attribute</code>","text":"<pre><code>camera_id: str\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.shape_idx","title":"shape_idx  <code>instance-attribute</code>","text":"<pre><code>shape_idx: int\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.shape_type","title":"shape_type  <code>instance-attribute</code>","text":"<pre><code>shape_type: str\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.shape_label","title":"shape_label  <code>instance-attribute</code>","text":"<pre><code>shape_label: str | None\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.MetaDataEntity.geometry_idx","title":"geometry_idx  <code>instance-attribute</code>","text":"<pre><code>geometry_idx: int\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity","title":"TabularDataEntity","text":"<p>               Bases: <code>MetaDataEntity</code></p>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.signatures","title":"signatures  <code>instance-attribute</code>","text":"<pre><code>signatures: Signatures\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.image_idx","title":"image_idx  <code>instance-attribute</code>","text":"<pre><code>image_idx: int\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.image_filepath","title":"image_filepath  <code>instance-attribute</code>","text":"<pre><code>image_filepath: Path\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.camera_id","title":"camera_id  <code>instance-attribute</code>","text":"<pre><code>camera_id: str\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.shape_idx","title":"shape_idx  <code>instance-attribute</code>","text":"<pre><code>shape_idx: int\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.shape_type","title":"shape_type  <code>instance-attribute</code>","text":"<pre><code>shape_type: str\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.shape_label","title":"shape_label  <code>instance-attribute</code>","text":"<pre><code>shape_label: str | None\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataEntity.geometry_idx","title":"geometry_idx  <code>instance-attribute</code>","text":"<pre><code>geometry_idx: int\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataset","title":"TabularDataset  <code>dataclass</code>","text":"<pre><code>TabularDataset(container: ImageContainerType)\n</code></pre> <p>Creates a tabular dataset that can extract and organize spectral signatures from geometric shapes within spectral images for analysis and modeling.</p> PARAMETER DESCRIPTION <code>container</code> <p>Either a single SpectralImage or a SpectralImageSet containing multiple spectral images to process.</p> <p> TYPE: <code>ImageContainerType</code> </p> Example <pre><code>from siapy.entities import SpectralImage\nfrom siapy.datasets import TabularDataset\n\n# With a single image\nimage = SpectralImage.open_rasterio(\"path/to/image.tif\")\ndataset = TabularDataset(image)\n\n# With multiple images\nimage_set = SpectralImageSet([image1, image2])\ndataset = TabularDataset(image_set)\n</code></pre> Source code in <code>siapy/datasets/tabular.py</code> <pre><code>def __init__(self, container: ImageContainerType):\n    \"\"\"Initialize a TabularDataset from spectral image data.\n\n    Creates a tabular dataset that can extract and organize spectral signatures\n    from geometric shapes within spectral images for analysis and modeling.\n\n    Args:\n        container: Either a single SpectralImage or a SpectralImageSet containing\n            multiple spectral images to process.\n\n    Example:\n        ```python\n        from siapy.entities import SpectralImage\n        from siapy.datasets import TabularDataset\n\n        # With a single image\n        image = SpectralImage.open_rasterio(\"path/to/image.tif\")\n        dataset = TabularDataset(image)\n\n        # With multiple images\n        image_set = SpectralImageSet([image1, image2])\n        dataset = TabularDataset(image_set)\n        ```\n    \"\"\"\n    self._image_set = SpectralImageSet([container]) if isinstance(container, SpectralImage) else container\n    self._data_entities: list[TabularDataEntity] = []\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataset.image_set","title":"image_set  <code>property</code>","text":"<pre><code>image_set: SpectralImageSet\n</code></pre> <p>Get the spectral image set being processed.</p> RETURNS DESCRIPTION <code>SpectralImageSet</code> <p>The SpectralImageSet containing all spectral images in this dataset.</p> Note <p>This is the original image set provided during initialization, possibly converted from a single SpectralImage.</p>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataset.data_entities","title":"data_entities  <code>property</code>","text":"<pre><code>data_entities: list[TabularDataEntity]\n</code></pre> <p>Get all processed data entities.</p> RETURNS DESCRIPTION <code>list[TabularDataEntity]</code> <p>A list of TabularDataEntity objects, each containing spectral signatures and metadata for a geometric shape instance within the image set.</p> Note <p>This list will be empty until <code>process_image_data()</code> is called. Each entity represents signatures extracted from one geometric shape in one image.</p>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataset.process_image_data","title":"process_image_data","text":"<pre><code>process_image_data() -&gt; None\n</code></pre> <p>Extract spectral signatures from geometric shapes in all images.</p> <p>Processes each image in the image set, extracting spectral signatures from within the convex hull of each geometric shape. Creates TabularDataEntity objects containing the signatures along with associated metadata.</p> Side Effects <ul> <li>Clears any existing data entities</li> <li>Populates the <code>data_entities</code> list with new TabularDataEntity objects</li> <li>Each geometric shape may produce multiple entities if signatures   are organized into multiple groups</li> </ul> Note <p>This method must be called before accessing data entities through iteration, indexing, or <code>generate_dataset_data()</code>.</p> Example <pre><code>dataset = TabularDataset(image_set)\ndataset.process_image_data()\nprint(f\"Processed {len(dataset)} data entities\")\n</code></pre> Source code in <code>siapy/datasets/tabular.py</code> <pre><code>def process_image_data(self) -&gt; None:\n    \"\"\"Extract spectral signatures from geometric shapes in all images.\n\n    Processes each image in the image set, extracting spectral signatures from\n    within the convex hull of each geometric shape. Creates TabularDataEntity\n    objects containing the signatures along with associated metadata.\n\n    Side Effects:\n        - Clears any existing data entities\n        - Populates the `data_entities` list with new TabularDataEntity objects\n        - Each geometric shape may produce multiple entities if signatures\n          are organized into multiple groups\n\n    Note:\n        This method must be called before accessing data entities through\n        iteration, indexing, or `generate_dataset_data()`.\n\n    Example:\n        ```python\n        dataset = TabularDataset(image_set)\n        dataset.process_image_data()\n        print(f\"Processed {len(dataset)} data entities\")\n        ```\n    \"\"\"\n    self.data_entities.clear()\n    for image_idx, image in enumerate(self.image_set):\n        for shape_idx, shape in enumerate(image.geometric_shapes.shapes):\n            signatures_hull = get_signatures_within_convex_hull(image, shape)\n            for geometry_idx, signatures in enumerate(signatures_hull):\n                entity = TabularDataEntity(\n                    image_idx=image_idx,\n                    shape_idx=shape_idx,\n                    geometry_idx=geometry_idx,\n                    image_filepath=image.filepath,\n                    camera_id=image.camera_id,\n                    shape_type=shape.shape_type,\n                    shape_label=shape.label,\n                    signatures=signatures,\n                )\n                self.data_entities.append(entity)\n</code></pre>"},{"location":"api/datasets/tabular/#siapy.datasets.tabular.TabularDataset.generate_dataset_data","title":"generate_dataset_data","text":"<pre><code>generate_dataset_data(\n    mean_signatures: bool = True,\n) -&gt; TabularDatasetData\n</code></pre> <p>Generate structured dataset data for analysis or export.</p> <p>Combines all spectral signatures and metadata from processed data entities into a unified TabularDatasetData structure suitable for machine learning or statistical analysis.</p> PARAMETER DESCRIPTION <code>mean_signatures</code> <p>If True, compute the mean of all signatures within each data entity. If False, include all individual signature measurements. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>TabularDatasetData</code> <p>A TabularDatasetData object containing:  - signatures: Combined Signatures object with spectral data  - metadata: DataFrame with image and shape metadata for each signature  - (optional) Target values if available in the data entities.</p> RAISES DESCRIPTION <code>InvalidInputError</code> <p>If no data entities exist (image data hasn't been processed yet).</p> Note <p>The metadata DataFrame columns correspond to MetaDataEntity fields: image_idx, image_filepath, camera_id, shape_idx, shape_type, shape_label, geometry_idx.</p> Example <pre><code>dataset.process_image_data()\n\n# Get averaged signatures per shape\ndata = dataset.generate_dataset_data(mean_signatures=True)\n\n# Get all individual signature measurements\ndata_detailed = dataset.generate_dataset_data(mean_signatures=False)\n\nprint(f\"Signatures shape: {data.signatures.to_numpy().shape}\")\nprint(f\"Metadata shape: {data.metadata.shape}\")\n</code></pre> Source code in <code>siapy/datasets/tabular.py</code> <pre><code>def generate_dataset_data(self, mean_signatures: bool = True) -&gt; TabularDatasetData:\n    \"\"\"Generate structured dataset data for analysis or export.\n\n    Combines all spectral signatures and metadata from processed data entities\n    into a unified TabularDatasetData structure suitable for machine learning\n    or statistical analysis.\n\n    Args:\n        mean_signatures: If True, compute the mean of all signatures within each\n            data entity. If False, include all individual signature measurements.\n            Defaults to True.\n\n    Returns:\n        A TabularDatasetData object containing: &lt;br&gt;\n            - signatures: Combined Signatures object with spectral data &lt;br&gt;\n            - metadata: DataFrame with image and shape metadata for each signature &lt;br&gt;\n            - (optional) Target values if available in the data entities.\n\n    Raises:\n        InvalidInputError: If no data entities exist (image data hasn't been\n            processed yet).\n\n    Note:\n        The metadata DataFrame columns correspond to MetaDataEntity fields:\n        image_idx, image_filepath, camera_id, shape_idx, shape_type,\n        shape_label, geometry_idx.\n\n    Example:\n        ```python\n        dataset.process_image_data()\n\n        # Get averaged signatures per shape\n        data = dataset.generate_dataset_data(mean_signatures=True)\n\n        # Get all individual signature measurements\n        data_detailed = dataset.generate_dataset_data(mean_signatures=False)\n\n        print(f\"Signatures shape: {data.signatures.to_numpy().shape}\")\n        print(f\"Metadata shape: {data.metadata.shape}\")\n        ```\n    \"\"\"\n    self._check_data_entities()\n    signatures_dfs = []\n    metadata_dfs = []\n    for entity in self.data_entities:\n        signatures_df = entity.signatures.to_dataframe().dropna()\n        if mean_signatures:\n            signatures_df = signatures_df.mean().to_frame().T\n\n        signatures_len = len(signatures_df)\n        metadata_df = pd.DataFrame(\n            {\n                \"image_idx\": [str(entity.image_idx)] * signatures_len,\n                \"image_filepath\": [str(entity.image_filepath)] * signatures_len,\n                \"camera_id\": [entity.camera_id] * signatures_len,\n                \"shape_idx\": [str(entity.shape_idx)] * signatures_len,\n                \"shape_type\": [entity.shape_type] * signatures_len,\n                \"shape_label\": [entity.shape_label] * signatures_len,\n                \"geometry_idx\": [str(entity.geometry_idx)] * signatures_len,\n            }\n        )\n\n        assert list(metadata_df.columns) == list(MetaDataEntity.model_fields.keys()), (\n            \"Sanity check failed! The columns in metadata_df do not match MetaDataEntity fields.\"\n        )\n\n        signatures_dfs.append(signatures_df)\n        metadata_dfs.append(metadata_df)\n\n    signatures_concat = pd.concat(signatures_dfs, ignore_index=True)\n    metadata_concat = pd.concat(metadata_dfs, ignore_index=True)\n    signatures = Signatures.from_dataframe(signatures_concat)\n    return TabularDatasetData(signatures=signatures, metadata=metadata_concat)\n</code></pre>"},{"location":"api/entities/imagesets/","title":"Image Sets","text":""},{"location":"api/entities/imagesets/#siapy.entities.imagesets","title":"siapy.entities.imagesets","text":""},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet","title":"SpectralImageSet  <code>dataclass</code>","text":"<pre><code>SpectralImageSet(\n    spectral_images: list[SpectralImage[Any]] | None = None,\n)\n</code></pre> Source code in <code>siapy/entities/imagesets.py</code> <pre><code>def __init__(self, spectral_images: list[SpectralImage[Any]] | None = None):\n    self._images = spectral_images if spectral_images is not None else []\n</code></pre>"},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet.images","title":"images  <code>property</code>","text":"<pre><code>images: list[SpectralImage[Any]]\n</code></pre>"},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet.cameras_id","title":"cameras_id  <code>property</code>","text":"<pre><code>cameras_id: list[str]\n</code></pre>"},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet.spy_open","title":"spy_open  <code>classmethod</code>","text":"<pre><code>spy_open(\n    *,\n    header_paths: Sequence[str | Path],\n    image_paths: Sequence[str | Path] | None = None,\n) -&gt; SpectralImageSet\n</code></pre> Source code in <code>siapy/entities/imagesets.py</code> <pre><code>@classmethod\ndef spy_open(\n    cls,\n    *,\n    header_paths: Sequence[str | Path],\n    image_paths: Sequence[str | Path] | None = None,\n) -&gt; \"SpectralImageSet\":\n    if image_paths is not None and len(header_paths) != len(image_paths):\n        raise InvalidInputError(\n            {\n                \"header_paths_length\": len(header_paths),\n                \"image_paths_length\": len(image_paths),\n            },\n            \"The length of hdr_paths and img_path must be equal.\",\n        )\n\n    if image_paths is None:\n        spectral_images = [\n            SpectralImage.spy_open(header_path=hdr_path)\n            for hdr_path in track(header_paths, description=\"Loading spectral images...\")\n        ]\n    else:\n        spectral_images = [\n            SpectralImage.spy_open(header_path=hdr_path, image_path=img_path)\n            for hdr_path, img_path in track(\n                zip(header_paths, image_paths),\n                description=\"Loading spectral images...\",\n            )\n        ]\n    logger.info(\"Spectral images loaded into memory.\")\n    return cls(spectral_images)\n</code></pre>"},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet.rasterio_open","title":"rasterio_open  <code>classmethod</code>","text":"<pre><code>rasterio_open(\n    *, filepaths: Sequence[str | Path]\n) -&gt; SpectralImageSet\n</code></pre> Source code in <code>siapy/entities/imagesets.py</code> <pre><code>@classmethod\ndef rasterio_open(\n    cls,\n    *,\n    filepaths: Sequence[str | Path],\n) -&gt; \"SpectralImageSet\":\n    spectral_images = [\n        SpectralImage.rasterio_open(filepath)\n        for filepath in track(filepaths, description=\"Loading raster images...\")\n    ]\n    logger.info(\"Raster images loaded into memory.\")\n    return cls(spectral_images)\n</code></pre>"},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet.images_by_camera_id","title":"images_by_camera_id","text":"<pre><code>images_by_camera_id(\n    camera_id: str,\n) -&gt; list[SpectralImage[Any]]\n</code></pre> Source code in <code>siapy/entities/imagesets.py</code> <pre><code>def images_by_camera_id(self, camera_id: str) -&gt; list[SpectralImage[Any]]:\n    ids = np.array([image.camera_id for image in self.images])\n    indices = np.nonzero(ids == camera_id)[0]\n    return [image for idx, image in enumerate(self.images) if idx in indices]\n</code></pre>"},{"location":"api/entities/imagesets/#siapy.entities.imagesets.SpectralImageSet.sort","title":"sort","text":"<pre><code>sort(key: Any = None, reverse: bool = False) -&gt; None\n</code></pre> Source code in <code>siapy/entities/imagesets.py</code> <pre><code>def sort(self, key: Any = None, reverse: bool = False) -&gt; None:\n    self.images.sort(key=key, reverse=reverse)\n</code></pre>"},{"location":"api/entities/pixels/","title":"Pixels","text":""},{"location":"api/entities/pixels/#siapy.entities.pixels","title":"siapy.entities.pixels","text":""},{"location":"api/entities/pixels/#siapy.entities.pixels.CoordinateInput","title":"CoordinateInput  <code>module-attribute</code>","text":"<pre><code>CoordinateInput: TypeAlias = (\n    PixelCoordinate | tuple[float, float] | Sequence[float]\n)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.HomogeneousCoordinate","title":"HomogeneousCoordinate  <code>dataclass</code>","text":"<pre><code>HomogeneousCoordinate(\n    X: str = \"x\", Y: str = \"y\", H: str = \"h\"\n)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.HomogeneousCoordinate.X","title":"X  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>X: str = 'x'\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.HomogeneousCoordinate.Y","title":"Y  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>Y: str = 'y'\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.HomogeneousCoordinate.H","title":"H  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>H: str = 'h'\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.PixelCoordinate","title":"PixelCoordinate","text":"<p>               Bases: <code>NamedTuple</code></p>"},{"location":"api/entities/pixels/#siapy.entities.pixels.PixelCoordinate.x","title":"x  <code>instance-attribute</code>","text":"<pre><code>x: float\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.PixelCoordinate.y","title":"y  <code>instance-attribute</code>","text":"<pre><code>y: float\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels","title":"Pixels  <code>dataclass</code>","text":"<pre><code>Pixels(_data: DataFrame)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.coords","title":"coords  <code>class-attribute</code>","text":"<pre><code>coords: HomogeneousCoordinate = HomogeneousCoordinate()\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.df","title":"df  <code>property</code>","text":"<pre><code>df: DataFrame\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.from_iterable","title":"from_iterable  <code>classmethod</code>","text":"<pre><code>from_iterable(\n    iterable: Iterable[CoordinateInput],\n) -&gt; \"Pixels\"\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>@classmethod\ndef from_iterable(cls, iterable: Iterable[CoordinateInput]) -&gt; \"Pixels\":\n    df = pd.DataFrame(iterable, columns=[cls.coords.X, cls.coords.Y])\n    validate_pixel_input_dimensions(df)\n    return cls(df)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.load_from_parquet","title":"load_from_parquet  <code>classmethod</code>","text":"<pre><code>load_from_parquet(filepath: str | Path) -&gt; 'Pixels'\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>@classmethod\ndef load_from_parquet(cls, filepath: str | Path) -&gt; \"Pixels\":\n    df = pd.read_parquet(filepath)\n    validate_pixel_input_dimensions(df)\n    return cls(df)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.df_homogenious","title":"df_homogenious","text":"<pre><code>df_homogenious() -&gt; DataFrame\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def df_homogenious(self) -&gt; pd.DataFrame:\n    df_homo = self.df.copy()\n    df_homo[self.coords.H] = 1\n    return df_homo\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.x","title":"x","text":"<pre><code>x() -&gt; 'pd.Series[float]'\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def x(self) -&gt; \"pd.Series[float]\":\n    return self.df[self.coords.X]\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.y","title":"y","text":"<pre><code>y() -&gt; 'pd.Series[float]'\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def y(self) -&gt; \"pd.Series[float]\":\n    return self.df[self.coords.Y]\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy() -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def to_numpy(self) -&gt; NDArray[np.floating[Any]]:\n    return self.df.to_numpy()\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.to_list","title":"to_list","text":"<pre><code>to_list() -&gt; list[PixelCoordinate]\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def to_list(self) -&gt; list[PixelCoordinate]:\n    return self.df.values.tolist()\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.save_to_parquet","title":"save_to_parquet","text":"<pre><code>save_to_parquet(filepath: str | Path) -&gt; None\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def save_to_parquet(self, filepath: str | Path) -&gt; None:\n    self.df.to_parquet(filepath, index=True)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.as_type","title":"as_type","text":"<pre><code>as_type(dtype: type) -&gt; 'Pixels'\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def as_type(self, dtype: type) -&gt; \"Pixels\":\n    converted_df = self.df.copy()\n    converted_df[self.coords.X] = converted_df[self.coords.X].astype(dtype)\n    converted_df[self.coords.Y] = converted_df[self.coords.Y].astype(dtype)\n    return Pixels(converted_df)\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.Pixels.get_coordinate","title":"get_coordinate","text":"<pre><code>get_coordinate(idx: int) -&gt; PixelCoordinate\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def get_coordinate(self, idx: int) -&gt; PixelCoordinate:\n    row = self.df.iloc[idx]\n    return PixelCoordinate(x=row[self.coords.X], y=row[self.coords.Y])\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.validate_pixel_input_dimensions","title":"validate_pixel_input_dimensions","text":"<pre><code>validate_pixel_input_dimensions(\n    df: DataFrame | Series,\n) -&gt; None\n</code></pre> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def validate_pixel_input_dimensions(df: pd.DataFrame | pd.Series) -&gt; None:\n    if isinstance(df, pd.Series):\n        raise InvalidTypeError(\n            input_value=df,\n            allowed_types=pd.DataFrame,\n            message=\"Expected a DataFrame, but got a Series.\",\n        )\n\n    if df.empty:\n        raise InvalidInputError(\n            message=\"Input DataFrame is empty.\",\n            input_value=df,\n        )\n\n    if df.shape[1] != 2:\n        raise InvalidInputError(\n            message=\"Invalid input dimensions: expected 2 columns (x, y), got\",\n            input_value=df.shape[1],\n        )\n\n    if sorted(df.columns) != sorted([HomogeneousCoordinate.X, HomogeneousCoordinate.Y]):\n        raise InvalidInputError(\n            message=f\"Invalid column names: expected ['{HomogeneousCoordinate.X}', '{HomogeneousCoordinate.Y}'], got\",\n            input_value=sorted(df.columns),\n        )\n</code></pre>"},{"location":"api/entities/pixels/#siapy.entities.pixels.validate_pixel_input","title":"validate_pixel_input","text":"<pre><code>validate_pixel_input(\n    input_data: Pixels\n    | DataFrame\n    | Iterable[CoordinateInput],\n) -&gt; Pixels\n</code></pre> <p>Validates and converts various input types to Pixels object.</p> Source code in <code>siapy/entities/pixels.py</code> <pre><code>def validate_pixel_input(input_data: Pixels | pd.DataFrame | Iterable[CoordinateInput]) -&gt; Pixels:\n    \"\"\"Validates and converts various input types to Pixels object.\"\"\"\n    try:\n        if isinstance(input_data, Pixels):\n            return input_data\n\n        if isinstance(input_data, pd.DataFrame):\n            validate_pixel_input_dimensions(input_data)\n            return Pixels(input_data)\n\n        if isinstance(input_data, np.ndarray):\n            if input_data.ndim != 2 or input_data.shape[1] != 2:\n                raise InvalidInputError(\n                    input_value=input_data.shape,\n                    message=f\"NumPy array must be 2D with shape (n, 2), got shape {input_data.shape}\",\n                )\n            return Pixels(pd.DataFrame(input_data, columns=[HomogeneousCoordinate.X, HomogeneousCoordinate.Y]))\n\n        if isinstance(input_data, Iterable):\n            return Pixels.from_iterable(input_data)  # type: ignore\n\n        raise InvalidTypeError(\n            input_value=input_data,\n            allowed_types=(Pixels, pd.DataFrame, np.ndarray, Iterable),\n            message=f\"Unsupported input type: {type(input_data).__name__}\",\n        )\n\n    except Exception as e:\n        if isinstance(e, (InvalidTypeError, InvalidInputError)):\n            raise\n\n        raise InvalidInputError(\n            input_value=input_data,\n            message=f\"Failed to convert input to Pixels: {str(e)}\"\n            f\"\\nExpected a Pixels instance or an iterable (e.g. list, np.array, tuple, pd.DataFrame).\"\n            f\"\\nThe input must contain 2D coordinates with x and y values.\",\n        )\n</code></pre>"},{"location":"api/entities/signatures/","title":"Signatures","text":""},{"location":"api/entities/signatures/#siapy.entities.signatures","title":"siapy.entities.signatures","text":""},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals","title":"Signals  <code>dataclass</code>","text":"<pre><code>Signals(_data: DataFrame)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals.df","title":"df  <code>property</code>","text":"<pre><code>df: DataFrame\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals.from_iterable","title":"from_iterable  <code>classmethod</code>","text":"<pre><code>from_iterable(iterable: Iterable) -&gt; Signals\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef from_iterable(cls, iterable: Iterable) -&gt; \"Signals\":\n    df = pd.DataFrame(iterable)\n    return cls(df)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals.load_from_parquet","title":"load_from_parquet  <code>classmethod</code>","text":"<pre><code>load_from_parquet(filepath: str | Path) -&gt; Signals\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef load_from_parquet(cls, filepath: str | Path) -&gt; \"Signals\":\n    df = pd.read_parquet(filepath)\n    return cls(df)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy() -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def to_numpy(self) -&gt; NDArray[np.floating[Any]]:\n    return self.df.to_numpy()\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals.average_signal","title":"average_signal","text":"<pre><code>average_signal(\n    axis: int | tuple[int, ...] | Sequence[int] | None = 0,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def average_signal(self, axis: int | tuple[int, ...] | Sequence[int] | None = 0) -&gt; NDArray[np.floating[Any]]:\n    return np.nanmean(self.to_numpy(), axis=axis)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signals.save_to_parquet","title":"save_to_parquet","text":"<pre><code>save_to_parquet(filepath: str | Path) -&gt; None\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def save_to_parquet(self, filepath: str | Path) -&gt; None:\n    self.df.to_parquet(filepath, index=True)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures","title":"Signatures  <code>dataclass</code>","text":"<pre><code>Signatures(pixels: Pixels, signals: Signals)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.pixels","title":"pixels  <code>instance-attribute</code>","text":"<pre><code>pixels: Pixels\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.signals","title":"signals  <code>instance-attribute</code>","text":"<pre><code>signals: Signals\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(data: dict[str, Any]) -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef from_dict(cls, data: dict[str, Any]) -&gt; \"Signatures\":\n    pixels_df = pd.DataFrame(data[\"pixels\"])\n    signals_df = pd.DataFrame(data[\"signals\"])\n    pixels = Pixels(pixels_df)\n    signals = Signals(signals_df)\n    validate_inputs(pixels, signals)\n    return cls(pixels, signals)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.from_array_and_pixels","title":"from_array_and_pixels  <code>classmethod</code>","text":"<pre><code>from_array_and_pixels(\n    array: NDArray[floating[Any]],\n    pixels: Pixels | DataFrame | Iterable[CoordinateInput],\n) -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef from_array_and_pixels(\n    cls, array: NDArray[np.floating[Any]], pixels: Pixels | pd.DataFrame | Iterable[CoordinateInput]\n) -&gt; \"Signatures\":\n    pixels = validate_pixel_input(pixels)\n    if pd.api.types.is_float_dtype(pixels.df.dtypes.x) or pd.api.types.is_float_dtype(pixels.df.dtypes.y):\n        logger.warning(\"Pixel DataFrame contains float values. Converting to integers.\")\n        pixels = pixels.as_type(int)\n\n    x = pixels.x()\n    y = pixels.y()\n\n    if array.ndim != 3:\n        raise InvalidInputError(f\"Expected a 3-dimensional array, but got {array.ndim}-dimensional array.\")\n    if np.max(x) &gt;= array.shape[1] or np.max(y) &gt;= array.shape[0]:\n        raise InvalidInputError(\n            f\"Pixel coordinates exceed image dimensions: \"\n            f\"image shape is {array.shape}, but max u={np.max(x)}, max v={np.max(y)}.\"\n        )\n\n    signals_list = array[y, x, :]\n    signals = Signals(pd.DataFrame(signals_list))\n    validate_inputs(pixels, signals)\n    return cls(pixels, signals)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.from_signals_and_pixels","title":"from_signals_and_pixels  <code>classmethod</code>","text":"<pre><code>from_signals_and_pixels(\n    signals: Signals | DataFrame | Iterable[Any],\n    pixels: Pixels | DataFrame | Iterable[CoordinateInput],\n) -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef from_signals_and_pixels(\n    cls,\n    signals: Signals | pd.DataFrame | Iterable[Any],\n    pixels: Pixels | pd.DataFrame | Iterable[CoordinateInput],\n) -&gt; \"Signatures\":\n    pixels = validate_pixel_input(pixels)\n    signals = validate_signal_input(signals)\n    validate_inputs(pixels, signals)\n    return cls(pixels, signals)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.from_dataframe","title":"from_dataframe  <code>classmethod</code>","text":"<pre><code>from_dataframe(dataframe: DataFrame) -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef from_dataframe(cls, dataframe: pd.DataFrame) -&gt; \"Signatures\":\n    if not all(coord in dataframe.columns for coord in [Pixels.coords.X, Pixels.coords.Y]):\n        raise InvalidInputError(\n            dataframe.columns.tolist(),\n            f\"DataFrame must include columns for both '{Pixels.coords.X}' and '{Pixels.coords.Y}' coordinates.\",\n        )\n    pixels = Pixels(dataframe[[Pixels.coords.X, Pixels.coords.Y]])\n    signals = Signals(dataframe.drop(columns=[Pixels.coords.X, Pixels.coords.Y]))\n    validate_inputs(pixels, signals)\n    return cls(pixels, signals)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.from_dataframe_multiindex","title":"from_dataframe_multiindex  <code>classmethod</code>","text":"<pre><code>from_dataframe_multiindex(df: DataFrame) -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef from_dataframe_multiindex(cls, df: pd.DataFrame) -&gt; \"Signatures\":\n    if not isinstance(df.columns, pd.MultiIndex):\n        raise InvalidInputError(\n            type(df.columns),\n            \"DataFrame must have MultiIndex columns\",\n        )\n\n    pixel_data = df.xs(\"pixel\", axis=1, level=\"category\")\n    signal_data = df.xs(\"signal\", axis=1, level=\"category\")\n\n    assert isinstance(pixel_data, pd.DataFrame)\n    assert isinstance(signal_data, pd.DataFrame)\n\n    pixels = Pixels(pixel_data)\n    signals = Signals(signal_data)\n    validate_inputs(pixels, signals)\n    return cls(pixels, signals)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.open_parquet","title":"open_parquet  <code>classmethod</code>","text":"<pre><code>open_parquet(filepath: str | Path) -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>@classmethod\ndef open_parquet(cls, filepath: str | Path) -&gt; \"Signatures\":\n    df = pd.read_parquet(filepath)\n    return cls.from_dataframe(df)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.to_dataframe","title":"to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def to_dataframe(self) -&gt; pd.DataFrame:\n    return pd.concat([self.pixels.df, self.signals.df], axis=1)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.to_dataframe_multiindex","title":"to_dataframe_multiindex","text":"<pre><code>to_dataframe_multiindex() -&gt; DataFrame\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def to_dataframe_multiindex(self) -&gt; pd.DataFrame:\n    pixel_columns = pd.MultiIndex.from_tuples(\n        [(\"pixel\", \"x\"), (\"pixel\", \"y\")],\n        names=[\"category\", \"coordinate\"],\n    )\n    signal_columns = pd.MultiIndex.from_tuples(\n        [(\"signal\", col) for col in self.signals.df.columns],\n        names=[\"category\", \"channel\"],\n    )\n\n    pixel_df = pd.DataFrame(self.pixels.df.values, columns=pixel_columns)\n    signal_df = pd.DataFrame(self.signals.df.values, columns=signal_columns)\n    return pd.concat([pixel_df, signal_df], axis=1)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy() -&gt; tuple[\n    NDArray[floating[Any]], NDArray[floating[Any]]\n]\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def to_numpy(self) -&gt; tuple[NDArray[np.floating[Any]], NDArray[np.floating[Any]]]:\n    return self.pixels.to_numpy(), self.signals.to_numpy()\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, Any]\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    return {\n        \"pixels\": self.pixels.df.to_dict(),\n        \"signals\": self.signals.df.to_dict(),\n    }\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.reset_index","title":"reset_index","text":"<pre><code>reset_index() -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def reset_index(self) -&gt; \"Signatures\":\n    return Signatures(\n        Pixels(self.pixels.df.reset_index(drop=True)), Signals(self.signals.df.reset_index(drop=True))\n    )\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.save_to_parquet","title":"save_to_parquet","text":"<pre><code>save_to_parquet(filepath: str | Path) -&gt; None\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def save_to_parquet(self, filepath: str | Path) -&gt; None:\n    self.to_dataframe().to_parquet(filepath, index=True)\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.Signatures.copy","title":"copy","text":"<pre><code>copy() -&gt; Signatures\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def copy(self) -&gt; \"Signatures\":\n    pixels_df = self.pixels.df.copy()\n    signals_df = self.signals.df.copy()\n    return Signatures(Pixels(pixels_df), Signals(signals_df))\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.validate_signal_input","title":"validate_signal_input","text":"<pre><code>validate_signal_input(\n    input_data: Signals\n    | DataFrame\n    | Iterable[Sequence[float]],\n) -&gt; Signals\n</code></pre> <p>Validates and converts various input types to Signals object.</p> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def validate_signal_input(input_data: Signals | pd.DataFrame | Iterable[Sequence[float]]) -&gt; Signals:\n    \"\"\"Validates and converts various input types to Signals object.\"\"\"\n    try:\n        if isinstance(input_data, Signals):\n            return input_data\n\n        if isinstance(input_data, pd.DataFrame):\n            return Signals(input_data)\n\n        if isinstance(input_data, np.ndarray):\n            if input_data.ndim not in (1, 2):\n                raise InvalidInputError(\n                    input_value=input_data.shape,\n                    message=f\"NumPy array must be 1D or 2D, got shape {input_data.shape}\",\n                )\n            if input_data.ndim == 1:\n                input_data = input_data.reshape(1, -1)  # Reshape 1D array to 2D if needed\n            return Signals(pd.DataFrame(input_data))\n\n        if isinstance(input_data, Iterable):\n            return Signals.from_iterable(input_data)\n\n        raise InvalidTypeError(\n            input_value=input_data,\n            allowed_types=(Signals, pd.DataFrame, np.ndarray, Iterable),\n            message=f\"Unsupported input type: {type(input_data).__name__}\",\n        )\n\n    except Exception as e:\n        if isinstance(e, (InvalidTypeError, InvalidInputError)):\n            raise\n\n        raise InvalidInputError(\n            input_value=input_data,\n            message=f\"Failed to convert input to Signals: {str(e)}\"\n            f\"\\nExpected a Signals instance or an iterable (e.g. list, np.array, pd.DataFrame).\"\n            f\"\\nThe input must contain spectral signal values.\",\n        )\n</code></pre>"},{"location":"api/entities/signatures/#siapy.entities.signatures.validate_inputs","title":"validate_inputs","text":"<pre><code>validate_inputs(pixels: Pixels, signals: Signals) -&gt; None\n</code></pre> Source code in <code>siapy/entities/signatures.py</code> <pre><code>def validate_inputs(pixels: Pixels, signals: Signals) -&gt; None:\n    if len(pixels) != len(signals):\n        raise InvalidInputError(\n            f\"Pixels and signals must have the same number of rows: {len(pixels)} pixels, {len(signals)} signals.\"\n        )\n</code></pre>"},{"location":"api/entities/images/interfaces/","title":"Interfaces","text":""},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces","title":"siapy.entities.images.interfaces","text":""},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase","title":"ImageBase","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class defining the interface for spectral image implementations.</p> <p>This class defines the common interface that all image backend implementations must implement, including methods for opening files, accessing metadata and properties, and converting to different formats.</p> <p>All concrete implementations (SpectralLibImage, RasterioLibImage, MockImage) must inherit from this class and implement all abstract methods.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.filepath","title":"filepath  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>filepath: Path\n</code></pre> <p>Get the file path of the image.</p> RETURNS DESCRIPTION <code>Path</code> <p>A Path object representing the location of the image file. For in-memory images, this may return an empty Path.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.metadata","title":"metadata  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Get the image metadata.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary containing image metadata such as coordinate reference system, geotransform information, wavelength data, and other image properties. The specific contents depend on the underlying format and library.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.shape","title":"shape  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>shape: tuple[int, int, int]\n</code></pre> <p>Get the dimensions of the image.</p> RETURNS DESCRIPTION <code>tuple[int, int, int]</code> <p>A tuple (height, width, bands) representing the image dimensions.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.bands","title":"bands  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>bands: int\n</code></pre> <p>Get the number of spectral bands in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of spectral bands (channels) in the image.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.default_bands","title":"default_bands  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>default_bands: list[int]\n</code></pre> <p>Get the default band indices for RGB display.</p> RETURNS DESCRIPTION <code>list[int]</code> <p>A list of band indices typically used for red, green, and blue channels when displaying the image as an RGB composite.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.wavelengths","title":"wavelengths  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>wavelengths: list[float]\n</code></pre> <p>Get the wavelengths corresponding to each spectral band.</p> RETURNS DESCRIPTION <code>list[float]</code> <p>A list of wavelength values (typically in nanometers) for each band. For non-spectral data, this may return band numbers or other identifiers.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.camera_id","title":"camera_id  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>camera_id: str\n</code></pre> <p>Get the camera or sensor identifier.</p> RETURNS DESCRIPTION <code>str</code> <p>A string identifying the camera or sensor used to capture the image. May return an empty string if no camera information is available.</p>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.open","title":"open  <code>abstractmethod</code> <code>classmethod</code>","text":"<pre><code>open(*args: Any, **kwargs: Any) -&gt; ImageBase\n</code></pre> <p>Open and load an image from a source.</p> PARAMETER DESCRIPTION <code>*args</code> <p>Positional arguments specific to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>()</code> </p> <code>**kwargs</code> <p>Keyword arguments specific to the implementation.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ImageBase</code> <p>An instance of the concrete image implementation.</p> Note <p>Each implementation defines its own signature for this method based on the specific requirements of the underlying library.</p> Source code in <code>siapy/entities/images/interfaces.py</code> <pre><code>@classmethod\n@abstractmethod\ndef open(cls: type[\"ImageBase\"], *args: Any, **kwargs: Any) -&gt; \"ImageBase\":\n    \"\"\"Open and load an image from a source.\n\n    Args:\n        *args: Positional arguments specific to the implementation.\n        **kwargs: Keyword arguments specific to the implementation.\n\n    Returns:\n        An instance of the concrete image implementation.\n\n    Note:\n        Each implementation defines its own signature for this method\n        based on the specific requirements of the underlying library.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.to_display","title":"to_display  <code>abstractmethod</code>","text":"<pre><code>to_display(equalize: bool = True) -&gt; Image\n</code></pre> <p>Convert the image to a PIL Image for display purposes.</p> PARAMETER DESCRIPTION <code>equalize</code> <p>Whether to apply histogram equalization to enhance contrast.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Image</code> <p>A PIL Image object suitable for display, typically as an RGB composite created from the default bands with appropriate scaling and normalization.</p> Source code in <code>siapy/entities/images/interfaces.py</code> <pre><code>@abstractmethod\ndef to_display(self, equalize: bool = True) -&gt; Image.Image:\n    \"\"\"Convert the image to a PIL Image for display purposes.\n\n    Args:\n        equalize: Whether to apply histogram equalization to enhance contrast.\n\n    Returns:\n        A PIL Image object suitable for display, typically as an RGB composite created from the default bands with appropriate scaling and normalization.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.to_numpy","title":"to_numpy  <code>abstractmethod</code>","text":"<pre><code>to_numpy(\n    nan_value: float | None = None,\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Convert the image to a numpy array.</p> PARAMETER DESCRIPTION <code>nan_value</code> <p>Optional value to replace NaN values with. If None, NaN values are preserved.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>NDArray[floating[Any]]</code> <p>A 3D numpy array with shape (height, width, bands) containing the image data. The array dtype should be a floating-point type.</p> Source code in <code>siapy/entities/images/interfaces.py</code> <pre><code>@abstractmethod\ndef to_numpy(self, nan_value: float | None = None) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Convert the image to a numpy array.\n\n    Args:\n        nan_value: Optional value to replace NaN values with. If None, NaN values are preserved.\n\n    Returns:\n        A 3D numpy array with shape (height, width, bands) containing the image data. The array dtype should be a floating-point type.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/entities/images/interfaces/#siapy.entities.images.interfaces.ImageBase.to_xarray","title":"to_xarray  <code>abstractmethod</code>","text":"<pre><code>to_xarray() -&gt; XarrayType\n</code></pre> <p>Convert the image to an xarray DataArray.</p> RETURNS DESCRIPTION <code>XarrayType</code> <p>An xarray DataArray with labeled dimensions and coordinates, suitable for advanced analysis and visualization. The array should include appropriate coordinate information and metadata attributes.</p> Source code in <code>siapy/entities/images/interfaces.py</code> <pre><code>@abstractmethod\ndef to_xarray(self) -&gt; \"XarrayType\":\n    \"\"\"Convert the image to an xarray DataArray.\n\n    Returns:\n        An xarray DataArray with labeled dimensions and coordinates, suitable for advanced analysis and visualization. The array should include appropriate coordinate information and metadata attributes.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/entities/images/mock/","title":"Mock Image","text":""},{"location":"api/entities/images/mock/#siapy.entities.images.mock","title":"siapy.entities.images.mock","text":""},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage","title":"MockImage","text":"<pre><code>MockImage(array: NDArray[floating[Any]])\n</code></pre> <p>               Bases: <code>ImageBase</code></p> PARAMETER DESCRIPTION <code>array</code> <p>A 3D numpy array with shape (height, width, bands) containing spectral data.    The array will be automatically converted to float32 dtype.</p> <p> TYPE: <code>NDArray[floating[Any]]</code> </p> RAISES DESCRIPTION <code>InvalidInputError</code> <p>If the input array is not 3-dimensional.</p> Example <pre><code>import numpy as np\n\n# Create a synthetic spectral image\ndata = np.random.rand(100, 100, 10).astype(np.float32)\nmock_image = MockImage(data)\n</code></pre> Note <p>The input array is automatically converted to float32 dtype regardless of input type.</p> Source code in <code>siapy/entities/images/mock.py</code> <pre><code>def __init__(\n    self,\n    array: NDArray[np.floating[Any]],\n) -&gt; None:\n    \"\"\"Initialize a MockImage from a numpy array.\n\n    Args:\n        array: A 3D numpy array with shape (height, width, bands) containing spectral data.\n               The array will be automatically converted to float32 dtype.\n\n    Raises:\n        InvalidInputError: If the input array is not 3-dimensional.\n\n    Example:\n        ```python\n        import numpy as np\n\n        # Create a synthetic spectral image\n        data = np.random.rand(100, 100, 10).astype(np.float32)\n        mock_image = MockImage(data)\n        ```\n\n    Note:\n        The input array is automatically converted to float32 dtype regardless of input type.\n    \"\"\"\n    if len(array.shape) != 3:\n        raise InvalidInputError(\n            input_value=array.shape,\n            message=\"Input array must be 3-dimensional (height, width, bands)\",\n        )\n\n    self._array = array.astype(np.float32)\n</code></pre>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.filepath","title":"filepath  <code>property</code>","text":"<pre><code>filepath: Path\n</code></pre> <p>Get a placeholder file path for the mock image.</p> RETURNS DESCRIPTION <code>Path</code> <p>An empty Path object since mock images are not associated with files.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Get empty metadata for the mock image.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>An empty dictionary since mock images have no associated metadata.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.shape","title":"shape  <code>property</code>","text":"<pre><code>shape: tuple[int, int, int]\n</code></pre> <p>Get the dimensions of the mock image.</p> RETURNS DESCRIPTION <code>tuple[int, int, int]</code> <p>A tuple (height, width, bands) representing the image dimensions extracted from the underlying numpy array shape.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.bands","title":"bands  <code>property</code>","text":"<pre><code>bands: int\n</code></pre> <p>Get the number of spectral bands in the mock image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of bands (third dimension) in the underlying array.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.default_bands","title":"default_bands  <code>property</code>","text":"<pre><code>default_bands: list[int]\n</code></pre> <p>Get the default band indices for RGB display.</p> RETURNS DESCRIPTION <code>list[int]</code> <p>A list of band indices for RGB display. If the image has 3 or more bands, returns [0, 1, 2]. Otherwise, returns indices for all available bands up to a maximum of 3.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.wavelengths","title":"wavelengths  <code>property</code>","text":"<pre><code>wavelengths: list[float]\n</code></pre> <p>Get placeholder wavelength values for the mock image.</p> RETURNS DESCRIPTION <code>list[float]</code> <p>A list of sequential integers as float values, starting from 0, representing mock wavelengths for each band.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.camera_id","title":"camera_id  <code>property</code>","text":"<pre><code>camera_id: str\n</code></pre> <p>Get a placeholder camera identifier for the mock image.</p> RETURNS DESCRIPTION <code>str</code> <p>An empty string since mock images are not associated with real cameras.</p>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.open","title":"open  <code>classmethod</code>","text":"<pre><code>open(array: NDArray[floating[Any]]) -&gt; MockImage\n</code></pre> <p>Create a MockImage instance from a numpy array.</p> PARAMETER DESCRIPTION <code>array</code> <p>A 3D numpy array with shape (height, width, bands) containing spectral data.</p> <p> TYPE: <code>NDArray[floating[Any]]</code> </p> RETURNS DESCRIPTION <code>MockImage</code> <p>A MockImage instance wrapping the provided array.</p> Example <pre><code>import numpy as np\n\n# Create synthetic data\ndata = np.random.rand(50, 50, 5).astype(np.float32)\nmock_image = MockImage.open(data)\n</code></pre> Source code in <code>siapy/entities/images/mock.py</code> <pre><code>@classmethod\ndef open(cls, array: NDArray[np.floating[Any]]) -&gt; \"MockImage\":\n    \"\"\"Create a MockImage instance from a numpy array.\n\n    Args:\n        array: A 3D numpy array with shape (height, width, bands) containing spectral data.\n\n    Returns:\n        A MockImage instance wrapping the provided array.\n\n    Example:\n        ```python\n        import numpy as np\n\n        # Create synthetic data\n        data = np.random.rand(50, 50, 5).astype(np.float32)\n        mock_image = MockImage.open(data)\n        ```\n    \"\"\"\n    return cls(array=array)\n</code></pre>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.to_display","title":"to_display","text":"<pre><code>to_display(equalize: bool = True) -&gt; Image\n</code></pre> <p>Convert the mock image to a PIL Image for display purposes.</p> PARAMETER DESCRIPTION <code>equalize</code> <p>Whether to apply histogram equalization to enhance contrast. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Image</code> <p>A PIL Image object suitable for display. For images with 3+ bands, uses the first 3 bands as RGB. For images with fewer bands, duplicates the first band across all RGB channels.</p> Example <pre><code># Display the mock image\npil_image = mock_image.to_display()\npil_image.show()\n\n# Display without histogram equalization\npil_image = mock_image.to_display(equalize=False)\n</code></pre> Note <p>NaN values in the image are automatically handled by replacing them with 0 during the scaling process. The method always returns an RGB image regardless of the number of input bands.</p> Source code in <code>siapy/entities/images/mock.py</code> <pre><code>def to_display(self, equalize: bool = True) -&gt; Image.Image:\n    \"\"\"Convert the mock image to a PIL Image for display purposes.\n\n    Args:\n        equalize: Whether to apply histogram equalization to enhance contrast. Defaults to True.\n\n    Returns:\n        A PIL Image object suitable for display. For images with 3+ bands, uses the first 3 bands as RGB. For images with fewer bands, duplicates the first band across all RGB channels.\n\n    Example:\n        ```python\n        # Display the mock image\n        pil_image = mock_image.to_display()\n        pil_image.show()\n\n        # Display without histogram equalization\n        pil_image = mock_image.to_display(equalize=False)\n        ```\n\n    Note:\n        NaN values in the image are automatically handled by replacing them with 0\n        during the scaling process. The method always returns an RGB image regardless\n        of the number of input bands.\n    \"\"\"\n    if self.bands &gt;= 3:\n        display_bands = self._array[:, :, self.default_bands]\n    else:\n        display_bands = np.stack([self._array[:, :, 0]] * 3, axis=2)\n\n    if equalize:\n        for i in range(display_bands.shape[2]):\n            band = display_bands[:, :, i]\n            non_nan = ~np.isnan(band)\n            if np.any(non_nan):\n                min_val = np.nanmin(band)\n                max_val = np.nanmax(band)\n                if max_val &gt; min_val:\n                    band = (band - min_val) / (max_val - min_val) * 255\n                display_bands[:, :, i] = band\n\n    display_array = np.nan_to_num(display_bands).astype(np.uint8)\n    return Image.fromarray(display_array)\n</code></pre>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy(\n    nan_value: float | None = None,\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Convert the mock image to a numpy array.</p> PARAMETER DESCRIPTION <code>nan_value</code> <p>Optional value to replace NaN values with. If None, NaN values are preserved.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>NDArray[floating[Any]]</code> <p>A copy of the underlying 3D numpy array with shape (height, width, bands). If nan_value is provided, all NaN values are replaced with this value.</p> Example <pre><code># Get the raw data with NaN values preserved\ndata = mock_image.to_numpy()\n\n# Replace NaN values with zero\ndata = mock_image.to_numpy(nan_value=0.0)\n</code></pre> Source code in <code>siapy/entities/images/mock.py</code> <pre><code>def to_numpy(self, nan_value: float | None = None) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Convert the mock image to a numpy array.\n\n    Args:\n        nan_value: Optional value to replace NaN values with. If None, NaN values are preserved.\n\n    Returns:\n        A copy of the underlying 3D numpy array with shape (height, width, bands). If nan_value is provided, all NaN values are replaced with this value.\n\n    Example:\n        ```python\n        # Get the raw data with NaN values preserved\n        data = mock_image.to_numpy()\n\n        # Replace NaN values with zero\n        data = mock_image.to_numpy(nan_value=0.0)\n        ```\n    \"\"\"\n    if nan_value is not None:\n        return np.nan_to_num(self._array, nan=nan_value)\n    return self._array.copy()\n</code></pre>"},{"location":"api/entities/images/mock/#siapy.entities.images.mock.MockImage.to_xarray","title":"to_xarray","text":"<pre><code>to_xarray() -&gt; XarrayType\n</code></pre> <p>Convert the mock image to an xarray DataArray.</p> RETURNS DESCRIPTION <code>XarrayType</code> <p>An xarray DataArray with labeled dimensions (y, x, band) and coordinates, including mock wavelength values and minimal metadata.</p> Example <pre><code># Convert to xarray for analysis\nxr_data = mock_image.to_xarray()\n\n# Access specific bands\nfirst_band = xr_data.sel(band=0)\n</code></pre> Source code in <code>siapy/entities/images/mock.py</code> <pre><code>def to_xarray(self) -&gt; \"XarrayType\":\n    \"\"\"Convert the mock image to an xarray DataArray.\n\n    Returns:\n        An xarray DataArray with labeled dimensions (y, x, band) and coordinates, including mock wavelength values and minimal metadata.\n\n    Example:\n        ```python\n        # Convert to xarray for analysis\n        xr_data = mock_image.to_xarray()\n\n        # Access specific bands\n        first_band = xr_data.sel(band=0)\n        ```\n    \"\"\"\n    return xr.DataArray(\n        self._array,\n        dims=[\"y\", \"x\", \"band\"],\n        coords={\n            \"band\": self.wavelengths,\n            \"x\": np.arange(self.shape[1]),\n            \"y\": np.arange(self.shape[0]),\n        },\n        attrs={\n            \"camera_id\": self.camera_id,\n        },\n    )\n</code></pre>"},{"location":"api/entities/images/rasterio_lib/","title":"Rasterio Library","text":""},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib","title":"siapy.entities.images.rasterio_lib","text":""},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage","title":"RasterioLibImage  <code>dataclass</code>","text":"<pre><code>RasterioLibImage(file: XarrayType)\n</code></pre> <p>               Bases: <code>ImageBase</code></p> PARAMETER DESCRIPTION <code>file</code> <p>An xarray DataArray containing the raster data loaded via rioxarray.</p> <p> TYPE: <code>XarrayType</code> </p> Source code in <code>siapy/entities/images/rasterio_lib.py</code> <pre><code>def __init__(self, file: \"XarrayType\"):\n    \"\"\"Initialize a RasterioLibImage wrapper around an xarray DataArray.\n\n    Args:\n        file: An xarray DataArray containing the raster data loaded via rioxarray.\n    \"\"\"\n    self._file = file\n</code></pre>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.file","title":"file  <code>property</code>","text":"<pre><code>file: XarrayType\n</code></pre> <p>Get the underlying xarray DataArray.</p> RETURNS DESCRIPTION <code>XarrayType</code> <p>The wrapped xarray DataArray containing the raster data.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.filepath","title":"filepath  <code>property</code>","text":"<pre><code>filepath: Path\n</code></pre> <p>Get the file path of the raster image.</p> RETURNS DESCRIPTION <code>Path</code> <p>A Path object representing the location of the raster file, extracted from the xarray encoding information.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Get the raster metadata from the xarray attributes.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary containing raster metadata such as coordinate reference system, geotransform information, and other properties stored in xarray attrs.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.shape","title":"shape  <code>property</code>","text":"<pre><code>shape: tuple[int, int, int]\n</code></pre> <p>Get the dimensions of the raster image.</p> RETURNS DESCRIPTION <code>tuple[int, int, int]</code> <p>A tuple (height, width, bands) representing the image dimensions. Note that rioxarray uses (band, y, x) ordering internally, which is converted to the standard (y, x, band) format.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.rows","title":"rows  <code>property</code>","text":"<pre><code>rows: int\n</code></pre> <p>Get the number of rows (height) in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of rows in the raster image.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.cols","title":"cols  <code>property</code>","text":"<pre><code>cols: int\n</code></pre> <p>Get the number of columns (width) in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of columns in the raster image.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.bands","title":"bands  <code>property</code>","text":"<pre><code>bands: int\n</code></pre> <p>Get the number of bands in the raster image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of bands (channels) in the raster image.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.default_bands","title":"default_bands  <code>property</code>","text":"<pre><code>default_bands: list[int]\n</code></pre> <p>Get the default band indices for RGB display.</p> RETURNS DESCRIPTION <code>list[int]</code> <p>A list of 1-based band indices commonly used for RGB display. For satellite imagery, this typically returns [1, 2, 3] for images with 3+ bands, or [1, 2] for images with 2 bands, etc. Note that these are 1-based indices as used by rioxarray.</p> Note <p>Returns 1-based band indices (not 0-based) to match rioxarray's band coordinate system. This differs from numpy array indexing which is 0-based.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.wavelengths","title":"wavelengths  <code>property</code>","text":"<pre><code>wavelengths: list[float]\n</code></pre> <p>Get the band values, which may represent wavelengths or band numbers.</p> RETURNS DESCRIPTION <code>list[float]</code> <p>A numpy array of band coordinate values from the xarray DataArray. For spectral data, these may represent wavelengths in nanometers; for other raster data, these are typically just sequential band numbers (1, 2, 3, etc.).</p> Note <p>The interpretation of these values depends on the source data. Check the metadata to determine if these represent actual wavelengths or just band identifiers.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.camera_id","title":"camera_id  <code>property</code>","text":"<pre><code>camera_id: str\n</code></pre> <p>Get the camera or sensor identifier from metadata.</p> RETURNS DESCRIPTION <code>str</code> <p>A string identifying the camera or sensor used to capture the image. Returns empty string if no camera_id is found in the metadata.</p> Note <p>This property looks for 'camera_id' in the metadata, which is not a standard raster metadata field and may not be present in most files.</p>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.open","title":"open  <code>classmethod</code>","text":"<pre><code>open(filepath: str | Path) -&gt; RasterioLibImage\n</code></pre> <p>Open a raster image using the rioxarray library.</p> PARAMETER DESCRIPTION <code>filepath</code> <p>Path to the raster file (supports formats like GeoTIFF, NetCDF, HDF5, etc.).</p> <p> TYPE: <code>str | Path</code> </p> RETURNS DESCRIPTION <code>RasterioLibImage</code> <p>A RasterioLibImage instance wrapping the opened raster data.</p> RAISES DESCRIPTION <code>InvalidFilepathError</code> <p>If the file path does not exist.</p> <code>InvalidInputError</code> <p>If the file cannot be opened (e.g., unsupported format,              corrupted file) or if rioxarray returns a list instead of              DataArray/Dataset.</p> Example <pre><code># Open a GeoTIFF file\nimage = RasterioLibImage.open(\"satellite_image.tif\")\n\n# Open a NetCDF file\nimage = RasterioLibImage.open(\"climate_data.nc\")\n</code></pre> Note <p>The method uses rioxarray.open_rasterio() internally, which supports most GDAL-compatible raster formats. Some formats may require additional dependencies.</p> Source code in <code>siapy/entities/images/rasterio_lib.py</code> <pre><code>@classmethod\ndef open(cls, filepath: str | Path) -&gt; \"RasterioLibImage\":\n    \"\"\"Open a raster image using the rioxarray library.\n\n    Args:\n        filepath: Path to the raster file (supports formats like GeoTIFF, NetCDF, HDF5, etc.).\n\n    Returns:\n        A RasterioLibImage instance wrapping the opened raster data.\n\n    Raises:\n        InvalidFilepathError: If the file path does not exist.\n        InvalidInputError: If the file cannot be opened (e.g., unsupported format,\n                         corrupted file) or if rioxarray returns a list instead of\n                         DataArray/Dataset.\n\n    Example:\n        ```python\n        # Open a GeoTIFF file\n        image = RasterioLibImage.open(\"satellite_image.tif\")\n\n        # Open a NetCDF file\n        image = RasterioLibImage.open(\"climate_data.nc\")\n        ```\n\n    Note:\n        The method uses rioxarray.open_rasterio() internally, which supports most\n        GDAL-compatible raster formats. Some formats may require additional dependencies.\n    \"\"\"\n    filepath = Path(filepath)\n    if not filepath.exists():\n        raise InvalidFilepathError(filepath)\n\n    try:\n        raster = rioxarray.open_rasterio(filepath)\n    except Exception as e:\n        raise InvalidInputError({\"filepath\": str(filepath)}, f\"Failed to open raster file: {e}\") from e\n\n    if isinstance(raster, list):\n        raise InvalidInputError({\"file_type\": type(raster).__name__}, \"Expected DataArray or Dataset, got list\")\n\n    return cls(raster)\n</code></pre>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.to_display","title":"to_display","text":"<pre><code>to_display(equalize: bool = True) -&gt; Image\n</code></pre> <p>Convert the image to a PIL Image for display purposes.</p> PARAMETER DESCRIPTION <code>equalize</code> <p>Whether to apply histogram equalization to enhance contrast. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Image</code> <p>A PIL Image object suitable for display, created from the default RGB bands with values scaled to 0-255 range and optional histogram equalization.</p> Example <pre><code># Display the image with default settings\npil_image = raster_image.to_display()\npil_image.show()\n\n# Display without histogram equalization\npil_image = raster_image.to_display(equalize=False)\n</code></pre> Source code in <code>siapy/entities/images/rasterio_lib.py</code> <pre><code>def to_display(self, equalize: bool = True) -&gt; Image.Image:\n    \"\"\"Convert the image to a PIL Image for display purposes.\n\n    Args:\n        equalize: Whether to apply histogram equalization to enhance contrast. Defaults to True.\n\n    Returns:\n        A PIL Image object suitable for display, created from the default RGB bands with values scaled to 0-255 range and optional histogram equalization.\n\n    Example:\n        ```python\n        # Display the image with default settings\n        pil_image = raster_image.to_display()\n        pil_image.show()\n\n        # Display without histogram equalization\n        pil_image = raster_image.to_display(equalize=False)\n        ```\n    \"\"\"\n    bands_data = self.file.sel(band=self.default_bands)\n    image_3ch = bands_data.transpose(\"y\", \"x\", \"band\").values\n    image_3ch_clean = np.nan_to_num(np.asarray(image_3ch))\n    min_val = np.nanmin(image_3ch_clean)\n    max_val = np.nanmax(image_3ch_clean)\n\n    image_scaled = ((image_3ch_clean - min_val) * (255.0 / (max_val - min_val))).astype(np.uint8)\n\n    image = Image.fromarray(image_scaled)\n    if equalize:\n        image = ImageOps.equalize(image)\n    return image\n</code></pre>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy(\n    nan_value: float | None = None,\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Convert the image to a numpy array.</p> PARAMETER DESCRIPTION <code>nan_value</code> <p>Optional value to replace NaN values with. If None, NaN values are preserved.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>NDArray[floating[Any]]</code> <p>A 3D numpy array with shape (height, width, bands) containing the raster data. The array is transposed from rioxarray's native (band, y, x) to (y, x, band) format.</p> Example <pre><code># Get the raw data with NaN values preserved\ndata = raster_image.to_numpy()\n\n# Replace NaN values with zero\ndata = raster_image.to_numpy(nan_value=0.0)\n</code></pre> Source code in <code>siapy/entities/images/rasterio_lib.py</code> <pre><code>def to_numpy(self, nan_value: float | None = None) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Convert the image to a numpy array.\n\n    Args:\n        nan_value: Optional value to replace NaN values with. If None, NaN values are preserved.\n\n    Returns:\n        A 3D numpy array with shape (height, width, bands) containing the raster data. The array is transposed from rioxarray's native (band, y, x) to (y, x, band) format.\n\n    Example:\n        ```python\n        # Get the raw data with NaN values preserved\n        data = raster_image.to_numpy()\n\n        # Replace NaN values with zero\n        data = raster_image.to_numpy(nan_value=0.0)\n        ```\n    \"\"\"\n    image = np.asarray(self.file.transpose(\"y\", \"x\", \"band\").values)\n    if nan_value is not None:\n        image = np.nan_to_num(image, nan=nan_value)\n    return image\n</code></pre>"},{"location":"api/entities/images/rasterio_lib/#siapy.entities.images.rasterio_lib.RasterioLibImage.to_xarray","title":"to_xarray","text":"<pre><code>to_xarray() -&gt; XarrayType\n</code></pre> <p>Convert the image to an xarray DataArray.</p> RETURNS DESCRIPTION <code>XarrayType</code> <p>The underlying xarray DataArray with all original coordinates, dimensions, and metadata preserved.</p> Example <pre><code># Access the xarray representation\nxr_data = raster_image.to_xarray()\n\n# Use xarray functionality\nsubset = xr_data.sel(x=slice(100, 200), y=slice(100, 200))\n</code></pre> Source code in <code>siapy/entities/images/rasterio_lib.py</code> <pre><code>def to_xarray(self) -&gt; \"XarrayType\":\n    \"\"\"Convert the image to an xarray DataArray.\n\n    Returns:\n        The underlying xarray DataArray with all original coordinates, dimensions, and metadata preserved.\n\n    Example:\n        ```python\n        # Access the xarray representation\n        xr_data = raster_image.to_xarray()\n\n        # Use xarray functionality\n        subset = xr_data.sel(x=slice(100, 200), y=slice(100, 200))\n        ```\n    \"\"\"\n    return self.file\n</code></pre>"},{"location":"api/entities/images/spectral_lib/","title":"Spectral Library","text":""},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib","title":"siapy.entities.images.spectral_lib","text":""},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage","title":"SpectralLibImage  <code>dataclass</code>","text":"<pre><code>SpectralLibImage(file: SpectralLibType)\n</code></pre> <p>               Bases: <code>ImageBase</code></p> PARAMETER DESCRIPTION <code>file</code> <p>A SpectralPython file object representing the opened spectral image.</p> <p> TYPE: <code>SpectralLibType</code> </p> Source code in <code>siapy/entities/images/spectral_lib.py</code> <pre><code>def __init__(\n    self,\n    file: \"SpectralLibType\",\n):\n    \"\"\"Initialize a SpectralLibImage wrapper around a SpectralPython file object.\n\n    Args:\n        file: A SpectralPython file object representing the opened spectral image.\n    \"\"\"\n    self._file = file\n</code></pre>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.file","title":"file  <code>property</code>","text":"<pre><code>file: SpectralLibType\n</code></pre> <p>Get the underlying SpectralPython file object.</p> RETURNS DESCRIPTION <code>SpectralLibType</code> <p>The wrapped SpectralPython file object.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.filepath","title":"filepath  <code>property</code>","text":"<pre><code>filepath: Path\n</code></pre> <p>Get the file path of the spectral image.</p> RETURNS DESCRIPTION <code>Path</code> <p>A Path object representing the location of the image file.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Get the image metadata from the ENVI header.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary containing image metadata such as coordinate reference system, wavelength information, and other image properties from the ENVI header.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.shape","title":"shape  <code>property</code>","text":"<pre><code>shape: tuple[int, int, int]\n</code></pre> <p>Get the dimensions of the spectral image.</p> RETURNS DESCRIPTION <code>tuple[int, int, int]</code> <p>A tuple (rows, samples, bands) representing the image dimensions.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.rows","title":"rows  <code>property</code>","text":"<pre><code>rows: int\n</code></pre> <p>Get the number of rows (height) in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of rows in the spectral image.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.cols","title":"cols  <code>property</code>","text":"<pre><code>cols: int\n</code></pre> <p>Get the number of columns (width) in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of columns in the spectral image.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.bands","title":"bands  <code>property</code>","text":"<pre><code>bands: int\n</code></pre> <p>Get the number of spectral bands in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of spectral bands (channels) in the image.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.default_bands","title":"default_bands  <code>property</code>","text":"<pre><code>default_bands: list[int]\n</code></pre> <p>Get the default band indices for RGB display.</p> RETURNS DESCRIPTION <code>list[int]</code> <p>A list of 0-based band indices from the ENVI metadata, typically used for red, green, and blue channels when displaying the image as an RGB composite. These indices are extracted from the \"default bands\" field in the ENVI header file.</p> Note <p>Unlike rasterio which uses 1-based indexing, SpectralPython uses 0-based indexing for band access. The returned indices can be used directly with numpy array indexing.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.wavelengths","title":"wavelengths  <code>property</code>","text":"<pre><code>wavelengths: list[float]\n</code></pre> <p>Get the wavelengths corresponding to each spectral band.</p> RETURNS DESCRIPTION <code>list[float]</code> <p>A list of wavelength values (typically in nanometers) for each band as stored in the ENVI metadata. The length equals the number of bands.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.description","title":"description  <code>property</code>","text":"<pre><code>description: dict[str, Any]\n</code></pre> <p>Get parsed description metadata from the ENVI header.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary containing parsed key-value pairs from the description field in the ENVI metadata, with automatic type conversion for numeric values and comma-separated lists.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.camera_id","title":"camera_id  <code>property</code>","text":"<pre><code>camera_id: str\n</code></pre> <p>Get the camera or sensor identifier from the description metadata.</p> RETURNS DESCRIPTION <code>str</code> <p>A string identifying the camera or sensor used to capture the image, extracted from the \"ID\" field in the parsed description metadata.</p>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.open","title":"open  <code>classmethod</code>","text":"<pre><code>open(\n    *,\n    header_path: str | Path,\n    image_path: str | Path | None = None,\n) -&gt; SpectralLibImage\n</code></pre> <p>Open a spectral image using the SpectralPython ENVI library.</p> PARAMETER DESCRIPTION <code>header_path</code> <p>Path to the ENVI header file (.hdr) containing image metadata.</p> <p> TYPE: <code>str | Path</code> </p> <code>image_path</code> <p>Optional path to the image data file. If None, the path is inferred from the header file.</p> <p> TYPE: <code>str | Path | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SpectralLibImage</code> <p>A SpectralLibImage instance wrapping the opened spectral file.</p> RAISES DESCRIPTION <code>InvalidFilepathError</code> <p>If the header file path does not exist.</p> <code>InvalidInputError</code> <p>If the file cannot be opened or if it's a SpectralLibrary instead of an Image.</p> Example <pre><code># Open an ENVI format image\nimage = SpectralLibImage.open(header_path=\"image.hdr\")\n\n# Open with explicit image file path\nimage = SpectralLibImage.open(\n    header_path=\"image.hdr\",\n    image_path=\"image.dat\"\n)\n</code></pre> Source code in <code>siapy/entities/images/spectral_lib.py</code> <pre><code>@classmethod\ndef open(cls, *, header_path: str | Path, image_path: str | Path | None = None) -&gt; \"SpectralLibImage\":\n    \"\"\"Open a spectral image using the SpectralPython ENVI library.\n\n    Args:\n        header_path: Path to the ENVI header file (.hdr) containing image metadata.\n        image_path: Optional path to the image data file. If None, the path is inferred from the header file.\n\n    Returns:\n        A SpectralLibImage instance wrapping the opened spectral file.\n\n    Raises:\n        InvalidFilepathError: If the header file path does not exist.\n        InvalidInputError: If the file cannot be opened or if it's a SpectralLibrary instead of an Image.\n\n    Example:\n        ```python\n        # Open an ENVI format image\n        image = SpectralLibImage.open(header_path=\"image.hdr\")\n\n        # Open with explicit image file path\n        image = SpectralLibImage.open(\n            header_path=\"image.hdr\",\n            image_path=\"image.dat\"\n        )\n        ```\n    \"\"\"\n    header_path = Path(header_path)\n    if not header_path.exists():\n        raise InvalidFilepathError(header_path)\n\n    try:\n        sp_file = sp.envi.open(file=header_path, image=image_path)\n    except Exception as e:\n        raise InvalidInputError({\"filepath\": str(header_path)}, f\"Failed to open spectral file: {e}\") from e\n\n    if isinstance(sp_file, sp.io.envi.SpectralLibrary):\n        raise InvalidInputError({\"file_type\": type(sp_file).__name__}, \"Expected Image, got SpectralLibrary\")\n\n    return cls(sp_file)\n</code></pre>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.to_display","title":"to_display","text":"<pre><code>to_display(equalize: bool = True) -&gt; Image\n</code></pre> <p>Convert the image to a PIL Image for display purposes.</p> PARAMETER DESCRIPTION <code>equalize</code> <p>Whether to apply histogram equalization to enhance contrast. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Image</code> <p>A PIL Image object suitable for display, created from the default RGB bands with normalized values and optional histogram equalization.</p> Example <pre><code># Display the image with default settings\npil_image = spectral_image.to_display()\npil_image.show()\n\n# Display without histogram equalization\npil_image = spectral_image.to_display(equalize=False)\n</code></pre> Source code in <code>siapy/entities/images/spectral_lib.py</code> <pre><code>def to_display(self, equalize: bool = True) -&gt; Image.Image:\n    \"\"\"Convert the image to a PIL Image for display purposes.\n\n    Args:\n        equalize: Whether to apply histogram equalization to enhance contrast. Defaults to True.\n\n    Returns:\n        A PIL Image object suitable for display, created from the default RGB bands with normalized values and optional histogram equalization.\n\n    Example:\n        ```python\n        # Display the image with default settings\n        pil_image = spectral_image.to_display()\n        pil_image.show()\n\n        # Display without histogram equalization\n        pil_image = spectral_image.to_display(equalize=False)\n        ```\n    \"\"\"\n    max_uint8 = 255.0\n    image_3ch = self.file.read_bands(self.default_bands)\n    image_3ch = self._remove_nan(image_3ch, nan_value=0)\n    image_3ch[:, :, 0] = image_3ch[:, :, 0] / image_3ch[:, :, 0].max() / max_uint8\n    image_3ch[:, :, 1] = image_3ch[:, :, 1] / (image_3ch[:, :, 1].max() / max_uint8)\n    image_3ch[:, :, 2] = image_3ch[:, :, 2] / (image_3ch[:, :, 2].max() / max_uint8)\n    image = Image.fromarray(image_3ch.astype(\"uint8\"))\n    if equalize:\n        image = ImageOps.equalize(image)\n    return image\n</code></pre>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy(\n    nan_value: float | None = None,\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Convert the image to a numpy array.</p> PARAMETER DESCRIPTION <code>nan_value</code> <p>Optional value to replace NaN values with. If None, NaN values are preserved.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>NDArray[floating[Any]]</code> <p>A 3D numpy array with shape (rows, cols, bands) containing the spectral data.</p> Example <pre><code># Get the raw data with NaN values preserved\ndata = spectral_image.to_numpy()\n\n# Replace NaN values with zero\ndata = spectral_image.to_numpy(nan_value=0.0)\n</code></pre> Source code in <code>siapy/entities/images/spectral_lib.py</code> <pre><code>def to_numpy(self, nan_value: float | None = None) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Convert the image to a numpy array.\n\n    Args:\n        nan_value: Optional value to replace NaN values with. If None, NaN values are preserved.\n\n    Returns:\n        A 3D numpy array with shape (rows, cols, bands) containing the spectral data.\n\n    Example:\n        ```python\n        # Get the raw data with NaN values preserved\n        data = spectral_image.to_numpy()\n\n        # Replace NaN values with zero\n        data = spectral_image.to_numpy(nan_value=0.0)\n        ```\n    \"\"\"\n    image = self.file[:, :, :]\n    if nan_value is not None:\n        image = self._remove_nan(image, nan_value)\n    return image\n</code></pre>"},{"location":"api/entities/images/spectral_lib/#siapy.entities.images.spectral_lib.SpectralLibImage.to_xarray","title":"to_xarray","text":"<pre><code>to_xarray() -&gt; XarrayType\n</code></pre> <p>Convert the image to an xarray DataArray.</p> RETURNS DESCRIPTION <code>XarrayType</code> <p>An xarray DataArray with labeled dimensions (y, x, band) and coordinates, including wavelength information and metadata attributes.</p> Example <pre><code># Convert to xarray for analysis\nxr_data = spectral_image.to_xarray()\n\n# Access specific bands or wavelengths\nred_band = xr_data.sel(band=650, method='nearest')\n</code></pre> Source code in <code>siapy/entities/images/spectral_lib.py</code> <pre><code>def to_xarray(self) -&gt; \"XarrayType\":\n    \"\"\"Convert the image to an xarray DataArray.\n\n    Returns:\n        An xarray DataArray with labeled dimensions (y, x, band) and coordinates, including wavelength information and metadata attributes.\n\n    Example:\n        ```python\n        # Convert to xarray for analysis\n        xr_data = spectral_image.to_xarray()\n\n        # Access specific bands or wavelengths\n        red_band = xr_data.sel(band=650, method='nearest')\n        ```\n    \"\"\"\n    data = self._file[:, :, :]\n    xarray = xr.DataArray(\n        data,\n        dims=[\"y\", \"x\", \"band\"],\n        coords={\n            \"y\": np.arange(self.rows),\n            \"x\": np.arange(self.cols),\n            \"band\": self.wavelengths,\n        },\n        attrs=self._file.metadata,\n    )\n    return xarray\n</code></pre>"},{"location":"api/entities/images/spimage/","title":"Spectral Images","text":""},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage","title":"siapy.entities.images.spimage","text":""},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T', bound=ImageBase)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage","title":"SpectralImage  <code>dataclass</code>","text":"<pre><code>SpectralImage(\n    image: T, geometric_shapes: list[Shape] | None = None\n)\n</code></pre> <p>               Bases: <code>Generic[T]</code></p> PARAMETER DESCRIPTION <code>image</code> <p>The underlying image implementation (e.g., RasterioLibImage, SpectralLibImage, MockImage).</p> <p> TYPE: <code>T</code> </p> <code>geometric_shapes</code> <p>Optional list of geometric shapes associated with this image. Defaults to None.</p> <p> TYPE: <code>list[Shape] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def __init__(\n    self,\n    image: T,\n    geometric_shapes: list[\"Shape\"] | None = None,\n):\n    \"\"\"Initialize a SpectralImage wrapper around an image backend.\n\n    Args:\n        image: The underlying image implementation (e.g., RasterioLibImage, SpectralLibImage, MockImage).\n        geometric_shapes: Optional list of geometric shapes associated with this image. Defaults to None.\n    \"\"\"\n    self._image = image\n    self._geometric_shapes = GeometricShapes(self, geometric_shapes)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.image","title":"image  <code>property</code>","text":"<pre><code>image: T\n</code></pre> <p>Get the underlying image implementation.</p> RETURNS DESCRIPTION <code>T</code> <p>The wrapped image backend instance (e.g., RasterioLibImage, SpectralLibImage, MockImage).</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.geometric_shapes","title":"geometric_shapes  <code>property</code>","text":"<pre><code>geometric_shapes: GeometricShapes\n</code></pre> <p>Get the geometric shapes associated with this image.</p> RETURNS DESCRIPTION <code>GeometricShapes</code> <p>A GeometricShapes instance containing all shapes linked to this image.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.filepath","title":"filepath  <code>property</code>","text":"<pre><code>filepath: Path\n</code></pre> <p>Get the file path of the image.</p> RETURNS DESCRIPTION <code>Path</code> <p>A Path object representing the location of the image file.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.metadata","title":"metadata  <code>property</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Get the image metadata.</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>A dictionary containing image metadata such as coordinate reference system, geotransform information, and other image properties.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.shape","title":"shape  <code>property</code>","text":"<pre><code>shape: tuple[int, int, int]\n</code></pre> <p>Get the dimensions of the image.</p> RETURNS DESCRIPTION <code>tuple[int, int, int]</code> <p>A tuple (height, width, bands) representing the image dimensions.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.width","title":"width  <code>property</code>","text":"<pre><code>width: int\n</code></pre> <p>Get the width of the image in pixels.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of pixels in the horizontal dimension.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.height","title":"height  <code>property</code>","text":"<pre><code>height: int\n</code></pre> <p>Get the height of the image in pixels.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of pixels in the vertical dimension.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.bands","title":"bands  <code>property</code>","text":"<pre><code>bands: int\n</code></pre> <p>Get the number of spectral bands in the image.</p> RETURNS DESCRIPTION <code>int</code> <p>The number of spectral bands (channels) in the image.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.default_bands","title":"default_bands  <code>property</code>","text":"<pre><code>default_bands: list[int]\n</code></pre> <p>Get the default band indices for RGB display.</p> RETURNS DESCRIPTION <code>list[int]</code> <p>A list of band indices typically used for red, green, and blue channels when displaying the image as an RGB composite.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.wavelengths","title":"wavelengths  <code>property</code>","text":"<pre><code>wavelengths: list[float]\n</code></pre> <p>Get the wavelengths corresponding to each spectral band.</p> RETURNS DESCRIPTION <code>list[float]</code> <p>A list of wavelength values (typically in nanometers) for each band. The length of this list equals the number of bands.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.camera_id","title":"camera_id  <code>property</code>","text":"<pre><code>camera_id: str\n</code></pre> <p>Get the camera or sensor identifier.</p> RETURNS DESCRIPTION <code>str</code> <p>A string identifying the camera or sensor used to capture the image.</p>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.spy_open","title":"spy_open  <code>classmethod</code>","text":"<pre><code>spy_open(\n    *,\n    header_path: str | Path,\n    image_path: str | Path | None = None,\n) -&gt; SpectralImage[SpectralLibImage]\n</code></pre> <p>Open a spectral image using the SpectralPython library backend.</p> PARAMETER DESCRIPTION <code>header_path</code> <p>Path to the header file (.hdr) containing image metadata.</p> <p> TYPE: <code>str | Path</code> </p> <code>image_path</code> <p>Optional path to the image data file. If None, inferred from header_path.</p> <p> TYPE: <code>str | Path | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>SpectralImage[SpectralLibImage]</code> <p>A SpectralImage instance wrapping a SpectralLibImage backend.</p> Example <pre><code># Open an ENVI format image\nimage = SpectralImage.spy_open(header_path=\"image.hdr\")\n\n# Open with explicit image file path\nimage = SpectralImage.spy_open(\n    header_path=\"image.hdr\",\n    image_path=\"image.dat\"\n)\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>@classmethod\ndef spy_open(\n    cls, *, header_path: str | Path, image_path: str | Path | None = None\n) -&gt; \"SpectralImage[SpectralLibImage]\":\n    \"\"\"Open a spectral image using the SpectralPython library backend.\n\n    Args:\n        header_path: Path to the header file (.hdr) containing image metadata.\n        image_path: Optional path to the image data file. If None, inferred from header_path.\n\n    Returns:\n        A SpectralImage instance wrapping a SpectralLibImage backend.\n\n    Example:\n        ```python\n        # Open an ENVI format image\n        image = SpectralImage.spy_open(header_path=\"image.hdr\")\n\n        # Open with explicit image file path\n        image = SpectralImage.spy_open(\n            header_path=\"image.hdr\",\n            image_path=\"image.dat\"\n        )\n        ```\n    \"\"\"\n    image = SpectralLibImage.open(header_path=header_path, image_path=image_path)\n    return SpectralImage(image)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.rasterio_open","title":"rasterio_open  <code>classmethod</code>","text":"<pre><code>rasterio_open(\n    filepath: str | Path,\n) -&gt; SpectralImage[RasterioLibImage]\n</code></pre> <p>Open a spectral image using the Rasterio library backend.</p> PARAMETER DESCRIPTION <code>filepath</code> <p>Path to the image file (supports formats like GeoTIFF, etc.).</p> <p> TYPE: <code>str | Path</code> </p> RETURNS DESCRIPTION <code>SpectralImage[RasterioLibImage]</code> <p>A SpectralImage instance wrapping a RasterioLibImage backend.</p> Example <pre><code># Open a GeoTIFF file\nimage = SpectralImage.rasterio_open(\"image.tif\")\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>@classmethod\ndef rasterio_open(cls, filepath: str | Path) -&gt; \"SpectralImage[RasterioLibImage]\":\n    \"\"\"Open a spectral image using the Rasterio library backend.\n\n    Args:\n        filepath: Path to the image file (supports formats like GeoTIFF, etc.).\n\n    Returns:\n        A SpectralImage instance wrapping a RasterioLibImage backend.\n\n    Example:\n        ```python\n        # Open a GeoTIFF file\n        image = SpectralImage.rasterio_open(\"image.tif\")\n        ```\n    \"\"\"\n    image = RasterioLibImage.open(filepath)\n    return SpectralImage(image)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.from_numpy","title":"from_numpy  <code>classmethod</code>","text":"<pre><code>from_numpy(\n    array: NDArray[floating[Any]],\n) -&gt; SpectralImage[MockImage]\n</code></pre> <p>Create a spectral image from a numpy array using the mock backend.</p> PARAMETER DESCRIPTION <code>array</code> <p>A 3D numpy array with shape (height, width, bands) containing spectral data.</p> <p> TYPE: <code>NDArray[floating[Any]]</code> </p> RETURNS DESCRIPTION <code>SpectralImage[MockImage]</code> <p>A SpectralImage instance wrapping a MockImage backend.</p> Example <pre><code>import numpy as np\n\n# Create a synthetic spectral image\ndata = np.random.rand(100, 100, 10)  # 100x100 image with 10 bands\nimage = SpectralImage.from_numpy(data)\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>@classmethod\ndef from_numpy(cls, array: NDArray[np.floating[Any]]) -&gt; \"SpectralImage[MockImage]\":\n    \"\"\"Create a spectral image from a numpy array using the mock backend.\n\n    Args:\n        array: A 3D numpy array with shape (height, width, bands) containing spectral data.\n\n    Returns:\n        A SpectralImage instance wrapping a MockImage backend.\n\n    Example:\n        ```python\n        import numpy as np\n\n        # Create a synthetic spectral image\n        data = np.random.rand(100, 100, 10)  # 100x100 image with 10 bands\n        image = SpectralImage.from_numpy(data)\n        ```\n    \"\"\"\n    image = MockImage.open(array)\n    return SpectralImage(image)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.to_display","title":"to_display","text":"<pre><code>to_display(equalize: bool = True) -&gt; Image\n</code></pre> <p>Convert the image to a PIL Image for display purposes.</p> PARAMETER DESCRIPTION <code>equalize</code> <p>Whether to apply histogram equalization to enhance contrast. Defaults to True.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Image</code> <p>A PIL Image object suitable for display, typically as an RGB composite.</p> Example <pre><code># Display the image with default settings\npil_image = spectral_image.to_display()\npil_image.show()\n\n# Display without histogram equalization\npil_image = spectral_image.to_display(equalize=False)\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def to_display(self, equalize: bool = True) -&gt; Image.Image:\n    \"\"\"Convert the image to a PIL Image for display purposes.\n\n    Args:\n        equalize: Whether to apply histogram equalization to enhance contrast. Defaults to True.\n\n    Returns:\n        A PIL Image object suitable for display, typically as an RGB composite.\n\n    Example:\n        ```python\n        # Display the image with default settings\n        pil_image = spectral_image.to_display()\n        pil_image.show()\n\n        # Display without histogram equalization\n        pil_image = spectral_image.to_display(equalize=False)\n        ```\n    \"\"\"\n    return self.image.to_display(equalize)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy(\n    nan_value: float | None = None,\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Convert the image to a numpy array.</p> PARAMETER DESCRIPTION <code>nan_value</code> <p>Optional value to replace NaN values with. If None, NaN values are preserved.</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>NDArray[floating[Any]]</code> <p>A 3D numpy array with shape (height, width, bands) containing the spectral data.</p> Example <pre><code># Get the raw data with NaN values preserved\ndata = spectral_image.to_numpy()\n\n# Replace NaN values with zero\ndata = spectral_image.to_numpy(nan_value=0.0)\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def to_numpy(self, nan_value: float | None = None) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Convert the image to a numpy array.\n\n    Args:\n        nan_value: Optional value to replace NaN values with. If None, NaN values are preserved.\n\n    Returns:\n        A 3D numpy array with shape (height, width, bands) containing the spectral data.\n\n    Example:\n        ```python\n        # Get the raw data with NaN values preserved\n        data = spectral_image.to_numpy()\n\n        # Replace NaN values with zero\n        data = spectral_image.to_numpy(nan_value=0.0)\n        ```\n    \"\"\"\n    return self.image.to_numpy(nan_value)\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.to_xarray","title":"to_xarray","text":"<pre><code>to_xarray() -&gt; XarrayType\n</code></pre> <p>Convert the image to an xarray DataArray.</p> RETURNS DESCRIPTION <code>XarrayType</code> <p>An xarray DataArray with labeled dimensions and coordinates, suitable for advanced analysis and visualization.</p> Example <pre><code># Convert to xarray for analysis\nxr_data = spectral_image.to_xarray()\n\n# Access specific bands or wavelengths\nred_band = xr_data.sel(wavelength=650, method='nearest')\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def to_xarray(self) -&gt; \"XarrayType\":\n    \"\"\"Convert the image to an xarray DataArray.\n\n    Returns:\n        An xarray DataArray with labeled dimensions and coordinates, suitable for advanced analysis and visualization.\n\n    Example:\n        ```python\n        # Convert to xarray for analysis\n        xr_data = spectral_image.to_xarray()\n\n        # Access specific bands or wavelengths\n        red_band = xr_data.sel(wavelength=650, method='nearest')\n        ```\n    \"\"\"\n    return self.image.to_xarray()\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.to_signatures","title":"to_signatures","text":"<pre><code>to_signatures(\n    pixels: Pixels | DataFrame | Iterable[CoordinateInput],\n) -&gt; Signatures\n</code></pre> <p>Extract spectral signatures from specific pixel locations.</p> PARAMETER DESCRIPTION <code>pixels</code> <p>Pixel coordinates to extract signatures from. Can be a Pixels object,     pandas DataFrame with 'x' and 'y' columns, or an iterable of coordinate tuples.</p> <p> TYPE: <code>Pixels | DataFrame | Iterable[CoordinateInput]</code> </p> RETURNS DESCRIPTION <code>Signatures</code> <p>A Signatures object containing the spectral data for the specified pixels.</p> Example <pre><code># Extract signatures from specific coordinates\ncoords = [(10, 20), (30, 40), (50, 60)]\nsignatures = spectral_image.to_signatures(coords)\n\n# Extract signatures from a DataFrame\nimport pandas as pd\ndf = pd.DataFrame({'x': [10, 30, 50], 'y': [20, 40, 60]})\nsignatures = spectral_image.to_signatures(df)\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def to_signatures(self, pixels: Pixels | pd.DataFrame | Iterable[CoordinateInput]) -&gt; Signatures:\n    \"\"\"Extract spectral signatures from specific pixel locations.\n\n    Args:\n        pixels: Pixel coordinates to extract signatures from. Can be a Pixels object,\n                pandas DataFrame with 'x' and 'y' columns, or an iterable of coordinate tuples.\n\n    Returns:\n        A Signatures object containing the spectral data for the specified pixels.\n\n    Example:\n        ```python\n        # Extract signatures from specific coordinates\n        coords = [(10, 20), (30, 40), (50, 60)]\n        signatures = spectral_image.to_signatures(coords)\n\n        # Extract signatures from a DataFrame\n        import pandas as pd\n        df = pd.DataFrame({'x': [10, 30, 50], 'y': [20, 40, 60]})\n        signatures = spectral_image.to_signatures(df)\n        ```\n    \"\"\"\n    pixels = validate_pixel_input(pixels)\n    image_arr = self.to_numpy()\n    signatures = Signatures.from_array_and_pixels(image_arr, pixels)\n    return signatures\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.to_subarray","title":"to_subarray","text":"<pre><code>to_subarray(\n    pixels: Pixels | DataFrame | Iterable[CoordinateInput],\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Extract a rectangular subarray containing the specified pixels.</p> <p>Creates a new array that encompasses all the specified pixel coordinates, with NaN values for pixels not in the original selection.</p> PARAMETER DESCRIPTION <code>pixels</code> <p>Pixel coordinates defining the region of interest. Can be a Pixels object,     pandas DataFrame with 'x' and 'y' columns, or an iterable of coordinate tuples.</p> <p> TYPE: <code>Pixels | DataFrame | Iterable[CoordinateInput]</code> </p> RETURNS DESCRIPTION <code>NDArray[floating[Any]]</code> <p>A 3D numpy array containing the subregion with shape (height, width, bands). Unselected pixels within the bounding rectangle are filled with NaN.</p> Example <pre><code># Extract a subarray around specific points\ncoords = [(10, 20), (15, 25), (12, 22)]\nsubarray = spectral_image.to_subarray(coords)\n\n# The resulting array will be 6x6x{bands} covering the bounding box\n# from (10,20) to (15,25) with only the specified pixels having data\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def to_subarray(self, pixels: Pixels | pd.DataFrame | Iterable[CoordinateInput]) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Extract a rectangular subarray containing the specified pixels.\n\n    Creates a new array that encompasses all the specified pixel coordinates,\n    with NaN values for pixels not in the original selection.\n\n    Args:\n        pixels: Pixel coordinates defining the region of interest. Can be a Pixels object,\n                pandas DataFrame with 'x' and 'y' columns, or an iterable of coordinate tuples.\n\n    Returns:\n        A 3D numpy array containing the subregion with shape (height, width, bands). Unselected pixels within the bounding rectangle are filled with NaN.\n\n    Example:\n        ```python\n        # Extract a subarray around specific points\n        coords = [(10, 20), (15, 25), (12, 22)]\n        subarray = spectral_image.to_subarray(coords)\n\n        # The resulting array will be 6x6x{bands} covering the bounding box\n        # from (10,20) to (15,25) with only the specified pixels having data\n        ```\n    \"\"\"\n    pixels = validate_pixel_input(pixels)\n    image_arr = self.to_numpy()\n    x_max = pixels.x().max()\n    x_min = pixels.x().min()\n    y_max = pixels.y().max()\n    y_min = pixels.y().min()\n    # create new image\n    image_arr_area = np.nan * np.ones((int(y_max - y_min + 1), int(x_max - x_min + 1), self.bands))\n    # convert original coordinates to coordinates for new image\n    y_norm = pixels.y() - y_min\n    x_norm = pixels.x() - x_min\n    # write values from original image to new image\n    image_arr_area[y_norm, x_norm, :] = image_arr[pixels.y(), pixels.x(), :]\n    return image_arr_area\n</code></pre>"},{"location":"api/entities/images/spimage/#siapy.entities.images.spimage.SpectralImage.average_intensity","title":"average_intensity","text":"<pre><code>average_intensity(\n    axis: int\n    | tuple[int, ...]\n    | Sequence[int]\n    | None = None,\n) -&gt; float | NDArray[floating[Any]]\n</code></pre> <p>Calculate the average intensity across specified dimensions.</p> PARAMETER DESCRIPTION <code>axis</code> <p>Axis or axes along which to compute the mean. If None, computes the mean over the entire array. Can be an integer, tuple of integers, or sequence of integers.    - axis=None: Average over all pixels and bands (returns single float)    - axis=(0,1): Average over spatial dimensions (returns array of band averages)    - axis=2: Average over spectral dimension (returns spatial average image)</p> <p> TYPE: <code>int | tuple[int, ...] | Sequence[int] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>float | NDArray[floating[Any]]</code> <p>Either a single float (if axis=None) or a numpy array with reduced dimensions. NaN values are ignored in the calculation.</p> Example <pre><code># Get overall average intensity\noverall_avg = spectral_image.average_intensity()\n\n# Get average spectrum (average over spatial dimensions)\navg_spectrum = spectral_image.average_intensity(axis=(0, 1))\n\n# Get spatial average (average over spectral dimension)\nspatial_avg = spectral_image.average_intensity(axis=2)\n</code></pre> Source code in <code>siapy/entities/images/spimage.py</code> <pre><code>def average_intensity(\n    self, axis: int | tuple[int, ...] | Sequence[int] | None = None\n) -&gt; float | NDArray[np.floating[Any]]:\n    \"\"\"Calculate the average intensity across specified dimensions.\n\n    Args:\n        axis: Axis or axes along which to compute the mean. If None, computes the mean over the entire array. Can be an integer, tuple of integers, or sequence of integers. &lt;br&gt;\n              - axis=None: Average over all pixels and bands (returns single float) &lt;br&gt;\n              - axis=(0,1): Average over spatial dimensions (returns array of band averages) &lt;br&gt;\n              - axis=2: Average over spectral dimension (returns spatial average image)\n\n    Returns:\n        Either a single float (if axis=None) or a numpy array with reduced dimensions. NaN values are ignored in the calculation.\n\n    Example:\n        ```python\n        # Get overall average intensity\n        overall_avg = spectral_image.average_intensity()\n\n        # Get average spectrum (average over spatial dimensions)\n        avg_spectrum = spectral_image.average_intensity(axis=(0, 1))\n\n        # Get spatial average (average over spectral dimension)\n        spatial_avg = spectral_image.average_intensity(axis=2)\n        ```\n    \"\"\"\n    image_arr = self.to_numpy()\n    return np.nanmean(image_arr, axis=axis)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/","title":"Geometric Shapes","text":""},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes","title":"siapy.entities.shapes.geometric_shapes","text":""},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes","title":"GeometricShapes  <code>dataclass</code>","text":"<pre><code>GeometricShapes(\n    image: SpectralImage[Any],\n    geometric_shapes: list[Shape] | None = None,\n)\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def __init__(\n    self,\n    image: \"SpectralImage[Any]\",\n    geometric_shapes: list[\"Shape\"] | None = None,\n):\n    self._image = image\n    self._geometric_shapes = geometric_shapes if geometric_shapes is not None else []\n    _check_shape_type(self._geometric_shapes, is_list=True)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.shapes","title":"shapes  <code>property</code> <code>writable</code>","text":"<pre><code>shapes: list[Shape]\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.append","title":"append","text":"<pre><code>append(shape: Shape) -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def append(self, shape: \"Shape\") -&gt; None:\n    _check_shape_type(shape, is_list=False)\n    self._geometric_shapes.append(shape)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.extend","title":"extend","text":"<pre><code>extend(shapes: Iterable[Shape]) -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def extend(self, shapes: Iterable[\"Shape\"]) -&gt; None:\n    _check_shape_type(shapes, is_list=True)\n    self._geometric_shapes.extend(shapes)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.insert","title":"insert","text":"<pre><code>insert(index: int, shape: Shape) -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def insert(self, index: int, shape: \"Shape\") -&gt; None:\n    _check_shape_type(shape, is_list=False)\n    self._geometric_shapes.insert(index, shape)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.remove","title":"remove","text":"<pre><code>remove(shape: Shape) -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def remove(self, shape: \"Shape\") -&gt; None:\n    _check_shape_type(shape, is_list=False)\n    self._geometric_shapes.remove(shape)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.pop","title":"pop","text":"<pre><code>pop(index: int = -1) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def pop(self, index: int = -1) -&gt; \"Shape\":\n    return self._geometric_shapes.pop(index)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.clear","title":"clear","text":"<pre><code>clear() -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def clear(self) -&gt; None:\n    self._geometric_shapes.clear()\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.index","title":"index","text":"<pre><code>index(\n    shape: Shape, start: int = 0, stop: int = maxsize\n) -&gt; int\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def index(self, shape: \"Shape\", start: int = 0, stop: int = sys.maxsize) -&gt; int:\n    _check_shape_type(shape, is_list=False)\n    return self._geometric_shapes.index(shape, start, stop)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.count","title":"count","text":"<pre><code>count(shape: Shape) -&gt; int\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def count(self, shape: \"Shape\") -&gt; int:\n    _check_shape_type(shape, is_list=False)\n    return self._geometric_shapes.count(shape)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.reverse","title":"reverse","text":"<pre><code>reverse() -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def reverse(self) -&gt; None:\n    self._geometric_shapes.reverse()\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.sort","title":"sort","text":"<pre><code>sort(key: Any = None, reverse: bool = False) -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def sort(self, key: Any = None, reverse: bool = False) -&gt; None:\n    self._geometric_shapes.sort(key=key, reverse=reverse)\n</code></pre>"},{"location":"api/entities/shapes/geometric_shapes/#siapy.entities.shapes.geometric_shapes.GeometricShapes.get_by_name","title":"get_by_name","text":"<pre><code>get_by_name(name: str) -&gt; Optional[Shape]\n</code></pre> Source code in <code>siapy/entities/shapes/geometric_shapes.py</code> <pre><code>def get_by_name(self, name: str) -&gt; Optional[\"Shape\"]:\n    names = [shape.label for shape in self.shapes]\n    if name in names:\n        index = names.index(name)\n        return self.shapes[index]\n    return None\n</code></pre>"},{"location":"api/entities/shapes/shape/","title":"Shape","text":""},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape","title":"siapy.entities.shapes.shape","text":""},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum","title":"ShapeGeometryEnum","text":"<p>               Bases: <code>Enum</code></p> <p>Geometry Types: - Point: Single coordinate point (x,y) - LineString: Series of connected points forming a line - Polygon: Closed shape with interior area - MultiPoint: Collection of independent points - MultiLineString: Collection of independent lines - MultiPolygon: Collection of independent polygons</p>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum.POINT","title":"POINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POINT = 'point'\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum.LINE","title":"LINE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>LINE = 'linestring'\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum.POLYGON","title":"POLYGON  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>POLYGON = 'polygon'\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum.MULTIPOINT","title":"MULTIPOINT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MULTIPOINT = 'multipoint'\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum.MULTILINE","title":"MULTILINE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MULTILINE = 'multilinestring'\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.ShapeGeometryEnum.MULTIPOLYGON","title":"MULTIPOLYGON  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>MULTIPOLYGON = 'multipolygon'\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape","title":"Shape  <code>dataclass</code>","text":"<pre><code>Shape(\n    label: str = \"\",\n    geometry: Optional[BaseGeometry] = None,\n    geo_dataframe: Optional[GeoDataFrame] = None,\n)\n</code></pre> <p>Unified shape class that can be created from shapefiles or programmatically.</p> <p>This class uses GeoDataFrame as its primary internal representation. Direct initialization is possible but using class methods is recommended.</p> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def __init__(\n    self,\n    label: str = \"\",\n    geometry: Optional[BaseGeometry] = None,\n    geo_dataframe: Optional[gpd.GeoDataFrame] = None,\n):\n    \"\"\"Initialize Shape with either a geometry or geodataframe\"\"\"\n    self._label = label\n\n    if geo_dataframe is not None and geometry is not None:\n        raise ConfigurationError(\"Cannot provide both geometry and geodataframe\")\n\n    if geo_dataframe is not None:\n        self._geodataframe = geo_dataframe\n    elif geometry is not None:\n        self._geodataframe = gpd.GeoDataFrame(geometry=[geometry])\n    else:\n        raise ConfigurationError(\"Must provide either geometry or geodataframe\")\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.df","title":"df  <code>property</code>","text":"<pre><code>df: GeoDataFrame\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.label","title":"label  <code>property</code> <code>writable</code>","text":"<pre><code>label: str\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.geometry","title":"geometry  <code>property</code> <code>writable</code>","text":"<pre><code>geometry: GeoSeries\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.shape_type","title":"shape_type  <code>property</code>","text":"<pre><code>shape_type: str\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.is_multi","title":"is_multi  <code>property</code>","text":"<pre><code>is_multi: bool\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.is_point","title":"is_point  <code>property</code>","text":"<pre><code>is_point: bool\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.is_line","title":"is_line  <code>property</code>","text":"<pre><code>is_line: bool\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.is_polygon","title":"is_polygon  <code>property</code>","text":"<pre><code>is_polygon: bool\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.boundary","title":"boundary  <code>property</code>","text":"<pre><code>boundary: GeoSeries\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.bounds","title":"bounds  <code>property</code>","text":"<pre><code>bounds: DataFrame\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.centroid","title":"centroid  <code>property</code>","text":"<pre><code>centroid: GeoSeries\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.convex_hull","title":"convex_hull  <code>property</code>","text":"<pre><code>convex_hull: GeoSeries\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.envelope","title":"envelope  <code>property</code>","text":"<pre><code>envelope: GeoSeries\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.exterior","title":"exterior  <code>property</code>","text":"<pre><code>exterior: GeoSeries\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.open_shapefile","title":"open_shapefile  <code>classmethod</code>","text":"<pre><code>open_shapefile(\n    filepath: str | Path, label: str = \"\"\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef open_shapefile(cls, filepath: str | Path, label: str = \"\") -&gt; \"Shape\":\n    filepath = Path(filepath)\n    if not filepath.exists():\n        raise InvalidFilepathError(filepath)\n    try:\n        geo_df = gpd.read_file(filepath)\n    except Exception as e:\n        raise InvalidInputError({\"filepath\": str(filepath)}, f\"Failed to open shapefile: {e}\") from e\n    return cls(geo_dataframe=geo_df, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_geometry","title":"from_geometry  <code>classmethod</code>","text":"<pre><code>from_geometry(\n    geometry: BaseGeometry, label: str = \"\"\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_geometry(cls, geometry: BaseGeometry, label: str = \"\") -&gt; \"Shape\":\n    if not isinstance(geometry, BaseGeometry):\n        raise InvalidTypeError(\n            input_value=geometry,\n            allowed_types=BaseGeometry,\n            message=\"Geometry must be of type BaseGeometry\",\n        )\n    return cls(geometry=geometry, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_geodataframe","title":"from_geodataframe  <code>classmethod</code>","text":"<pre><code>from_geodataframe(\n    geo_dataframe: GeoDataFrame, label: str = \"\"\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_geodataframe(cls, geo_dataframe: gpd.GeoDataFrame, label: str = \"\") -&gt; \"Shape\":\n    if not isinstance(geo_dataframe, gpd.GeoDataFrame):\n        raise InvalidTypeError(\n            input_value=geo_dataframe,\n            allowed_types=gpd.GeoDataFrame,\n            message=\"GeoDataFrame must be of type GeoDataFrame\",\n        )\n    return cls(geo_dataframe=geo_dataframe, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_point","title":"from_point  <code>classmethod</code>","text":"<pre><code>from_point(x: float, y: float, label: str = '') -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_point(cls, x: float, y: float, label: str = \"\") -&gt; \"Shape\":\n    return cls(geometry=Point(x, y), label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_multipoint","title":"from_multipoint  <code>classmethod</code>","text":"<pre><code>from_multipoint(\n    points: Pixels | DataFrame | Iterable[CoordinateInput],\n    label: str = \"\",\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_multipoint(cls, points: Pixels | pd.DataFrame | Iterable[CoordinateInput], label: str = \"\") -&gt; \"Shape\":\n    points = validate_pixel_input(points)\n    if len(points) &lt; 1:\n        raise ConfigurationError(\"At least one point is required\")\n    coords = points.to_list()\n    return cls(geometry=MultiPoint(coords), label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_line","title":"from_line  <code>classmethod</code>","text":"<pre><code>from_line(\n    pixels: Pixels | DataFrame | Iterable[CoordinateInput],\n    label: str = \"\",\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_line(cls, pixels: Pixels | pd.DataFrame | Iterable[CoordinateInput], label: str = \"\") -&gt; \"Shape\":\n    pixels = validate_pixel_input(pixels)\n    if len(pixels) &lt; 2:\n        raise ConfigurationError(\"At least two points are required for a line\")\n\n    return cls(geometry=LineString(pixels.to_list()), label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_multiline","title":"from_multiline  <code>classmethod</code>","text":"<pre><code>from_multiline(\n    line_segments: list[\n        Pixels | DataFrame | Iterable[CoordinateInput]\n    ],\n    label: str = \"\",\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_multiline(\n    cls, line_segments: list[Pixels | pd.DataFrame | Iterable[CoordinateInput]], label: str = \"\"\n) -&gt; \"Shape\":\n    if not line_segments:\n        raise ConfigurationError(\"At least one line segment is required\")\n\n    lines = []\n    for segment in line_segments:\n        validated_segment = validate_pixel_input(segment)\n        lines.append(LineString(validated_segment.to_list()))\n\n    multi_line = MultiLineString(lines)\n    return cls(geometry=multi_line, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_polygon","title":"from_polygon  <code>classmethod</code>","text":"<pre><code>from_polygon(\n    exterior: Pixels\n    | DataFrame\n    | Iterable[CoordinateInput],\n    holes: Optional[\n        list[Pixels | DataFrame | Iterable[CoordinateInput]]\n    ] = None,\n    label: str = \"\",\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_polygon(\n    cls,\n    exterior: Pixels | pd.DataFrame | Iterable[CoordinateInput],\n    holes: Optional[list[Pixels | pd.DataFrame | Iterable[CoordinateInput]]] = None,\n    label: str = \"\",\n) -&gt; \"Shape\":\n    exterior = validate_pixel_input(exterior)\n    if len(exterior) &lt; 3:\n        raise ConfigurationError(\"At least three points are required for a polygon\")\n\n    exterior_coords = exterior.to_list()\n    # Close the polygon if not already closed\n    if exterior_coords[0] != exterior_coords[-1]:\n        exterior_coords.append(exterior_coords[0])\n\n    if holes:\n        # Close each hole if not already closed\n        closed_holes = []\n        for hole in holes:\n            validated_hole = validate_pixel_input(hole)\n            hole_coords = validated_hole.to_list()\n            if hole_coords[0] != hole_coords[-1]:\n                hole_coords.append(hole_coords[0])\n            closed_holes.append(hole_coords)\n        geometry = Polygon(exterior_coords, closed_holes)\n    else:\n        geometry = Polygon(exterior_coords)\n\n    return cls(geometry=geometry, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_multipolygon","title":"from_multipolygon  <code>classmethod</code>","text":"<pre><code>from_multipolygon(\n    polygons: list[\n        Pixels | DataFrame | Iterable[CoordinateInput]\n    ],\n    label: str = \"\",\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_multipolygon(\n    cls, polygons: list[Pixels | pd.DataFrame | Iterable[CoordinateInput]], label: str = \"\"\n) -&gt; \"Shape\":\n    if not polygons:\n        raise ConfigurationError(\"At least one polygon is required\")\n\n    polygon_objects = []\n    for pixels in polygons:\n        validated_pixels = validate_pixel_input(pixels)\n        coords = validated_pixels.to_list()\n        # Close the polygon if not already closed\n        if coords[0] != coords[-1]:\n            coords.append(coords[0])\n        polygon_objects.append(Polygon(coords))\n\n    multi_polygon = MultiPolygon(polygon_objects)\n    return cls(geometry=multi_polygon, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_rectangle","title":"from_rectangle  <code>classmethod</code>","text":"<pre><code>from_rectangle(\n    x_min: int,\n    y_min: int,\n    x_max: int,\n    y_max: int,\n    label: str = \"\",\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_rectangle(cls, x_min: int, y_min: int, x_max: int, y_max: int, label: str = \"\") -&gt; \"Shape\":\n    coords = [(x_min, y_min), (x_max, y_min), (x_max, y_max), (x_min, y_max)]\n    return cls(geometry=Polygon(coords), label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.from_circle","title":"from_circle  <code>classmethod</code>","text":"<pre><code>from_circle(\n    center: PixelCoordinate, radius: float, label: str = \"\"\n) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>@classmethod\ndef from_circle(cls, center: PixelCoordinate, radius: float, label: str = \"\") -&gt; \"Shape\":\n    point = Point(center)\n    circle = point.buffer(radius)\n    return cls(geometry=circle, label=label)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.copy","title":"copy","text":"<pre><code>copy() -&gt; Shape\n</code></pre> <p>Create a deep copy of the Shape instance.</p> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def copy(self) -&gt; \"Shape\":\n    \"\"\"Create a deep copy of the Shape instance.\"\"\"\n    copied_df = self.df.copy(deep=True)\n    return Shape(label=self.label, geo_dataframe=copied_df)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.buffer","title":"buffer","text":"<pre><code>buffer(distance: float) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def buffer(self, distance: float) -&gt; \"Shape\":\n    buffered_geometry = self.geometry.buffer(distance)\n    result = self.copy()\n    result.geometry = buffered_geometry\n    return result\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.intersection","title":"intersection","text":"<pre><code>intersection(other: Shape) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def intersection(self, other: \"Shape\") -&gt; \"Shape\":\n    intersection_geometry = self.geometry.intersection(other.geometry)\n    result = self.copy()\n    result.geometry = intersection_geometry\n    return result\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.union","title":"union","text":"<pre><code>union(other: Shape) -&gt; Shape\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def union(self, other: \"Shape\") -&gt; \"Shape\":\n    union_geometry = self.geometry.union(other.geometry)\n    result = self.copy()\n    result.geometry = union_geometry\n    return result\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.to_file","title":"to_file","text":"<pre><code>to_file(\n    filepath: str | Path, driver: str = \"ESRI Shapefile\"\n) -&gt; None\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def to_file(self, filepath: str | Path, driver: str = \"ESRI Shapefile\") -&gt; None:\n    self._geodataframe.to_file(filepath, driver=driver)\n</code></pre>"},{"location":"api/entities/shapes/shape/#siapy.entities.shapes.shape.Shape.to_numpy","title":"to_numpy","text":"<pre><code>to_numpy() -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/entities/shapes/shape.py</code> <pre><code>def to_numpy(self) -&gt; NDArray[np.floating[Any]]:\n    return self.df.to_numpy()\n</code></pre>"},{"location":"api/features/features/","title":"Features","text":""},{"location":"api/features/features/#siapy.features.features","title":"siapy.features.features","text":""},{"location":"api/features/features/#siapy.features.features.AutoFeatClassification","title":"AutoFeatClassification","text":"<pre><code>AutoFeatClassification(\n    *,\n    categorical_cols: list[str] | None = None,\n    feateng_cols: list[str] | None = None,\n    units: dict[str, str] | None = None,\n    feateng_steps: int = 2,\n    featsel_runs: int = 5,\n    max_gb: int | None = None,\n    transformations: list[str] | tuple[str, ...] = (\n        \"1/\",\n        \"exp\",\n        \"log\",\n        \"abs\",\n        \"sqrt\",\n        \"^2\",\n        \"^3\",\n    ),\n    apply_pi_theorem: bool = True,\n    always_return_numpy: bool = False,\n    n_jobs: int = 1,\n    verbose: int = 0,\n    random_seed: int | None = None,\n)\n</code></pre> <p>               Bases: <code>AutoFeatClassifier</code></p> Source code in <code>siapy/features/features.py</code> <pre><code>def __init__(\n    self,\n    *,\n    categorical_cols: list[str] | None = None,\n    feateng_cols: list[str] | None = None,\n    units: dict[str, str] | None = None,\n    feateng_steps: int = 2,\n    featsel_runs: int = 5,\n    max_gb: int | None = None,\n    transformations: list[str] | tuple[str, ...] = (\n        \"1/\",\n        \"exp\",\n        \"log\",\n        \"abs\",\n        \"sqrt\",\n        \"^2\",\n        \"^3\",\n    ),\n    apply_pi_theorem: bool = True,\n    always_return_numpy: bool = False,\n    n_jobs: int = 1,\n    verbose: int = 0,\n    random_seed: int | None = None,\n):\n    self.random_seed = random_seed\n    set_random_seed(self.random_seed)\n    super().__init__(\n        categorical_cols=categorical_cols,\n        feateng_cols=feateng_cols,\n        units=units,\n        feateng_steps=feateng_steps,\n        featsel_runs=featsel_runs,\n        max_gb=max_gb,\n        transformations=transformations,\n        apply_pi_theorem=apply_pi_theorem,\n        always_return_numpy=always_return_numpy,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatClassification.random_seed","title":"random_seed  <code>instance-attribute</code>","text":"<pre><code>random_seed = random_seed\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatClassification.fit","title":"fit","text":"<pre><code>fit(\n    data: ndarray[Any, Any] | DataFrame,\n    target: ndarray[Any, Any] | DataFrame,\n) -&gt; \"AutoFeatClassification\"\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit(\n    self, data: np.ndarray[Any, Any] | pd.DataFrame, target: np.ndarray[Any, Any] | pd.DataFrame\n) -&gt; \"AutoFeatClassification\":\n    set_random_seed(self.random_seed)\n    super().fit(data, target)\n    return self\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatClassification.transform","title":"transform","text":"<pre><code>transform(\n    data: ndarray[Any, Any] | DataFrame,\n) -&gt; ndarray[Any, Any] | DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def transform(self, data: np.ndarray[Any, Any] | pd.DataFrame) -&gt; np.ndarray[Any, Any] | pd.DataFrame:\n    set_random_seed(self.random_seed)\n    data_transformed = super().transform(data)\n    return data_transformed\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatClassification.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    data: ndarray[Any, Any] | DataFrame,\n    target: ndarray[Any, Any] | DataFrame,\n) -&gt; ndarray[Any, Any] | DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit_transform(\n    self, data: np.ndarray[Any, Any] | pd.DataFrame, target: np.ndarray[Any, Any] | pd.DataFrame\n) -&gt; np.ndarray[Any, Any] | pd.DataFrame:\n    set_random_seed(self.random_seed)\n    data_transformed = super().fit_transform(data, target)\n    return data_transformed\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatRegression","title":"AutoFeatRegression","text":"<pre><code>AutoFeatRegression(\n    *,\n    categorical_cols: list[str] | None = None,\n    feateng_cols: list[str] | None = None,\n    units: dict[str, str] | None = None,\n    feateng_steps: int = 2,\n    featsel_runs: int = 5,\n    max_gb: int | None = None,\n    transformations: list[str] | tuple[str, ...] = (\n        \"1/\",\n        \"exp\",\n        \"log\",\n        \"abs\",\n        \"sqrt\",\n        \"^2\",\n        \"^3\",\n    ),\n    apply_pi_theorem: bool = True,\n    always_return_numpy: bool = False,\n    n_jobs: int = 1,\n    verbose: int = 0,\n    random_seed: int | None = None,\n)\n</code></pre> <p>               Bases: <code>AutoFeatRegressor</code></p> Source code in <code>siapy/features/features.py</code> <pre><code>def __init__(\n    self,\n    *,\n    categorical_cols: list[str] | None = None,\n    feateng_cols: list[str] | None = None,\n    units: dict[str, str] | None = None,\n    feateng_steps: int = 2,\n    featsel_runs: int = 5,\n    max_gb: int | None = None,\n    transformations: list[str] | tuple[str, ...] = (\n        \"1/\",\n        \"exp\",\n        \"log\",\n        \"abs\",\n        \"sqrt\",\n        \"^2\",\n        \"^3\",\n    ),\n    apply_pi_theorem: bool = True,\n    always_return_numpy: bool = False,\n    n_jobs: int = 1,\n    verbose: int = 0,\n    random_seed: int | None = None,\n):\n    self.random_seed = random_seed\n    set_random_seed(self.random_seed)\n    super().__init__(\n        categorical_cols=categorical_cols,\n        feateng_cols=feateng_cols,\n        units=units,\n        feateng_steps=feateng_steps,\n        featsel_runs=featsel_runs,\n        max_gb=max_gb,\n        transformations=transformations,\n        apply_pi_theorem=apply_pi_theorem,\n        always_return_numpy=always_return_numpy,\n        n_jobs=n_jobs,\n        verbose=verbose,\n    )\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatRegression.random_seed","title":"random_seed  <code>instance-attribute</code>","text":"<pre><code>random_seed = random_seed\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatRegression.fit","title":"fit","text":"<pre><code>fit(\n    data: ndarray[Any, Any] | DataFrame,\n    target: ndarray[Any, Any] | DataFrame,\n) -&gt; \"AutoFeatRegression\"\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit(\n    self, data: np.ndarray[Any, Any] | pd.DataFrame, target: np.ndarray[Any, Any] | pd.DataFrame\n) -&gt; \"AutoFeatRegression\":\n    set_random_seed(self.random_seed)\n    super().fit(data, target)\n    return self\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatRegression.transform","title":"transform","text":"<pre><code>transform(\n    data: ndarray[Any, Any] | DataFrame,\n) -&gt; ndarray[Any, Any] | DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def transform(self, data: np.ndarray[Any, Any] | pd.DataFrame) -&gt; np.ndarray[Any, Any] | pd.DataFrame:\n    set_random_seed(self.random_seed)\n    data_transformed = super().transform(data)\n    return data_transformed\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoFeatRegression.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    data: ndarray[Any, Any] | DataFrame,\n    target: ndarray[Any, Any] | DataFrame,\n) -&gt; ndarray[Any, Any] | DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit_transform(\n    self, data: np.ndarray[Any, Any] | pd.DataFrame, target: np.ndarray[Any, Any] | pd.DataFrame\n) -&gt; np.ndarray[Any, Any] | pd.DataFrame:\n    set_random_seed(self.random_seed)\n    data_transformed = super().fit_transform(data, target)\n    return data_transformed\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices","title":"AutoSpectralIndices","text":"<pre><code>AutoSpectralIndices(\n    problem_type: Literal[\"regression\", \"classification\"],\n    spectral_indices: str | Iterable[str],\n    *,\n    selector_config: FeatureSelectorConfig = FeatureSelectorConfig(),\n    bands_map: dict[str, str] | None = None,\n    merge_with_original: bool = True,\n)\n</code></pre> <p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> Source code in <code>siapy/features/features.py</code> <pre><code>def __init__(\n    self,\n    problem_type: Literal[\"regression\", \"classification\"],\n    spectral_indices: str | Iterable[str],\n    *,\n    selector_config: FeatureSelectorConfig = FeatureSelectorConfig(),\n    bands_map: dict[str, str] | None = None,\n    merge_with_original: bool = True,\n):\n    self.spectral_indices = spectral_indices\n    self.selector = feature_selector_factory(problem_type=problem_type, config=selector_config)\n    self.bands_map = bands_map\n    self.merge_with_original = merge_with_original\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.spectral_indices","title":"spectral_indices  <code>instance-attribute</code>","text":"<pre><code>spectral_indices = spectral_indices\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.selector","title":"selector  <code>instance-attribute</code>","text":"<pre><code>selector = feature_selector_factory(\n    problem_type=problem_type, config=selector_config\n)\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.bands_map","title":"bands_map  <code>instance-attribute</code>","text":"<pre><code>bands_map = bands_map\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.merge_with_original","title":"merge_with_original  <code>instance-attribute</code>","text":"<pre><code>merge_with_original = merge_with_original\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.fit","title":"fit","text":"<pre><code>fit(\n    data: DataFrame, target: \"pd.Series[Any]\"\n) -&gt; BaseEstimator\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit(self, data: pd.DataFrame, target: \"pd.Series[Any]\") -&gt; BaseEstimator:\n    df_indices = compute_spectral_indices(\n        data=data,\n        spectral_indices=self.spectral_indices,\n        bands_map=self.bands_map,\n    )\n    self.selector.fit(df_indices, target)\n    return self\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.transform","title":"transform","text":"<pre><code>transform(data: DataFrame) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def transform(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n    df_indices = compute_spectral_indices(\n        data=data,\n        spectral_indices=self.spectral_indices,\n        bands_map=self.bands_map,\n    )\n    if hasattr(self.selector[1], \"k_feature_idx_\"):\n        columns_select_idx = list(self.selector[1].k_feature_idx_)\n        df_indices = df_indices.iloc[:, columns_select_idx]\n    else:\n        raise MethodNotImplementedError(self.selector[1].__class__.__name__, \"k_feature_idx_\")\n    if self.merge_with_original:\n        return pd.concat([data, df_indices], axis=1)\n    return df_indices\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndices.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    data: DataFrame, target: \"pd.Series[Any]\"\n) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit_transform(self, data: pd.DataFrame, target: \"pd.Series[Any]\") -&gt; pd.DataFrame:\n    self.fit(data, target)\n    return self.transform(data)\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification","title":"AutoSpectralIndicesClassification","text":"<pre><code>AutoSpectralIndicesClassification(\n    spectral_indices: str | Iterable[str],\n    *,\n    selector_config: FeatureSelectorConfig = FeatureSelectorConfig(),\n    bands_map: dict[str, str] | None = None,\n    merge_with_original: bool = True,\n)\n</code></pre> <p>               Bases: <code>AutoSpectralIndices</code></p> Source code in <code>siapy/features/features.py</code> <pre><code>def __init__(\n    self,\n    spectral_indices: str | Iterable[str],\n    *,\n    selector_config: FeatureSelectorConfig = FeatureSelectorConfig(),\n    bands_map: dict[str, str] | None = None,\n    merge_with_original: bool = True,\n):\n    super().__init__(\n        problem_type=\"classification\",\n        spectral_indices=spectral_indices,\n        selector_config=selector_config,\n        bands_map=bands_map,\n        merge_with_original=merge_with_original,\n    )\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.spectral_indices","title":"spectral_indices  <code>instance-attribute</code>","text":"<pre><code>spectral_indices = spectral_indices\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.selector","title":"selector  <code>instance-attribute</code>","text":"<pre><code>selector = feature_selector_factory(\n    problem_type=problem_type, config=selector_config\n)\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.bands_map","title":"bands_map  <code>instance-attribute</code>","text":"<pre><code>bands_map = bands_map\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.merge_with_original","title":"merge_with_original  <code>instance-attribute</code>","text":"<pre><code>merge_with_original = merge_with_original\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.fit","title":"fit","text":"<pre><code>fit(\n    data: DataFrame, target: \"pd.Series[Any]\"\n) -&gt; BaseEstimator\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit(self, data: pd.DataFrame, target: \"pd.Series[Any]\") -&gt; BaseEstimator:\n    df_indices = compute_spectral_indices(\n        data=data,\n        spectral_indices=self.spectral_indices,\n        bands_map=self.bands_map,\n    )\n    self.selector.fit(df_indices, target)\n    return self\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.transform","title":"transform","text":"<pre><code>transform(data: DataFrame) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def transform(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n    df_indices = compute_spectral_indices(\n        data=data,\n        spectral_indices=self.spectral_indices,\n        bands_map=self.bands_map,\n    )\n    if hasattr(self.selector[1], \"k_feature_idx_\"):\n        columns_select_idx = list(self.selector[1].k_feature_idx_)\n        df_indices = df_indices.iloc[:, columns_select_idx]\n    else:\n        raise MethodNotImplementedError(self.selector[1].__class__.__name__, \"k_feature_idx_\")\n    if self.merge_with_original:\n        return pd.concat([data, df_indices], axis=1)\n    return df_indices\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesClassification.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    data: DataFrame, target: \"pd.Series[Any]\"\n) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit_transform(self, data: pd.DataFrame, target: \"pd.Series[Any]\") -&gt; pd.DataFrame:\n    self.fit(data, target)\n    return self.transform(data)\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression","title":"AutoSpectralIndicesRegression","text":"<pre><code>AutoSpectralIndicesRegression(\n    spectral_indices: str | Iterable[str],\n    *,\n    selector_config: FeatureSelectorConfig = FeatureSelectorConfig(),\n    bands_map: dict[str, str] | None = None,\n    merge_with_original: bool = True,\n)\n</code></pre> <p>               Bases: <code>AutoSpectralIndices</code></p> Source code in <code>siapy/features/features.py</code> <pre><code>def __init__(\n    self,\n    spectral_indices: str | Iterable[str],\n    *,\n    selector_config: FeatureSelectorConfig = FeatureSelectorConfig(),\n    bands_map: dict[str, str] | None = None,\n    merge_with_original: bool = True,\n):\n    super().__init__(\n        problem_type=\"regression\",\n        spectral_indices=spectral_indices,\n        selector_config=selector_config,\n        bands_map=bands_map,\n        merge_with_original=merge_with_original,\n    )\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.spectral_indices","title":"spectral_indices  <code>instance-attribute</code>","text":"<pre><code>spectral_indices = spectral_indices\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.selector","title":"selector  <code>instance-attribute</code>","text":"<pre><code>selector = feature_selector_factory(\n    problem_type=problem_type, config=selector_config\n)\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.bands_map","title":"bands_map  <code>instance-attribute</code>","text":"<pre><code>bands_map = bands_map\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.merge_with_original","title":"merge_with_original  <code>instance-attribute</code>","text":"<pre><code>merge_with_original = merge_with_original\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.fit","title":"fit","text":"<pre><code>fit(\n    data: DataFrame, target: \"pd.Series[Any]\"\n) -&gt; BaseEstimator\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit(self, data: pd.DataFrame, target: \"pd.Series[Any]\") -&gt; BaseEstimator:\n    df_indices = compute_spectral_indices(\n        data=data,\n        spectral_indices=self.spectral_indices,\n        bands_map=self.bands_map,\n    )\n    self.selector.fit(df_indices, target)\n    return self\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.transform","title":"transform","text":"<pre><code>transform(data: DataFrame) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def transform(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n    df_indices = compute_spectral_indices(\n        data=data,\n        spectral_indices=self.spectral_indices,\n        bands_map=self.bands_map,\n    )\n    if hasattr(self.selector[1], \"k_feature_idx_\"):\n        columns_select_idx = list(self.selector[1].k_feature_idx_)\n        df_indices = df_indices.iloc[:, columns_select_idx]\n    else:\n        raise MethodNotImplementedError(self.selector[1].__class__.__name__, \"k_feature_idx_\")\n    if self.merge_with_original:\n        return pd.concat([data, df_indices], axis=1)\n    return df_indices\n</code></pre>"},{"location":"api/features/features/#siapy.features.features.AutoSpectralIndicesRegression.fit_transform","title":"fit_transform","text":"<pre><code>fit_transform(\n    data: DataFrame, target: \"pd.Series[Any]\"\n) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/features.py</code> <pre><code>def fit_transform(self, data: pd.DataFrame, target: \"pd.Series[Any]\") -&gt; pd.DataFrame:\n    self.fit(data, target)\n    return self.transform(data)\n</code></pre>"},{"location":"api/features/helpers/","title":"Helpers","text":""},{"location":"api/features/helpers/#siapy.features.helpers","title":"siapy.features.helpers","text":""},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig","title":"FeatureSelectorConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.k_features","title":"k_features  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>k_features: int | str | tuple[int, ...] = (1, 20)\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.cv","title":"cv  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cv: int = 3\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.forward","title":"forward  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>forward: bool = True\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.floating","title":"floating  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>floating: bool = True\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.verbose","title":"verbose  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>verbose: int = 2\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.n_jobs","title":"n_jobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_jobs: int = 1\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.pre_dispatch","title":"pre_dispatch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pre_dispatch: int | str = '2*n_jobs'\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.FeatureSelectorConfig.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(\n    arbitrary_types_allowed=True, validate_assignment=True\n)\n</code></pre>"},{"location":"api/features/helpers/#siapy.features.helpers.feature_selector_factory","title":"feature_selector_factory","text":"<pre><code>feature_selector_factory(\n    problem_type: Literal[\"regression\", \"classification\"],\n    *,\n    k_features: int | str | tuple[int, ...] = (1, 20),\n    cv: int = 3,\n    forward: bool = True,\n    floating: bool = True,\n    verbose: int = 2,\n    n_jobs: int = 1,\n    pre_dispatch: int | str = \"2*n_jobs\",\n    config: FeatureSelectorConfig | None = None,\n) -&gt; Pipeline\n</code></pre> Source code in <code>siapy/features/helpers.py</code> <pre><code>def feature_selector_factory(\n    problem_type: Literal[\"regression\", \"classification\"],\n    *,\n    k_features: Annotated[\n        int | str | tuple[int, ...],\n        \"can be: 'best' - most extensive, (1, n) - check range of features, n - exact number of features\",\n    ] = (1, 20),\n    cv: int = 3,\n    forward: Annotated[bool, \"selection in forward direction\"] = True,\n    floating: Annotated[bool, \"floating algorithm - can go back and remove features once added\"] = True,\n    verbose: int = 2,\n    n_jobs: int = 1,\n    pre_dispatch: int | str = \"2*n_jobs\",\n    config: Annotated[\n        FeatureSelectorConfig | None,\n        \"If provided, other arguments are overwritten by config values\",\n    ] = None,\n) -&gt; Pipeline:\n    if config:\n        k_features = config.k_features\n        cv = config.cv\n        forward = config.forward\n        floating = config.floating\n        verbose = config.verbose\n        n_jobs = config.n_jobs\n        pre_dispatch = config.pre_dispatch\n\n    if problem_type == \"regression\":\n        algo = Ridge()\n        scoring = \"neg_mean_squared_error\"\n    elif problem_type == \"classification\":\n        algo = RidgeClassifier()\n        scoring = \"f1_weighted\"\n    else:\n        raise InvalidInputError(\n            problem_type,\n            \"Invalid problem type, possible values are: 'regression' or 'classification'\",\n        )\n    sfs = SequentialFeatureSelector(\n        estimator=algo,\n        k_features=k_features,  # type: ignore # noqa\n        forward=forward,\n        floating=floating,\n        verbose=verbose,\n        scoring=scoring,\n        cv=cv,\n        n_jobs=n_jobs,\n        pre_dispatch=pre_dispatch,  # type: ignore # noqa\n    )\n    return make_pipeline(RobustScaler(), sfs, memory=None)\n</code></pre>"},{"location":"api/features/spectral_indices/","title":"Spectral Indices","text":""},{"location":"api/features/spectral_indices/#siapy.features.spectral_indices","title":"siapy.features.spectral_indices","text":""},{"location":"api/features/spectral_indices/#siapy.features.spectral_indices.get_spectral_indices","title":"get_spectral_indices","text":"<pre><code>get_spectral_indices(\n    bands_acronym: str | Iterable[str],\n) -&gt; dict[str, SpectralIndex]\n</code></pre> Source code in <code>siapy/features/spectral_indices.py</code> <pre><code>def get_spectral_indices(\n    bands_acronym: str | Iterable[str],\n) -&gt; dict[str, spyndex.axioms.SpectralIndex]:\n    bands_acronym = _convert_str_to_list(bands_acronym)\n    bands_acronym_set = set(bands_acronym)\n\n    if not bands_acronym_set.issubset(list(spyndex.bands)):\n        raise InvalidInputError(\n            {\n                \"received_bands_acronym\": bands_acronym_set,\n                \"valid_bands_acronym\": list(spyndex.bands),\n            },\n            \"Invalid input argument for 'bands_acronym'. Please ensure that all elements in 'bands_acronym' are valid band acronyms.\",\n        )\n\n    spectral_indexes = {}\n    for name in spyndex.indices.to_dict():\n        index = spyndex.indices[name]\n        if set(index.bands).issubset(bands_acronym_set):\n            spectral_indexes[name] = index\n\n    return spectral_indexes\n</code></pre>"},{"location":"api/features/spectral_indices/#siapy.features.spectral_indices.compute_spectral_indices","title":"compute_spectral_indices","text":"<pre><code>compute_spectral_indices(\n    data: DataFrame,\n    spectral_indices: str | Iterable[str],\n    bands_map: dict[str, str] | None = None,\n    remove_nan_and_constants: bool = True,\n) -&gt; DataFrame\n</code></pre> Source code in <code>siapy/features/spectral_indices.py</code> <pre><code>def compute_spectral_indices(\n    data: pd.DataFrame,\n    spectral_indices: str | Iterable[str],\n    bands_map: dict[str, str] | None = None,\n    remove_nan_and_constants: bool = True,\n) -&gt; pd.DataFrame:\n    spectral_indices = _convert_str_to_list(spectral_indices)\n\n    params = {}\n    for band in data.columns:\n        if bands_map is not None and band in bands_map.keys():\n            if bands_map[band] not in list(spyndex.bands):\n                raise InvalidInputError(\n                    {\n                        \"received_band_mapping\": bands_map[band],\n                        \"valid_bands_acronym\": list(spyndex.bands),\n                    },\n                    f\"Invalid band mapping is not a recognized band acronym. \\n\"\n                    f\"Received mapping: {band} -&gt; {bands_map[band]}. \\n\"\n                    \"Please ensure that all values in 'bands_map' are valid band acronyms.\",\n                )\n            params[bands_map[band]] = data[band]\n        else:\n            if band not in list(spyndex.bands):\n                raise InvalidInputError(\n                    {\n                        \"received_band\": band,\n                        \"valid_bands_acronym\": list(spyndex.bands),\n                    },\n                    f\"Invalid band: '{band}' is not a recognized band acronym. \\n\"\n                    \"Please ensure that all columns in 'data' are valid band acronyms.\",\n                )\n            params[band] = data[band]\n\n    df = spyndex.computeIndex(index=list(spectral_indices), params=params)\n    if remove_nan_and_constants:\n        # Drop columns with inf or NaN values\n        df = df.drop(df.columns[df.isin([np.inf, -np.inf, np.nan]).any()], axis=1)\n        # Drop columns with constant values\n        df = df.drop(df.columns[df.nunique() == 1], axis=1)\n    return df\n</code></pre>"},{"location":"api/optimizers/configs/","title":"Configs","text":""},{"location":"api/optimizers/configs/#siapy.optimizers.configs","title":"siapy.optimizers.configs","text":""},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig","title":"CreateStudyConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.storage","title":"storage  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>storage: str | BaseStorage | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.sampler","title":"sampler  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>sampler: BaseSampler | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.pruner","title":"pruner  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>pruner: BasePruner | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.study_name","title":"study_name  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>study_name: str | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.direction","title":"direction  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>direction: (\n    Literal[\"maximize\", \"minimize\"] | StudyDirection | None\n) = \"minimize\"\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.CreateStudyConfig.load_if_exists","title":"load_if_exists  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>load_if_exists: bool = False\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig","title":"OptimizeStudyConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.n_trials","title":"n_trials  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_trials: int | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.timeout","title":"timeout  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>timeout: float | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.n_jobs","title":"n_jobs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>n_jobs: int = -1\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.catch","title":"catch  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>catch: Iterable[type[Exception]] | type[Exception] = ()\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.callbacks","title":"callbacks  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>callbacks: (\n    list[Callable[[Study, FrozenTrial], None]] | None\n) = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.gc_after_trial","title":"gc_after_trial  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>gc_after_trial: bool = False\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.OptimizeStudyConfig.show_progress_bar","title":"show_progress_bar  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>show_progress_bar: bool = True\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.TabularOptimizerConfig","title":"TabularOptimizerConfig","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.TabularOptimizerConfig.model_config","title":"model_config  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>model_config = ConfigDict(arbitrary_types_allowed=True)\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.TabularOptimizerConfig.create_study","title":"create_study  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>create_study: CreateStudyConfig = CreateStudyConfig()\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.TabularOptimizerConfig.optimize_study","title":"optimize_study  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>optimize_study: OptimizeStudyConfig = OptimizeStudyConfig()\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.TabularOptimizerConfig.scorer","title":"scorer  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>scorer: Scorer | None = None\n</code></pre>"},{"location":"api/optimizers/configs/#siapy.optimizers.configs.TabularOptimizerConfig.trial_parameters","title":"trial_parameters  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>trial_parameters: TrialParameters | None = None\n</code></pre>"},{"location":"api/optimizers/evaluators/","title":"Evaluators","text":""},{"location":"api/optimizers/evaluators/#siapy.optimizers.evaluators","title":"siapy.optimizers.evaluators","text":""},{"location":"api/optimizers/evaluators/#siapy.optimizers.evaluators.ScorerFuncType","title":"ScorerFuncType  <code>module-attribute</code>","text":"<pre><code>ScorerFuncType = Callable[\n    [BaseEstimator, ArrayLike2dType, ArrayLike1dType], float\n]\n</code></pre>"},{"location":"api/optimizers/evaluators/#siapy.optimizers.evaluators.check_model_prediction_methods","title":"check_model_prediction_methods","text":"<pre><code>check_model_prediction_methods(\n    model: BaseEstimator,\n) -&gt; None\n</code></pre> Source code in <code>siapy/optimizers/evaluators.py</code> <pre><code>def check_model_prediction_methods(model: BaseEstimator) -&gt; None:\n    required_methods = [\"fit\", \"predict\", \"score\"]\n    for method in required_methods:\n        if not hasattr(model, method):\n            raise MethodNotImplementedError(model.__class__.__name__, method)\n</code></pre>"},{"location":"api/optimizers/evaluators/#siapy.optimizers.evaluators.cross_validation","title":"cross_validation","text":"<pre><code>cross_validation(\n    model: BaseEstimator,\n    X: ArrayLike2dType,\n    y: ArrayLike1dType,\n    X_val: ArrayLike2dType | None = None,\n    y_val: ArrayLike1dType | None = None,\n    *,\n    groups: ArrayLike1dType | None = None,\n    scoring: str | ScorerFuncType | None = None,\n    cv: int\n    | BaseCrossValidator\n    | Iterable[Any]\n    | None = None,\n    n_jobs: int | None = 1,\n    verbose: int = 0,\n    params: dict[str, Any] | None = None,\n    pre_dispatch: int | str = 1,\n    error_score: Literal[\"raise\"] | int = 0,\n) -&gt; float\n</code></pre> Source code in <code>siapy/optimizers/evaluators.py</code> <pre><code>def cross_validation(\n    model: BaseEstimator,\n    X: ArrayLike2dType,\n    y: ArrayLike1dType,\n    X_val: Annotated[ArrayLike2dType | None, \"Not used, only for compatibility\"] = None,\n    y_val: Annotated[ArrayLike1dType | None, \"Not used, only for compatibility\"] = None,\n    *,\n    groups: ArrayLike1dType | None = None,\n    scoring: str | ScorerFuncType | None = None,\n    cv: int | BaseCrossValidator | Iterable[Any] | None = None,\n    n_jobs: int | None = 1,\n    verbose: int = 0,\n    params: dict[str, Any] | None = None,\n    pre_dispatch: int | str = 1,\n    error_score: Literal[\"raise\"] | int = 0,\n) -&gt; float:\n    if X_val is not None or y_val is not None:\n        logger.info(\"Specification of X_val and y_val is redundant for cross_validation.These parameters are ignored.\")\n    check_model_prediction_methods(model)\n    score = cross_val_score(\n        estimator=model,\n        X=X,  # type: ignore\n        y=y,\n        groups=groups,\n        scoring=scoring,\n        cv=cv,\n        n_jobs=n_jobs,\n        verbose=verbose,\n        params=params,\n        pre_dispatch=pre_dispatch,\n        error_score=error_score,\n    )\n    return score.mean()\n</code></pre>"},{"location":"api/optimizers/evaluators/#siapy.optimizers.evaluators.hold_out_validation","title":"hold_out_validation","text":"<pre><code>hold_out_validation(\n    model: BaseEstimator,\n    X: ArrayLike2dType,\n    y: ArrayLike1dType,\n    X_val: ArrayLike2dType | None = None,\n    y_val: ArrayLike1dType | None = None,\n    *,\n    scoring: str | ScorerFuncType | None = None,\n    test_size: float | None = 0.2,\n    random_state: int | None = None,\n    shuffle: bool = True,\n    stratify: NDArray[floating[Any]] | None = None,\n) -&gt; float\n</code></pre> Source code in <code>siapy/optimizers/evaluators.py</code> <pre><code>def hold_out_validation(\n    model: BaseEstimator,\n    X: ArrayLike2dType,\n    y: ArrayLike1dType,\n    X_val: ArrayLike2dType | None = None,\n    y_val: ArrayLike1dType | None = None,\n    *,\n    scoring: str | ScorerFuncType | None = None,\n    test_size: float | None = 0.2,\n    random_state: int | None = None,\n    shuffle: bool = True,\n    stratify: NDArray[np.floating[Any]] | None = None,\n) -&gt; float:\n    if X_val is not None and y_val is not None:\n        x_train, x_test, y_train, y_test = X, X_val, y, y_val\n    elif X_val is not None or y_val is not None:\n        raise InvalidInputError(\n            input_value={\"X_val\": X_val, \"y_val\": y_val},\n            message=\"To manually define validation set, both X_val and y_val must be specified.\",\n        )\n    else:\n        x_train, x_test, y_train, y_test = train_test_split(\n            X,\n            y,\n            test_size=test_size,\n            random_state=random_state,\n            shuffle=shuffle,\n            stratify=stratify,\n        )\n    check_model_prediction_methods(model)\n    model.fit(x_train, y_train)  # type: ignore\n\n    if scoring:\n        if isinstance(scoring, str):\n            scoring_func = get_scorer(scoring)\n        else:\n            scoring_func = scoring\n        score = scoring_func(model, x_test, y_test)\n    else:\n        score = model.score(x_test, y_test)  # type: ignore\n    return score\n</code></pre>"},{"location":"api/optimizers/metrics/","title":"Metrics","text":""},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics","title":"siapy.optimizers.metrics","text":""},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.ClassificationMetrics","title":"ClassificationMetrics","text":"<p>               Bases: <code>NamedTuple</code></p>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.ClassificationMetrics.accuracy","title":"accuracy  <code>instance-attribute</code>","text":"<pre><code>accuracy: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.ClassificationMetrics.precision","title":"precision  <code>instance-attribute</code>","text":"<pre><code>precision: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.ClassificationMetrics.recall","title":"recall  <code>instance-attribute</code>","text":"<pre><code>recall: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.ClassificationMetrics.f1","title":"f1  <code>instance-attribute</code>","text":"<pre><code>f1: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.ClassificationMetrics.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, float]\n</code></pre> Source code in <code>siapy/optimizers/metrics.py</code> <pre><code>def to_dict(self) -&gt; dict[str, float]:\n    return self._asdict()\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics","title":"RegressionMetrics","text":"<p>               Bases: <code>NamedTuple</code></p>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.mae","title":"mae  <code>instance-attribute</code>","text":"<pre><code>mae: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.mse","title":"mse  <code>instance-attribute</code>","text":"<pre><code>mse: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.rmse","title":"rmse  <code>instance-attribute</code>","text":"<pre><code>rmse: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.r2","title":"r2  <code>instance-attribute</code>","text":"<pre><code>r2: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.pe","title":"pe  <code>instance-attribute</code>","text":"<pre><code>pe: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.maxe","title":"maxe  <code>instance-attribute</code>","text":"<pre><code>maxe: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.nrmse_mean","title":"nrmse_mean  <code>instance-attribute</code>","text":"<pre><code>nrmse_mean: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.nrmse_range","title":"nrmse_range  <code>instance-attribute</code>","text":"<pre><code>nrmse_range: float\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.RegressionMetrics.to_dict","title":"to_dict","text":"<pre><code>to_dict() -&gt; dict[str, float]\n</code></pre> Source code in <code>siapy/optimizers/metrics.py</code> <pre><code>def to_dict(self) -&gt; dict[str, float]:\n    return self._asdict()\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.normalized_rmse","title":"normalized_rmse","text":"<pre><code>normalized_rmse(\n    y_true: NDArray[floating[Any]],\n    y_pred: NDArray[floating[Any]],\n    normalize_by: Literal[\"range\", \"mean\"] = \"range\",\n) -&gt; float\n</code></pre> Source code in <code>siapy/optimizers/metrics.py</code> <pre><code>def normalized_rmse(\n    y_true: NDArray[np.floating[Any]],\n    y_pred: NDArray[np.floating[Any]],\n    normalize_by: Literal[\"range\", \"mean\"] = \"range\",\n) -&gt; float:\n    rmse = root_mean_squared_error(y_true, y_pred)\n    if normalize_by == \"range\":\n        normalizer = np.max(y_true) - np.min(y_true)\n    elif normalize_by == \"mean\":\n        normalizer = np.mean(y_true)\n    else:\n        raise InvalidInputError(\n            input_value=normalize_by,\n            message=\"Unknown normalizer. Possible values are: 'range' or 'mean'.\",\n        )\n    return float(rmse / normalizer)\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.calculate_classification_metrics","title":"calculate_classification_metrics","text":"<pre><code>calculate_classification_metrics(\n    y_true: NDArray[floating[Any]],\n    y_pred: NDArray[floating[Any]],\n    average: Literal[\n        \"micro\", \"macro\", \"samples\", \"weighted\", \"binary\"\n    ]\n    | None = \"weighted\",\n) -&gt; ClassificationMetrics\n</code></pre> Source code in <code>siapy/optimizers/metrics.py</code> <pre><code>def calculate_classification_metrics(\n    y_true: NDArray[np.floating[Any]],\n    y_pred: NDArray[np.floating[Any]],\n    average: Literal[\"micro\", \"macro\", \"samples\", \"weighted\", \"binary\"] | None = \"weighted\",\n) -&gt; ClassificationMetrics:\n    accuracy = float(accuracy_score(y_true, y_pred))\n    precision = float(precision_score(y_true, y_pred, average=average))\n    recall = float(recall_score(y_true, y_pred, average=average))\n    f1 = float(f1_score(y_true, y_pred, average=average))\n    return ClassificationMetrics(\n        accuracy=accuracy,\n        precision=precision,\n        recall=recall,\n        f1=f1,\n    )\n</code></pre>"},{"location":"api/optimizers/metrics/#siapy.optimizers.metrics.calculate_regression_metrics","title":"calculate_regression_metrics","text":"<pre><code>calculate_regression_metrics(\n    y_true: NDArray[floating[Any]],\n    y_pred: NDArray[floating[Any]],\n) -&gt; RegressionMetrics\n</code></pre> Source code in <code>siapy/optimizers/metrics.py</code> <pre><code>def calculate_regression_metrics(\n    y_true: NDArray[np.floating[Any]],\n    y_pred: NDArray[np.floating[Any]],\n) -&gt; RegressionMetrics:\n    mae = float(mean_absolute_error(y_true, y_pred))\n    mse = float(mean_squared_error(y_true, y_pred))\n    rmse = float(root_mean_squared_error(y_true, y_pred))\n    r2 = float(r2_score(y_true, y_pred))\n    pe = float(mean_absolute_percentage_error(y_true, y_pred))\n    maxe = float(max_error(y_true, y_pred))\n    nrmse_mean = float(normalized_rmse(y_true, y_pred, normalize_by=\"mean\"))\n    nrmse_range = float(normalized_rmse(y_true, y_pred, normalize_by=\"range\"))\n    return RegressionMetrics(\n        mae=mae,\n        mse=mse,\n        rmse=rmse,\n        r2=r2,\n        pe=pe,\n        maxe=maxe,\n        nrmse_mean=nrmse_mean,\n        nrmse_range=nrmse_range,\n    )\n</code></pre>"},{"location":"api/optimizers/optimizers/","title":"Optimizers","text":""},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers","title":"siapy.optimizers.optimizers","text":""},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer","title":"TabularOptimizer","text":"<pre><code>TabularOptimizer(\n    model: BaseEstimator,\n    configs: TabularOptimizerConfig,\n    X: ArrayLike2dType,\n    y: ArrayLike1dType,\n    X_val: ArrayLike2dType | None = None,\n    y_val: ArrayLike1dType | None = None,\n)\n</code></pre> Source code in <code>siapy/optimizers/optimizers.py</code> <pre><code>def __init__(\n    self,\n    model: BaseEstimator,\n    configs: TabularOptimizerConfig,\n    X: ArrayLike2dType,\n    y: ArrayLike1dType,\n    X_val: ArrayLike2dType | None = None,\n    y_val: ArrayLike1dType | None = None,\n):\n    self.model = model\n    self.configs = configs\n    self.X = X\n    self.y = y\n    self.X_val = X_val\n    self.y_val = y_val\n\n    self._study: optuna.study.Study | None = None\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.model","title":"model  <code>instance-attribute</code>","text":"<pre><code>model = model\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.configs","title":"configs  <code>instance-attribute</code>","text":"<pre><code>configs = configs\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.X","title":"X  <code>instance-attribute</code>","text":"<pre><code>X = X\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.y","title":"y  <code>instance-attribute</code>","text":"<pre><code>y = y\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.X_val","title":"X_val  <code>instance-attribute</code>","text":"<pre><code>X_val = X_val\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.y_val","title":"y_val  <code>instance-attribute</code>","text":"<pre><code>y_val = y_val\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.study","title":"study  <code>property</code>","text":"<pre><code>study: Study | None\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.best_trial","title":"best_trial  <code>property</code>","text":"<pre><code>best_trial: FrozenTrial | None\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.from_tabular_dataset_data","title":"from_tabular_dataset_data  <code>classmethod</code>","text":"<pre><code>from_tabular_dataset_data(\n    model: BaseEstimator,\n    configs: TabularOptimizerConfig,\n    data: TabularDatasetData,\n    data_val: TabularDatasetData | None = None,\n) -&gt; TabularOptimizer\n</code></pre> Source code in <code>siapy/optimizers/optimizers.py</code> <pre><code>@classmethod\ndef from_tabular_dataset_data(\n    cls,\n    model: BaseEstimator,\n    configs: TabularOptimizerConfig,\n    data: TabularDatasetData,\n    data_val: TabularDatasetData | None = None,\n) -&gt; \"TabularOptimizer\":\n    signals = data.signatures.signals.df\n    target = data.target\n    signals_val = data_val.signatures.signals.df if data_val else None\n    target_val = data_val.target if data_val else None\n\n    if target is None:\n        raise InvalidInputError(\n            input_value=target,\n            message=\"Target data is required for optimization.\",\n        )\n    if signals_val is not None and target_val is None:\n        raise InvalidInputError(\n            input_value={\n                \"signals_val\": signals_val,\n                \"target_val\": target_val,\n            },\n            message=(\n                \"If validation data (data_val) is provided, \"\n                \"validation targets (data_val.target) must also be provided.\"\n            ),\n        )\n    return cls(\n        model=model,\n        configs=configs,\n        X=signals,\n        y=target.value,\n        X_val=signals_val,\n        y_val=target_val.value if target_val else None,\n    )\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.run","title":"run","text":"<pre><code>run() -&gt; Study\n</code></pre> Source code in <code>siapy/optimizers/optimizers.py</code> <pre><code>def run(self) -&gt; optuna.study.Study:\n    study = optuna.create_study(**self.configs.create_study.model_dump())\n    study.optimize(\n        self.objective,\n        **self.configs.optimize_study.model_dump(),\n    )\n    if self.best_trial:\n        logger.info(\"Best scoring metric: %s\", self.best_trial.value)\n        logger.info(\"Best hyperparameters found were: %s\", self.best_trial.params)\n    self._study = study\n    return study\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.get_best_model","title":"get_best_model","text":"<pre><code>get_best_model() -&gt; BaseEstimator\n</code></pre> Source code in <code>siapy/optimizers/optimizers.py</code> <pre><code>def get_best_model(self) -&gt; BaseEstimator:\n    if self.best_trial is None:\n        raise InvalidInputError(\n            input_value=\"None\",\n            message=\"Study is not available for model refitting.\",\n        )\n\n    best_model = clone(self.model)\n    best_model.set_params(**self.best_trial.params)\n    best_model.fit(self.X, self.y)\n    return best_model\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.objective","title":"objective","text":"<pre><code>objective(trial: Trial) -&gt; float\n</code></pre> Source code in <code>siapy/optimizers/optimizers.py</code> <pre><code>def objective(self, trial: optuna.trial.Trial) -&gt; float:\n    params = self._trial_params(trial)\n    self.model = clone(self.model)\n    self.model.set_params(**params)\n    score = self.scorer()\n    return score\n</code></pre>"},{"location":"api/optimizers/optimizers/#siapy.optimizers.optimizers.TabularOptimizer.scorer","title":"scorer","text":"<pre><code>scorer() -&gt; float\n</code></pre> Source code in <code>siapy/optimizers/optimizers.py</code> <pre><code>def scorer(self) -&gt; float:\n    if self.configs.scorer is None:\n        raise InvalidInputError(\n            input_value=self.configs.scorer,\n            message=\"Scorer is not defined. Add scorer to configs or implement your custom scorer.\",\n        )\n    return self.configs.scorer(\n        model=self.model,\n        X=self.X,\n        y=self.y,\n        X_val=self.X_val,\n        y_val=self.y_val,\n    )\n</code></pre>"},{"location":"api/optimizers/parameters/","title":"Parameters","text":""},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters","title":"siapy.optimizers.parameters","text":""},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.ParametersDictType","title":"ParametersDictType  <code>module-attribute</code>","text":"<pre><code>ParametersDictType = dict[str, list[dict[str, Any]]]\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.FloatParameter","title":"FloatParameter","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.FloatParameter.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.FloatParameter.low","title":"low  <code>instance-attribute</code>","text":"<pre><code>low: float\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.FloatParameter.high","title":"high  <code>instance-attribute</code>","text":"<pre><code>high: float\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.FloatParameter.step","title":"step  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>step: float | None = None\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.FloatParameter.log","title":"log  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>log: bool = False\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.IntParameter","title":"IntParameter","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.IntParameter.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.IntParameter.low","title":"low  <code>instance-attribute</code>","text":"<pre><code>low: int\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.IntParameter.high","title":"high  <code>instance-attribute</code>","text":"<pre><code>high: int\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.IntParameter.step","title":"step  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>step: int = 1\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.IntParameter.log","title":"log  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>log: bool = False\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.CategoricalParameter","title":"CategoricalParameter","text":"<p>               Bases: <code>BaseModel</code></p>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.CategoricalParameter.name","title":"name  <code>instance-attribute</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.CategoricalParameter.choices","title":"choices  <code>instance-attribute</code>","text":"<pre><code>choices: Sequence[None | bool | int | float | str]\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.TrialParameters","title":"TrialParameters  <code>dataclass</code>","text":"<pre><code>TrialParameters(\n    float_parameters: list[FloatParameter] | None = None,\n    int_parameters: list[IntParameter] | None = None,\n    categorical_parameters: list[CategoricalParameter]\n    | None = None,\n)\n</code></pre> Source code in <code>siapy/optimizers/parameters.py</code> <pre><code>def __init__(\n    self,\n    float_parameters: list[FloatParameter] | None = None,\n    int_parameters: list[IntParameter] | None = None,\n    categorical_parameters: list[CategoricalParameter] | None = None,\n):\n    self._float_parameters = float_parameters or []\n    self._int_parameters = int_parameters or []\n    self._categorical_parameters = categorical_parameters or []\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.TrialParameters.float_parameters","title":"float_parameters  <code>property</code>","text":"<pre><code>float_parameters: list[FloatParameter]\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.TrialParameters.int_parameters","title":"int_parameters  <code>property</code>","text":"<pre><code>int_parameters: list[IntParameter]\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.TrialParameters.categorical_parameters","title":"categorical_parameters  <code>property</code>","text":"<pre><code>categorical_parameters: list[CategoricalParameter]\n</code></pre>"},{"location":"api/optimizers/parameters/#siapy.optimizers.parameters.TrialParameters.from_dict","title":"from_dict  <code>classmethod</code>","text":"<pre><code>from_dict(\n    parameters: ParametersDictType,\n) -&gt; TrialParameters\n</code></pre> Source code in <code>siapy/optimizers/parameters.py</code> <pre><code>@classmethod\ndef from_dict(cls, parameters: ParametersDictType) -&gt; \"TrialParameters\":\n    float_params = [FloatParameter(**fp) for fp in parameters.get(\"float_parameters\", [])]\n    int_params = [IntParameter(**ip) for ip in parameters.get(\"int_parameters\", [])]\n    cat_params = [CategoricalParameter(**cp) for cp in parameters.get(\"categorical_parameters\", [])]\n    return cls(\n        float_parameters=float_params,\n        int_parameters=int_params,\n        categorical_parameters=cat_params,\n    )\n</code></pre>"},{"location":"api/optimizers/scorers/","title":"Scorers","text":""},{"location":"api/optimizers/scorers/#siapy.optimizers.scorers","title":"siapy.optimizers.scorers","text":""},{"location":"api/optimizers/scorers/#siapy.optimizers.scorers.Scorer","title":"Scorer","text":"<pre><code>Scorer(scorer: Callable[..., float])\n</code></pre> Source code in <code>siapy/optimizers/scorers.py</code> <pre><code>def __init__(self, scorer: Callable[..., float]) -&gt; None:\n    self._scorer = scorer\n</code></pre>"},{"location":"api/optimizers/scorers/#siapy.optimizers.scorers.Scorer.init_cross_validator_scorer","title":"init_cross_validator_scorer  <code>classmethod</code>","text":"<pre><code>init_cross_validator_scorer(\n    scoring: str | ScorerFuncType | None = None,\n    cv: int\n    | BaseCrossValidator\n    | _RepeatedSplits\n    | Iterable[int]\n    | Literal[\"RepeatedKFold\", \"RepeatedStratifiedKFold\"]\n    | None = None,\n    n_jobs: int | None = None,\n) -&gt; Scorer\n</code></pre> Source code in <code>siapy/optimizers/scorers.py</code> <pre><code>@classmethod\ndef init_cross_validator_scorer(\n    cls,\n    scoring: str | ScorerFuncType | None = None,\n    cv: int\n    | model_selection.BaseCrossValidator\n    | model_selection._split._RepeatedSplits\n    | Iterable[int]\n    | Literal[\"RepeatedKFold\", \"RepeatedStratifiedKFold\"]\n    | None = None,\n    n_jobs: Annotated[\n        int | None,\n        \"Number of jobs to run in parallel. `-1` means using all processors.\",\n    ] = None,\n) -&gt; \"Scorer\":\n    if isinstance(cv, str) and cv in [\n        \"RepeatedKFold\",\n        \"RepeatedStratifiedKFold\",\n    ]:\n        cv = initialize_object(\n            module=model_selection,\n            module_name=cv,\n            n_splits=3,\n            n_repeats=5,\n            random_state=0,\n        )\n    scorer = partial(\n        cross_validation,\n        scoring=scoring,\n        cv=cv,  # type: ignore\n        groups=None,\n        n_jobs=n_jobs,\n        verbose=0,\n        params=None,\n        pre_dispatch=1,\n        error_score=0,\n    )\n    return cls(scorer)\n</code></pre>"},{"location":"api/optimizers/scorers/#siapy.optimizers.scorers.Scorer.init_hold_out_scorer","title":"init_hold_out_scorer  <code>classmethod</code>","text":"<pre><code>init_hold_out_scorer(\n    scoring: str | ScorerFuncType | None = None,\n    test_size: float | None = 0.2,\n    stratify: NDArray[floating[Any]] | None = None,\n) -&gt; Scorer\n</code></pre> Source code in <code>siapy/optimizers/scorers.py</code> <pre><code>@classmethod\ndef init_hold_out_scorer(\n    cls,\n    scoring: str | ScorerFuncType | None = None,\n    test_size: float | None = 0.2,\n    stratify: NDArray[np.floating[Any]] | None = None,\n) -&gt; \"Scorer\":\n    scorer = partial(\n        hold_out_validation,\n        scoring=scoring,\n        test_size=test_size,\n        random_state=0,\n        shuffle=True,\n        stratify=stratify,\n    )\n    return cls(scorer)\n</code></pre>"},{"location":"api/transformations/corregistrator/","title":"Corregistrator","text":""},{"location":"api/transformations/corregistrator/#siapy.transformations.corregistrator","title":"siapy.transformations.corregistrator","text":""},{"location":"api/transformations/corregistrator/#siapy.transformations.corregistrator.map_affine_approx_2d","title":"map_affine_approx_2d","text":"<pre><code>map_affine_approx_2d(\n    points_ref: NDArray[floating[Any]],\n    points_mov: NDArray[floating[Any]],\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Affine transformation</p> Source code in <code>siapy/transformations/corregistrator.py</code> <pre><code>def map_affine_approx_2d(\n    points_ref: NDArray[np.floating[Any]], points_mov: NDArray[np.floating[Any]]\n) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Affine transformation\"\"\"\n    # U = T*X -&gt; T = U*X'(X*X')^-1\n    matx_2d = points_ref.transpose() @ points_mov @ np.linalg.inv(points_mov.transpose() @ points_mov)\n    return matx_2d\n</code></pre>"},{"location":"api/transformations/corregistrator/#siapy.transformations.corregistrator.affine_matx_2d","title":"affine_matx_2d","text":"<pre><code>affine_matx_2d(\n    scale: tuple[float, float] | Sequence[float] = (1, 1),\n    trans: tuple[float, float] | Sequence[float] = (0, 0),\n    rot: float = 0,\n    shear: tuple[float, float] | Sequence[float] = (0, 0),\n) -&gt; NDArray[floating[Any]]\n</code></pre> <p>Create arbitrary affine transformation matrix</p> Source code in <code>siapy/transformations/corregistrator.py</code> <pre><code>def affine_matx_2d(\n    scale: tuple[float, float] | Sequence[float] = (1, 1),\n    trans: tuple[float, float] | Sequence[float] = (0, 0),\n    rot: float = 0,\n    shear: tuple[float, float] | Sequence[float] = (0, 0),\n) -&gt; NDArray[np.floating[Any]]:\n    \"\"\"Create arbitrary affine transformation matrix\"\"\"\n    rot = rot * np.pi / 180\n    matx_scale = np.array(((scale[0], 0, 0), (0, scale[1], 0), (0, 0, 1)))\n    matx_trans = np.array(((1, 0, trans[0]), (0, 1, trans[1]), (0, 0, 1)))\n    matx_rot = np.array(\n        (\n            (np.cos(rot), -np.sin(rot), 0),\n            (np.sin(rot), np.cos(rot), 0),\n            (0, 0, 1),\n        )\n    )\n    matx_shear = np.array(((1, shear[0], 0), (shear[1], 1, 0), (0, 0, 1)))\n    matx_2d = np.dot(matx_trans, np.dot(matx_shear, np.dot(matx_rot, matx_scale)))\n    return matx_2d\n</code></pre>"},{"location":"api/transformations/corregistrator/#siapy.transformations.corregistrator.align","title":"align","text":"<pre><code>align(\n    pixels_ref: Pixels\n    | DataFrame\n    | Iterable[CoordinateInput],\n    pixels_mov: Pixels\n    | DataFrame\n    | Iterable[CoordinateInput],\n    *,\n    eps: float = 1e-06,\n    max_iter: int = 50,\n    plot_progress: bool = False,\n) -&gt; tuple[NDArray[floating[Any]], NDArray[floating[Any]]]\n</code></pre> <p>Align interactive corresponding points</p> Source code in <code>siapy/transformations/corregistrator.py</code> <pre><code>def align(\n    pixels_ref: Pixels | pd.DataFrame | Iterable[CoordinateInput],\n    pixels_mov: Pixels | pd.DataFrame | Iterable[CoordinateInput],\n    *,\n    eps: float = 1e-6,\n    max_iter: int = 50,\n    plot_progress: bool = False,\n) -&gt; tuple[NDArray[np.floating[Any]], NDArray[np.floating[Any]]]:\n    \"\"\"Align interactive corresponding points\"\"\"\n    pixels_ref = validate_pixel_input(pixels_ref)\n    pixels_mov = validate_pixel_input(pixels_mov)\n\n    points_ref = pixels_ref.df_homogenious().to_numpy()\n    points_mov = pixels_mov.df_homogenious().to_numpy()\n\n    matrices = []\n    errors = []\n    idx = 0\n    if plot_progress:\n        points_mov_orig = points_mov\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n\n    while True:\n        points_ref_corr = np.array(points_ref)\n        points_mov_corr = np.array(points_mov)\n\n        matx_2d_combined = map_affine_approx_2d(points_ref_corr, points_mov_corr)\n        points_mov = np.dot(points_mov, matx_2d_combined.transpose())\n\n        matrices.append(matx_2d_combined)\n        errors.append(np.sqrt(np.sum((points_ref_corr[:, :2] - points_mov_corr[:, :2]) ** 2)))\n        idx = idx + 1\n\n        # check for convergence\n        matx_diff = np.abs(matx_2d_combined - affine_matx_2d())\n        if idx &gt; max_iter or np.all(matx_diff &lt; eps):\n            break\n\n    matx_2d_combined = affine_matx_2d()  # initialize with identity matrix\n    for matx_2d in matrices:\n        if plot_progress:\n            points_mov_corr = np.dot(points_mov_orig, matx_2d_combined.transpose())\n            ax.clear()\n            ax.plot(points_ref[:, 0], points_ref[:, 1], \"ob\")\n            ax.plot(points_mov_corr[:, 0], points_mov_corr[:, 1], \"om\")\n            fig.canvas.draw()\n            plt.pause(1)\n\n        # multiply all matrices to get the final transformation\n        matx_2d_combined = np.dot(matx_2d, matx_2d_combined)\n\n    errors_np = np.array(errors)\n\n    return matx_2d_combined, errors_np\n</code></pre>"},{"location":"api/transformations/corregistrator/#siapy.transformations.corregistrator.transform","title":"transform","text":"<pre><code>transform(\n    pixels: Pixels | DataFrame | Iterable[CoordinateInput],\n    transformation_matx: NDArray[floating[Any]],\n) -&gt; Pixels\n</code></pre> <p>Transform pixels</p> Source code in <code>siapy/transformations/corregistrator.py</code> <pre><code>def transform(\n    pixels: Pixels | pd.DataFrame | Iterable[CoordinateInput], transformation_matx: NDArray[np.floating[Any]]\n) -&gt; Pixels:\n    \"\"\"Transform pixels\"\"\"\n    pixels = validate_pixel_input(pixels)\n    points_transformed = np.dot(pixels.df_homogenious().to_numpy(), transformation_matx.transpose())\n    points_transformed = np.round(points_transformed[:, :2]).astype(\"int\")\n    return Pixels.from_iterable(points_transformed)\n</code></pre>"},{"location":"api/transformations/image/","title":"Image","text":""},{"location":"api/transformations/image/#siapy.transformations.image","title":"siapy.transformations.image","text":""},{"location":"api/transformations/image/#siapy.transformations.image.add_gaussian_noise","title":"add_gaussian_noise","text":"<pre><code>add_gaussian_noise(\n    image: ImageType,\n    mean: float = 0.0,\n    std: float = 1.0,\n    clip_to_max: bool = True,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/transformations/image.py</code> <pre><code>def add_gaussian_noise(\n    image: ImageType,\n    mean: float = 0.0,\n    std: float = 1.0,\n    clip_to_max: bool = True,\n) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n    rng = np.random.default_rng()\n    noise = rng.normal(loc=mean, scale=std, size=image_np.shape)\n    image_np = image_np + noise\n    if clip_to_max:\n        image_np = np.clip(image_np, 0, np.max(image_np))\n    return image_np\n</code></pre>"},{"location":"api/transformations/image/#siapy.transformations.image.random_crop","title":"random_crop","text":"<pre><code>random_crop(\n    image: ImageType, output_size: ImageSizeType\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/transformations/image.py</code> <pre><code>def random_crop(image: ImageType, output_size: ImageSizeType) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n    output_size = validate_image_size(output_size)\n    h, w = image_np.shape[:2]\n    new_h, new_w = output_size\n    top = np.random.randint(0, h - new_h)\n    left = np.random.randint(0, w - new_w)\n    return image_np[top : top + new_h, left : left + new_w]\n</code></pre>"},{"location":"api/transformations/image/#siapy.transformations.image.random_mirror","title":"random_mirror","text":"<pre><code>random_mirror(image: ImageType) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/transformations/image.py</code> <pre><code>def random_mirror(image: ImageType) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n    axis = random.choices([0, 1, (0, 1), None])[0]\n    if isinstance(axis, int) or isinstance(axis, tuple):\n        image_np = np.flip(image_np, axis=axis)\n    return image_np\n</code></pre>"},{"location":"api/transformations/image/#siapy.transformations.image.random_rotation","title":"random_rotation","text":"<pre><code>random_rotation(\n    image: ImageType, angle: float\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/transformations/image.py</code> <pre><code>def random_rotation(image: ImageType, angle: float) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n    rotated_image = transform.rotate(image_np, angle, preserve_range=True)\n    return rotated_image\n</code></pre>"},{"location":"api/transformations/image/#siapy.transformations.image.rescale","title":"rescale","text":"<pre><code>rescale(\n    image: ImageType, output_size: ImageSizeType\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/transformations/image.py</code> <pre><code>def rescale(image: ImageType, output_size: ImageSizeType) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n    output_size = validate_image_size(output_size)\n    rescaled_image = transform.resize(image_np, output_size, preserve_range=True)\n    return rescaled_image\n</code></pre>"},{"location":"api/transformations/image/#siapy.transformations.image.area_normalization","title":"area_normalization","text":"<pre><code>area_normalization(\n    image: ImageType,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/transformations/image.py</code> <pre><code>def area_normalization(image: ImageType) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n\n    def _signal_normalize(signal: NDArray[np.floating[Any]]) -&gt; NDArray[np.floating[Any]]:\n        area = np.trapz(signal)\n        if area == 0:\n            return signal\n        return signal / area\n\n    def _image_normalization(\n        image_np: NDArray[np.floating[Any]], func1d: Callable[[NDArray[np.floating[Any]]], NDArray[np.floating[Any]]]\n    ) -&gt; NDArray[np.floating[Any]]:\n        return np.apply_along_axis(func1d, axis=2, arr=image_np)\n\n    return _image_normalization(image_np, _signal_normalize)\n</code></pre>"},{"location":"api/utils/image_validators/","title":"Images Validators","text":""},{"location":"api/utils/image_validators/#siapy.utils.image_validators","title":"siapy.utils.image_validators","text":""},{"location":"api/utils/image_validators/#siapy.utils.image_validators.validate_image_to_numpy_3channels","title":"validate_image_to_numpy_3channels","text":"<pre><code>validate_image_to_numpy_3channels(\n    image: ImageType,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/utils/image_validators.py</code> <pre><code>def validate_image_to_numpy_3channels(image: ImageType) -&gt; NDArray[np.floating[Any]]:\n    if isinstance(image, SpectralImage):\n        image_display = np.array(image.to_display())\n    elif isinstance(image, Image):\n        image_display = np.array(image)\n    elif isinstance(image, np.ndarray) and len(image.shape) == 3 and image.shape[-1] == 3:\n        image_display = image.copy()\n    else:\n        raise InvalidInputError(\n            input_value=image,\n            message=\"Argument image must be convertible to numpy array with 3 channels.\",\n        )\n    return image_display\n</code></pre>"},{"location":"api/utils/image_validators/#siapy.utils.image_validators.validate_image_to_numpy","title":"validate_image_to_numpy","text":"<pre><code>validate_image_to_numpy(\n    image: ImageType,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/utils/image_validators.py</code> <pre><code>def validate_image_to_numpy(image: ImageType) -&gt; NDArray[np.floating[Any]]:\n    if isinstance(image, SpectralImage):\n        image_np = image.to_numpy()\n    elif isinstance(image, Image):\n        image_np = np.array(image)\n    elif isinstance(image, np.ndarray):\n        image_np = image.copy()\n    else:\n        raise InvalidInputError(\n            input_value=image,\n            message=\"Argument image must be convertible to a numpy array.\",\n        )\n    return image_np\n</code></pre>"},{"location":"api/utils/image_validators/#siapy.utils.image_validators.validate_image_size","title":"validate_image_size","text":"<pre><code>validate_image_size(\n    output_size: ImageSizeType,\n) -&gt; tuple[int, int]\n</code></pre> Source code in <code>siapy/utils/image_validators.py</code> <pre><code>def validate_image_size(output_size: ImageSizeType) -&gt; tuple[int, int]:\n    if not isinstance(output_size, (int, tuple)):\n        raise InvalidTypeError(\n            input_value=output_size,\n            allowed_types=ImageSizeType,\n            message=\"Argument output_size must be an int or a tuple.\",\n        )\n    if isinstance(output_size, int):\n        output_size = (output_size, output_size)\n    elif len(output_size) != 2 or not all([isinstance(el, int) for el in output_size]):\n        raise InvalidInputError(\n            input_value=output_size,\n            message=\"Argument output_size tuple must have 2 elements and contain only integers.\",\n        )\n    return output_size\n</code></pre>"},{"location":"api/utils/images/","title":"Images","text":""},{"location":"api/utils/images/#siapy.utils.images","title":"siapy.utils.images","text":""},{"location":"api/utils/images/#siapy.utils.images.spy_save_image","title":"spy_save_image","text":"<pre><code>spy_save_image(\n    image: ImageType,\n    save_path: str | Path,\n    *,\n    metadata: dict[str, Any] | None = None,\n    overwrite: bool = True,\n    dtype: type[ImageDataType] = float32,\n) -&gt; None\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def spy_save_image(\n    image: Annotated[ImageType, \"The image to save.\"],\n    save_path: Annotated[str | Path, \"Header file (with '.hdr' extension) name with path.\"],\n    *,\n    metadata: Annotated[\n        dict[str, Any] | None,\n        \"A dict containing ENVI header parameters (e.g., parameters extracted from a source image).\",\n    ] = None,\n    overwrite: Annotated[\n        bool,\n        \"If the associated image file or header already exist and set to True, the files will be overwritten; otherwise, if either of the files exist, an exception will be raised.\",\n    ] = True,\n    dtype: Annotated[\n        type[ImageDataType],\n        \"The numpy data type with which to store the image.\",\n    ] = np.float32,\n) -&gt; None:\n    image_np = validate_image_to_numpy(image)\n    if isinstance(save_path, str):\n        save_path = Path(save_path)\n    if metadata is None:\n        metadata = {}\n\n    os.makedirs(save_path.parent, exist_ok=True)\n    sp.envi.save_image(\n        hdr_file=save_path,\n        image=image_np,\n        dtype=dtype,\n        force=overwrite,\n        metadata=metadata,\n    )\n    logger.info(f\"Image saved as:  {save_path}\")\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.spy_create_image","title":"spy_create_image","text":"<pre><code>spy_create_image(\n    image: ImageType,\n    save_path: str | Path,\n    *,\n    metadata: dict[str, Any] | None = None,\n    overwrite: bool = True,\n    dtype: type[ImageDataType] = float32,\n) -&gt; SpectralImage[Any]\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def spy_create_image(\n    image: Annotated[ImageType, \"The image to save.\"],\n    save_path: Annotated[str | Path, \"Header file (with '.hdr' extension) name with path.\"],\n    *,\n    metadata: Annotated[\n        dict[str, Any] | None,\n        \"A dict containing ENVI header parameters (e.g., parameters extracted from a source image).\",\n    ] = None,\n    overwrite: Annotated[\n        bool,\n        \"If the associated image file or header already exist and set to True, the files will be overwritten; otherwise, if either of the files exist, an exception will be raised.\",\n    ] = True,\n    dtype: Annotated[\n        type[ImageDataType],\n        \"The numpy data type with which to store the image.\",\n    ] = np.float32,\n) -&gt; SpectralImage[Any]:\n    image_np = validate_image_to_numpy(image)\n    if isinstance(save_path, str):\n        save_path = Path(save_path)\n    if metadata is None:\n        metadata = {\n            \"lines\": image_np.shape[0],\n            \"samples\": image_np.shape[1],\n            \"bands\": image_np.shape[2],\n        }\n\n    os.makedirs(save_path.parent, exist_ok=True)\n    spectral_image = sp.envi.create_image(\n        hdr_file=save_path,\n        metadata=metadata,\n        dtype=dtype,\n        force=overwrite,\n    )\n    mmap = spectral_image.open_memmap(writable=True)\n    mmap[:, :, :] = image_np\n    logger.info(f\"Image created as:  {save_path}\")\n    return SpectralImage(SpectralLibImage(spectral_image))\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.spy_merge_images_by_specter","title":"spy_merge_images_by_specter","text":"<pre><code>spy_merge_images_by_specter(\n    *,\n    image_original: ImageType,\n    image_to_merge: ImageType,\n    save_path: str | Path,\n    overwrite: bool = True,\n    dtype: type[ImageDataType] = float32,\n    auto_metadata_extraction: bool = True,\n) -&gt; SpectralImage[Any]\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def spy_merge_images_by_specter(\n    *,\n    image_original: Annotated[ImageType, \"Original image.\"],\n    image_to_merge: Annotated[ImageType, \"Image which will be merged onto original image.\"],\n    save_path: Annotated[str | Path, \"Header file (with '.hdr' extension) name with path.\"],\n    overwrite: Annotated[\n        bool,\n        \"If the associated image file or header already exist and set to True, the files will be overwritten; otherwise, if either of the files exist, an exception will be raised.\",\n    ] = True,\n    dtype: Annotated[\n        type[ImageDataType],\n        \"The numpy data type with which to store the image.\",\n    ] = np.float32,\n    auto_metadata_extraction: Annotated[\n        bool,\n        \"Whether to automatically extract metadata images.\",\n    ] = True,\n) -&gt; SpectralImage[Any]:\n    image_original_np = validate_image_to_numpy(image_original)\n    image_to_merge_np = validate_image_to_numpy(image_to_merge)\n\n    metadata = {\n        \"lines\": image_original_np.shape[0],\n        \"samples\": image_original_np.shape[1],\n        \"bands\": image_original_np.shape[2] + image_to_merge_np.shape[2],\n    }\n    if (\n        auto_metadata_extraction\n        and isinstance(image_original, SpectralImage)\n        and isinstance(image_to_merge, SpectralImage)\n    ):\n        original_meta = image_original.metadata\n        merged_meta = image_to_merge.metadata\n        metadata_ext = {}\n\n        metadata_ext[\"wavelength\"] = original_meta.get(\"wavelength\", []) + merged_meta.get(\"wavelength\", [])\n        metadata_ext[\"data type\"] = original_meta.get(\"data type\", \"\")\n        metadata_ext[\"byte order\"] = original_meta.get(\"byte order\", \"\")\n        metadata_ext[\"data ignore value\"] = original_meta.get(\"data ignore value\", \"\")\n        metadata_ext[\"header offset\"] = original_meta.get(\"header offset\", 0)\n        metadata_ext[\"interleave\"] = original_meta.get(\"interleave\", \"\")\n        metadata_ext[\"wavelength units\"] = original_meta.get(\"wavelength units\", \"\")\n        metadata_ext[\"acquisition date\"] = original_meta.get(\"acquisition date\", \"\")\n\n        metadata_ext[\"default bands\"] = original_meta.get(\"default bands\", [])\n        metadata_ext[\"default bands additional\"] = merged_meta.get(\"default bands\", [])\n        metadata_ext[\"description\"] = original_meta.get(\"description\", \"\")\n        # metadata_ext[\"description additional\"] = merged_meta.get(\"description\", \"\")\n\n        metadata.update(metadata_ext)\n\n    image_to_merge_np = rescale(\n        image_to_merge_np,\n        (image_original_np.shape[0], image_original_np.shape[1]),\n    )\n    image_to_merge_np = image_to_merge_np.astype(image_original_np.dtype)\n    image_merged = np.concatenate((image_original_np, image_to_merge_np), axis=2)\n\n    return spy_create_image(\n        image=image_merged,\n        save_path=save_path,\n        metadata=metadata,\n        overwrite=overwrite,\n        dtype=dtype,\n    )\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.rasterio_save_image","title":"rasterio_save_image","text":"<pre><code>rasterio_save_image(\n    image: ImageType,\n    save_path: str | Path,\n    *,\n    metadata: dict[str, Any] | None = None,\n    overwrite: bool = True,\n    dtype: type[ImageDataType] = float32,\n    **kwargs: dict[str, Any],\n) -&gt; None\n</code></pre> <p>Save an image using rioxarray.</p> Source code in <code>siapy/utils/images.py</code> <pre><code>def rasterio_save_image(\n    image: ImageType,\n    save_path: str | Path,\n    *,\n    metadata: Annotated[dict[str, Any] | None, \"A dict containing additional metadata.\"] = None,\n    overwrite: Annotated[\n        bool, \"If the file exists and set to True, it will be overwritten; otherwise an exception will be raised.\"\n    ] = True,\n    dtype: Annotated[type[ImageDataType], \"The numpy data type with which to store the image.\"] = np.float32,\n    **kwargs: Annotated[dict[str, Any], \"Additional keyword arguments for rioxarray.\"],\n) -&gt; None:\n    \"\"\"Save an image using rioxarray.\"\"\"\n    image_np = validate_image_to_numpy(image)\n    if isinstance(save_path, str):\n        save_path = Path(save_path)\n    if metadata is None:\n        metadata = {}\n\n    os.makedirs(save_path.parent, exist_ok=True)\n\n    if save_path.exists() and not overwrite:\n        raise InvalidInputError(\n            input_value={\"save_path\": save_path},\n            message=f\"File {save_path} already exists and overwrite=False.\",\n        )\n\n    wavelengths = metadata.get(\"wavelength\", [])\n    if not wavelengths:\n        wavelengths = np.arange(image_np.shape[2])\n\n    xarray = xr.DataArray(\n        data=image_np.transpose(2, 0, 1).astype(dtype),\n        dims=[\"band\", \"y\", \"x\"],\n        coords={\n            \"y\": np.arange(image_np.shape[0]),\n            \"x\": np.arange(image_np.shape[1]),\n            \"band\": wavelengths,\n        },\n        attrs=metadata,\n    )\n\n    xarray.rio.to_raster(save_path, **kwargs)\n    logger.info(f\"Image saved with rasterio as: {save_path}\")\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.rasterio_create_image","title":"rasterio_create_image","text":"<pre><code>rasterio_create_image(\n    image: ImageType,\n    save_path: str | Path,\n    *,\n    metadata: dict[str, Any] | None = None,\n    overwrite: bool = True,\n    dtype: type[ImageDataType] = float32,\n    **kwargs: dict[str, Any],\n) -&gt; SpectralImage[Any]\n</code></pre> <p>Create and save an image using rioxarray, then return a SpectralImage object.</p> Source code in <code>siapy/utils/images.py</code> <pre><code>def rasterio_create_image(\n    image: Annotated[ImageType, \"The image to use.\"],\n    save_path: Annotated[str | Path, \"File name with path.\"],\n    *,\n    metadata: Annotated[dict[str, Any] | None, \"A dict containing additional metadata.\"] = None,\n    overwrite: Annotated[\n        bool, \"If the file exists and set to True, it will be overwritten; otherwise an exception will be raised.\"\n    ] = True,\n    dtype: Annotated[type[ImageDataType], \"The numpy data type with which to store the image.\"] = np.float32,\n    **kwargs: Annotated[dict[str, Any], \"Additional keyword arguments for rioxarray.\"],\n) -&gt; SpectralImage[Any]:\n    \"\"\"Create and save an image using rioxarray, then return a SpectralImage object.\"\"\"\n    image_np = validate_image_to_numpy(image)\n    if isinstance(save_path, str):\n        save_path = Path(save_path)\n\n    if metadata is None:\n        metadata = {}\n\n    # Save the image first\n    rasterio_save_image(\n        image=image_np,\n        save_path=save_path,\n        metadata=metadata,\n        overwrite=overwrite,\n        dtype=dtype,\n        **kwargs,\n    )\n    logger.info(f\"Image created as: {save_path}\")\n    return SpectralImage(RasterioLibImage.open(save_path))\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.convert_radiance_image_to_reflectance","title":"convert_radiance_image_to_reflectance","text":"<pre><code>convert_radiance_image_to_reflectance(\n    image: ImageType,\n    panel_correction: NDArray[floating[Any]],\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def convert_radiance_image_to_reflectance(\n    image: ImageType,\n    panel_correction: NDArray[np.floating[Any]],\n) -&gt; NDArray[np.floating[Any]]:\n    image_np = validate_image_to_numpy(image)\n    return image_np * panel_correction\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.calculate_correction_factor","title":"calculate_correction_factor","text":"<pre><code>calculate_correction_factor(\n    panel_radiance_mean: NDArray[floating[Any]],\n    panel_reference_reflectance: float,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def calculate_correction_factor(\n    panel_radiance_mean: NDArray[np.floating[Any]],\n    panel_reference_reflectance: float,\n) -&gt; NDArray[np.floating[Any]]:\n    if not (0 &lt;= panel_reference_reflectance &lt;= 1):\n        raise InvalidInputError(\n            input_value={\"panel_reference_reflectance\": panel_reference_reflectance},\n            message=\"Panel reference reflectance must be between 0 and 1.\",\n        )\n\n    panel_reflectance_mean = np.full(panel_radiance_mean.shape, panel_reference_reflectance)\n    panel_correction = panel_reflectance_mean / panel_radiance_mean\n    return panel_correction\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.calculate_correction_factor_from_panel","title":"calculate_correction_factor_from_panel","text":"<pre><code>calculate_correction_factor_from_panel(\n    image: ImageType,\n    panel_reference_reflectance: float,\n    panel_shape_label: str | None = None,\n) -&gt; NDArray[floating[Any]]\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def calculate_correction_factor_from_panel(\n    image: ImageType,\n    panel_reference_reflectance: float,\n    panel_shape_label: str | None = None,\n) -&gt; NDArray[np.floating[Any]]:\n    if panel_shape_label and isinstance(image, SpectralImage):\n        panel_shape = image.geometric_shapes.get_by_name(panel_shape_label)\n        if not panel_shape:\n            raise InvalidInputError(\n                input_value={\"panel_shape_label\": panel_shape_label},\n                message=\"Panel shape label not found.\",\n            )\n        if len(panel_shape) != 1:\n            raise InvalidInputError(\n                input_value={\"panel_shape\": panel_shape},\n                message=\"Panel shape label must refer to a single shape.\",\n            )\n        panel_signatures = get_signatures_within_convex_hull(image, panel_shape)[0]\n        panel_radiance_mean = panel_signatures.signals.average_signal()\n\n    else:\n        image_np = validate_image_to_numpy(image)\n        temp_mean = image_np.mean(axis=(0, 1))\n        if not isinstance(temp_mean, np.ndarray):\n            raise InvalidInputError(\n                input_value={\"image\": image_np},\n                message=f\"Expected image.mean(axis=(0, 1)) to return np.ndarray, but got {type(temp_mean).__name__}.\",\n            )\n        panel_radiance_mean = temp_mean\n\n    return calculate_correction_factor(\n        panel_radiance_mean=panel_radiance_mean,\n        panel_reference_reflectance=panel_reference_reflectance,\n    )\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.blockfy_image","title":"blockfy_image","text":"<pre><code>blockfy_image(\n    image: ImageType, p: int, q: int\n) -&gt; list[NDArray[floating[Any]]]\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def blockfy_image(\n    image: ImageType,\n    p: Annotated[int, \"block row size\"],\n    q: Annotated[int, \"block column size\"],\n) -&gt; list[NDArray[np.floating[Any]]]:\n    image_np = validate_image_to_numpy(image)\n    # Calculate how many blocks can cover the entire image\n    bpr = (image_np.shape[0] - 1) // p + 1  # blocks per row\n    bpc = (image_np.shape[1] - 1) // q + 1  # blocks per column\n\n    # Pad array with NaNs so it can be divided by p row-wise and by q column-wise\n    image_pad = np.nan * np.ones([p * bpr, q * bpc, image_np.shape[2]])\n    image_pad[: image_np.shape[0], : image_np.shape[1], : image_np.shape[2]] = image_np\n\n    image_slices = []\n    row_prev = 0\n\n    for row_block in range(bpc):\n        row_prev = row_block * p\n        column_prev = 0\n\n        for column_block in range(bpr):\n            column_prev = column_block * q\n            block = image_pad[\n                row_prev : row_prev + p,\n                column_prev : column_prev + q,\n            ]\n\n            if block.shape == (p, q, image_np.shape[2]):\n                image_slices.append(block)\n\n    return image_slices\n</code></pre>"},{"location":"api/utils/images/#siapy.utils.images.calculate_image_background_percentage","title":"calculate_image_background_percentage","text":"<pre><code>calculate_image_background_percentage(\n    image: ImageType,\n) -&gt; float\n</code></pre> Source code in <code>siapy/utils/images.py</code> <pre><code>def calculate_image_background_percentage(image: ImageType) -&gt; float:\n    image_np = validate_image_to_numpy(image)\n    # Check where any of bands include nan values (axis=2) to get positions of background\n    mask_nan = np.any(np.isnan(image_np), axis=2)\n    # Calculate percentage of background\n    percentage = np.sum(mask_nan) / mask_nan.size * 100\n    return percentage\n</code></pre>"},{"location":"api/utils/plots/","title":"Plots","text":""},{"location":"api/utils/plots/#siapy.utils.plots","title":"siapy.utils.plots","text":""},{"location":"api/utils/plots/#siapy.utils.plots.InteractiveButtonsEnum","title":"InteractiveButtonsEnum","text":"<p>               Bases: <code>Enum</code></p>"},{"location":"api/utils/plots/#siapy.utils.plots.InteractiveButtonsEnum.SAVE","title":"SAVE  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SAVE = auto()\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.InteractiveButtonsEnum.REPEAT","title":"REPEAT  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>REPEAT = auto()\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.InteractiveButtonsEnum.SKIP","title":"SKIP  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>SKIP = auto()\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.pixels_select_click","title":"pixels_select_click","text":"<pre><code>pixels_select_click(image: ImageType) -&gt; Pixels\n</code></pre> Source code in <code>siapy/utils/plots.py</code> <pre><code>def pixels_select_click(image: ImageType) -&gt; Pixels:\n    image_display = validate_image_to_numpy_3channels(image)\n\n    coordinates = []\n    fig, ax = plt.subplots(1, 1)\n    ax.imshow(image_display)\n    fig.tight_layout()\n    enter_clicked = 0\n\n    def onclick(event: Any) -&gt; None:\n        nonlocal coordinates, fig\n        logger.info(f\"Pressed coordinate: X = {event.xdata}, Y = {event.ydata}\")\n        x_coor = round(event.xdata)\n        y_coor = round(event.ydata)\n        coordinates.append([x_coor, y_coor])\n\n        ax.scatter(\n            int(x_coor),\n            int(y_coor),\n            marker=\"x\",\n            c=\"red\",\n        )\n        fig.canvas.draw()\n\n    def accept(event: Any) -&gt; None:\n        nonlocal enter_clicked\n        if event.key == \"enter\":\n            logger.info(\"Enter clicked.\")\n            enter_clicked = 1\n            plt.close()\n\n    def onexit(event: Any) -&gt; None:\n        nonlocal enter_clicked\n        if not enter_clicked:\n            logger.info(\"Exiting application.\")\n            plt.close()\n            sys.exit(0)\n\n    fig.canvas.mpl_connect(\"button_press_event\", onclick)\n    fig.canvas.mpl_connect(\"key_press_event\", accept)\n    fig.canvas.mpl_connect(\"close_event\", onexit)\n    plt.show()\n    return Pixels.from_iterable(coordinates)\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.pixels_select_lasso","title":"pixels_select_lasso","text":"<pre><code>pixels_select_lasso(\n    image: ImageType,\n    selector_props: dict[str, Any] | None = None,\n) -&gt; list[Pixels]\n</code></pre> Source code in <code>siapy/utils/plots.py</code> <pre><code>def pixels_select_lasso(image: ImageType, selector_props: dict[str, Any] | None = None) -&gt; list[Pixels]:\n    image_display = validate_image_to_numpy_3channels(image)\n\n    x, y = np.meshgrid(np.arange(image_display.shape[1]), np.arange(image_display.shape[0]))\n    pixes_all_stack = np.vstack((x.flatten(), y.flatten())).T\n\n    fig, ax = plt.subplots(1, 1)\n    ax.imshow(image_display)\n    fig.tight_layout()\n\n    indices: NDArray[np.bool_] = np.array([], dtype=bool)\n    indices_list: list[NDArray[np.bool_]] = []\n    enter_clicked = 0\n\n    def onselect(vertices_selected: list[tuple[float, float]]) -&gt; None:\n        logger.info(\"Selected.\")\n        nonlocal indices\n        path = Path(vertices_selected)\n        indices = path.contains_points(pixes_all_stack)\n\n    def onrelease(event: Any) -&gt; None:\n        nonlocal indices, indices_list\n        indices_list.append(indices)\n\n    def onexit(event: Any) -&gt; None:\n        nonlocal enter_clicked\n        if not enter_clicked:\n            logger.info(\"Exiting application.\")\n            plt.close()\n            sys.exit(0)\n\n    def accept(event: Any) -&gt; None:\n        nonlocal enter_clicked\n        if event.key == \"enter\":\n            logger.info(\"Enter clicked.\")\n            enter_clicked = 1\n            plt.close()\n\n    props = selector_props if selector_props is not None else {\"color\": \"red\", \"linewidth\": 2, \"linestyle\": \"-\"}\n    lasso = LassoSelector(ax, onselect, props=props)  # noqa: F841 type: ignore[reportUnusedVariable]\n    fig.canvas.mpl_connect(\"button_release_event\", onrelease)\n    fig.canvas.mpl_connect(\"close_event\", onexit)\n    fig.canvas.mpl_connect(\"key_press_event\", accept)\n\n    plt.show()\n\n    selected_areas = []\n    for indices in indices_list:\n        coordinates = pixes_all_stack[indices]\n        selected_areas.append(Pixels.from_iterable(coordinates))\n\n    logger.info(f\"Number of selected areas: {len(selected_areas)}\")\n    return selected_areas\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.display_image_with_areas","title":"display_image_with_areas","text":"<pre><code>display_image_with_areas(\n    image: ImageType,\n    areas: Pixels | list[Pixels],\n    *,\n    color: str = \"red\",\n) -&gt; None\n</code></pre> Source code in <code>siapy/utils/plots.py</code> <pre><code>def display_image_with_areas(\n    image: ImageType,\n    areas: Pixels | list[Pixels],\n    *,\n    color: str = \"red\",\n) -&gt; None:\n    if not isinstance(areas, list):\n        areas = [areas]\n\n    image_display = validate_image_to_numpy_3channels(image)\n    fig, ax = plt.subplots()\n    ax.imshow(image_display)\n\n    for pixels in areas:\n        ax.scatter(\n            pixels.x(),\n            pixels.y(),\n            lw=0,\n            marker=\"o\",\n            c=color,\n            s=(72.0 / fig.dpi) ** 2,\n        )\n\n    plt.show()\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.display_multiple_images_with_areas","title":"display_multiple_images_with_areas","text":"<pre><code>display_multiple_images_with_areas(\n    images_with_areas: list[\n        tuple[ImageType, Pixels | list[Pixels]]\n    ],\n    *,\n    color: str = \"red\",\n    plot_interactive_buttons: bool = True,\n) -&gt; InteractiveButtonsEnum | None\n</code></pre> Source code in <code>siapy/utils/plots.py</code> <pre><code>def display_multiple_images_with_areas(\n    images_with_areas: list[tuple[ImageType, Pixels | list[Pixels]]],\n    *,\n    color: str = \"red\",\n    plot_interactive_buttons: bool = True,\n) -&gt; InteractiveButtonsEnum | None:\n    num_images = len(images_with_areas)\n    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 5, 5))\n\n    if isinstance(axes, Axes):\n        axes = np.array([axes])\n\n    for ax, (image, selected_areas) in zip(axes, images_with_areas):\n        if not isinstance(selected_areas, list):\n            selected_areas = [selected_areas]\n\n        image_display = validate_image_to_numpy_3channels(image)\n        ax.imshow(image_display)\n\n        for pixels in selected_areas:\n            ax.scatter(\n                pixels.x(),\n                pixels.y(),\n                lw=0,\n                marker=\"o\",\n                c=color,\n                s=(72.0 / fig.dpi) ** 2,\n            )\n    if plot_interactive_buttons:\n        return interactive_buttons()\n\n    plt.show()\n    return None\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.interactive_buttons","title":"interactive_buttons","text":"<pre><code>interactive_buttons() -&gt; InteractiveButtonsEnum\n</code></pre> Source code in <code>siapy/utils/plots.py</code> <pre><code>def interactive_buttons() -&gt; InteractiveButtonsEnum:\n    flag = InteractiveButtonsEnum.REPEAT\n\n    def repeat(event: Any) -&gt; None:\n        nonlocal flag\n        logger.info(\"Pressed repeat button.\")\n        plt.close()\n        flag = InteractiveButtonsEnum.REPEAT\n\n    def save(event: Any) -&gt; None:\n        nonlocal flag\n        logger.info(\"Pressed save button.\")\n        plt.close()\n        flag = InteractiveButtonsEnum.SAVE\n\n    def skip(event: Any) -&gt; None:\n        nonlocal flag\n        logger.info(\"Pressed skip button.\")\n        plt.close()\n        flag = InteractiveButtonsEnum.SKIP\n\n    axcolor = \"lightgoldenrodyellow\"\n    position = plt.axes((0.9, 0.1, 0.1, 0.04))\n    button_save = Button(position, \"Save\", color=axcolor, hovercolor=\"0.975\")\n    button_save.on_clicked(save)\n    position = plt.axes((0.9, 0.15, 0.1, 0.04))\n    button_repeat = Button(position, \"Repeat\", color=axcolor, hovercolor=\"0.975\")\n    button_repeat.on_clicked(repeat)\n    position = plt.axes((0.9, 0.2, 0.1, 0.04))\n    button_skip = Button(position, \"Skip\", color=axcolor, hovercolor=\"0.975\")\n    button_skip.on_clicked(skip)\n    plt.show()\n    return flag\n</code></pre>"},{"location":"api/utils/plots/#siapy.utils.plots.display_signals","title":"display_signals","text":"<pre><code>display_signals(\n    data: TabularDatasetData,\n    *,\n    figsize: tuple[int, int] = (6, 4),\n    dpi: int = 150,\n    colormap: str = \"viridis\",\n    x_label: str = \"Spectral bands\",\n    y_label: str = \"\",\n    label_fontsize: int = 14,\n    tick_params_label_size: int = 12,\n    legend_fontsize: int = 10,\n    legend_frameon: bool = True,\n) -&gt; None\n</code></pre> Source code in <code>siapy/utils/plots.py</code> <pre><code>def display_signals(\n    data: TabularDatasetData,\n    *,\n    figsize: tuple[int, int] = (6, 4),\n    dpi: int = 150,\n    colormap: str = \"viridis\",\n    x_label: str = \"Spectral bands\",\n    y_label: str = \"\",\n    label_fontsize: int = 14,\n    tick_params_label_size: int = 12,\n    legend_fontsize: int = 10,\n    legend_frameon: bool = True,\n) -&gt; None:\n    if not isinstance(data.target, ClassificationTarget):\n        raise InvalidInputError(\n            input_value=data.target,\n            message=\"The target must be an instance of ClassificationTarget.\",\n        )\n\n    signals = data.signatures.signals.df.copy()\n    target = data.target.model_copy()\n    y_data_encoded = target.value\n    classes = list(target.encoding.to_dict().values())\n\n    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)\n    cmap = plt.get_cmap(colormap)\n    unique_labels = np.unique(y_data_encoded)\n    no_colors = len(unique_labels)\n\n    if no_colors &gt; 2:\n        colors = list(cmap(np.linspace(0, 1, no_colors)))\n    else:\n        colors = [\"darkgoldenrod\", \"forestgreen\"]\n\n    x_values = list(range(len(signals.columns)))\n\n    grouped_data = signals.groupby(y_data_encoded.to_numpy())\n    mean_values = grouped_data.mean()\n    std_values = grouped_data.std()\n\n    for idx in unique_labels:\n        mean = mean_values.loc[idx].tolist()\n        std = std_values.loc[idx].tolist()\n        ax.plot(x_values, mean, color=colors[idx], label=classes[idx], alpha=0.6)\n        ax.fill_between(\n            x_values,\n            [m - s for m, s in zip(mean, std)],\n            [m + s for m, s in zip(mean, std)],\n            color=colors[idx],\n            alpha=0.2,\n        )\n\n    custom_lines = []\n    for idx in unique_labels:\n        custom_lines.append(Line2D([0], [0], color=colors[idx], lw=2))\n\n    ax.set_ylabel(y_label, fontsize=label_fontsize)\n    ax.set_xlabel(x_label, fontsize=label_fontsize)\n    ax.tick_params(axis=\"both\", which=\"major\", labelsize=tick_params_label_size)\n    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=tick_params_label_size)\n    # ax.set_ylim([0, 1])\n    # ax.spines[\"bottom\"].set_linewidth(2)\n    # ax.spines[\"left\"].set_linewidth(2)\n    ax.spines[\"right\"].set_linewidth(0)\n    ax.spines[\"top\"].set_linewidth(0)\n    ax.set_xticks(x_values)\n    ax.set_xticklabels(signals.columns, rotation=0)\n    ax.legend(\n        loc=\"upper left\",\n        fontsize=legend_fontsize,\n        framealpha=1,\n        frameon=legend_frameon,\n    )\n    plt.show()\n</code></pre>"},{"location":"api/utils/signatures/","title":"Signatures","text":""},{"location":"api/utils/signatures/#siapy.utils.signatures","title":"siapy.utils.signatures","text":""},{"location":"api/utils/signatures/#siapy.utils.signatures.get_signatures_within_convex_hull","title":"get_signatures_within_convex_hull","text":"<pre><code>get_signatures_within_convex_hull(\n    image: SpectralImage, shape: Shape\n) -&gt; list[Signatures]\n</code></pre> Source code in <code>siapy/utils/signatures.py</code> <pre><code>def get_signatures_within_convex_hull(image: SpectralImage, shape: Shape) -&gt; list[Signatures]:\n    image_xarr = image.to_xarray()\n    signatures = []\n\n    if shape.is_point:\n        for g in shape.geometry:\n            if isinstance(g, MultiPoint):\n                points = list(g.geoms)\n            elif isinstance(g, Point):\n                points = [g]\n            else:\n                raise InvalidTypeError(\n                    input_value=g,\n                    allowed_types=(Point, MultiPoint),\n                    message=\"Geometry must be Point or MultiPoint\",\n                )\n            signals = []\n            pixels = []\n            for p in points:\n                signals.append(image_xarr.sel(x=p.x, y=p.y, method=\"nearest\").values)\n                pixels.append((p.x, p.y))\n\n            signatures.append(Signatures.from_signals_and_pixels(signals, pixels))\n\n    else:\n        for hull in shape.convex_hull:\n            minx, miny, maxx, maxy = hull.bounds\n\n            x_coords = image_xarr.x[(image_xarr.x &gt;= minx) &amp; (image_xarr.x &lt;= maxx)].values\n            y_coords = image_xarr.y[(image_xarr.y &gt;= miny) &amp; (image_xarr.y &lt;= maxy)].values\n\n            if len(x_coords) == 0 or len(y_coords) == 0:\n                continue\n\n            # Create a prepared geometry for faster contains check\n            prepared_hull = shapely_prep(hull)\n\n            signals = []\n            pixels = []\n            for x, y in itertools.product(x_coords, y_coords):\n                point = Point(x, y)\n                # Check if point is: inside the hull or intersects with the hull\n                if prepared_hull.contains(point) or prepared_hull.intersects(point):\n                    try:\n                        signal = image_xarr.sel(x=x, y=y).values\n                    except (KeyError, IndexError):\n                        continue\n                    signals.append(signal)\n                    pixels.append((x, y))\n\n            signatures.append(Signatures.from_signals_and_pixels(signals, pixels))\n\n    return signatures\n</code></pre>"},{"location":"concepts/datasets/","title":"Datasets","text":"API Documentation <p><code>siapy.datasets</code></p> <p>The datasets module provides structured containers and utilities for transforming spectral image data into formats optimized for analysis and machine learning. It bridges the gap between raw spectral data and analytical workflows.</p> <pre><code>import numpy as np\nfrom rich import print\n\nfrom siapy.datasets.tabular import TabularDataset\nfrom siapy.entities import Shape, SpectralImage, SpectralImageSet\n\n# Create two mock spectral images with dimensions 100x100 pixels and 10 bands\nrng = np.random.default_rng(seed=42)\nimage1 = SpectralImage.from_numpy(rng.random((100, 100, 10)))\nimage2 = SpectralImage.from_numpy(rng.random((100, 100, 10)))\n\n# Define a region of interest as a rectangular shape (coordinates in pixel space)\n# This will select pixels from position (50,50) to (80,80) in both images\nrectangle = Shape.from_rectangle(x_min=50, y_min=50, x_max=80, y_max=80)\nimage1.geometric_shapes.append(rectangle)\nimage2.geometric_shapes.append(rectangle)\n\n# Combine the images into a SpectralImageSet for batch processing\nimage_set = SpectralImageSet([image1, image2])\n\n# Initialize the TabularDataset with our image set and process the data\n# This extracts pixel data from the regions defined by our shapes\ndataset = TabularDataset(image_set)\ndataset.process_image_data()\n\n# The dataset is now iterable - we can access each entity (processed region)\nfor entity in dataset:\n    print(f\"Processing entity: {entity}\")\n\n# Generate tabular data from our processed dataset\n# Setting mean_signatures=False preserves individual pixel values instead of averaging them\ndataset_data = dataset.generate_dataset_data(mean_signatures=False)\n\n# Convert the tabular data to a pandas DataFrame with multi-level indexing\n# This makes it easy to analyze and manipulate the data\ndf = dataset_data.to_dataframe_multiindex()\n\nprint(f\"dataset_data: \\n{dataset_data}\")\nprint(f\"df: \\n{df}\")\n</code></pre>"},{"location":"concepts/entities/","title":"Entities","text":"API Documentation <p><code>siapy.entities</code></p> <p>Entities serve as the foundational data structures in SiaPy, representing key elements of spectral image analysis and processing workflows. They implement consistent, strongly-typed interfaces that allow seamless interaction between spectral data, spatial coordinates, and geometric information.</p>"},{"location":"concepts/entities/#module-architecture","title":"Module architecture","text":"<p>The relationships between components are shown in the following diagram:</p> <p></p>"},{"location":"concepts/entities/#design-principles","title":"Design principles","text":"<p>SiaPy's architecture follows several key design principles:</p> <p>Specialized yet compatible: Each entity is optimized for its specific role while maintaining compatibility with the broader SiaPy ecosystem</p> <p>Independence: Most entities can function independently (with the exception of abstract base classes)</p> <p>Composition over inheritance:</p> <ul> <li>The composition is preferred, so that one class can leverage another by injecting it into its architecture</li> <li>Inheritance is primarily used to implement common interfaces through base classes</li> </ul> <p>Extensibility:</p> <ul> <li>The <code>SpectralImage</code> class supports multiple data sources through spectral or rasterio libraries, however, custom data loading can be implemented by creating your own driver</li> <li>Basic geometric shapes (e.g. points, lines, polygons) are implemented using the shapely library, which could also be extended through base abstraction</li> </ul>"},{"location":"concepts/entities/#visual-representation-of-spectral-entities","title":"Visual representation of spectral entities","text":"<p>The components follow standard naming conventions for spectral image analysis. A <code>SpectralImage</code> represents a three-dimensional data cube (height \u00d7 width \u00d7 bands). Each pixel in this cube has spatial coordinates (x, y) and a corresponding spectral signal with values across all bands.</p> <p>A signature combines a pixel's spatial location with its spectral signal, creating a complete spatial-spectral data point. The <code>Signatures</code> class serves as a container for multiple such data points, enabling analysis across collections of pixels.</p> <p>Since spectral images often contain distinct objects with different spectral properties, <code>Shapes</code> (regions of connected pixels) allow for extraction and analysis of specific areas. The <code>SpectralImage</code> class therefore integrates all primitive structures: <code>Pixels</code> and <code>Signals</code> by definition, and <code>Shapes</code> when attached to the image.</p> <p></p> Name What it represents Shape / size <code>Spectral image</code> A single hyperspectral or multispectral data cube. <code>(H, W, B)</code> \u2192 height \u00d7 width \u00d7 bands <code>Spectral image set</code> An ordered collection of <code>SpectralImage</code> objects. Think of it as a \u201cdataset\u201d with convenience methods that loop internally instead of in user code. N \u00d7 <code>SpectralImage</code> for N spectral images <code>Pixels</code> One Cartesian coordinate <code>(x, y)</code>. <code>(N, 2)</code> for N pixels <code>Shapes</code> A geometric region of interest (e.g. rectangle, polygon, circle), serving as a container of pixels. Vector geometry <code>Signatures</code> A collection of 1-D spectral signals <code>(B,)</code> tied to pixel values <code>(x, y)</code> or aggregated over a shape. <code>(N, B + 2)</code> \u2192 N signatures, each with B spectral bands plus <code>(x, y)</code> coordinates"},{"location":"concepts/entities/#pixels","title":"Pixels","text":"API Documentation <p><code>siapy.entities.Pixels</code></p> <p>The <code>Pixels</code> class represents spatial coordinates within spectral image, providing a container for (x, y) coordinate pairs. It uses pandas DataFrame internally for storage, enabling high-performance operations. The class provides multiple initialization methods and conversion functions to work with different data representations (i.e. DataFrames, list, arrays)</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom siapy.entities import Pixels\n\n# Create from pandas DataFrame\npixels1 = Pixels(pd.DataFrame({\"x\": [10, 20, 30], \"y\": [40, 50, 60]}))\n\n# Create from numpy array\npixels2 = Pixels.from_iterable(np.array([[10, 40], [20, 50], [30, 60]]))\n\n# Create from list of coordinates\npixels3 = Pixels.from_iterable([(10, 40), (20, 50), (30, 60)])\n\n# Should be the same\nassert pixels1 == pixels2 == pixels3\n</code></pre>"},{"location":"concepts/entities/#signals","title":"Signals","text":"API Documentation <p><code>siapy.entities.signatures.Signals</code></p> <p>The <code>Signals</code> class stores spectral data for each pixel in a pandas DataFrame, allowing you to use any column names you choose (e.g. \"band_1\", \"nir\", \"red_edge\"). You can initialize it from a DataFrame, lists, dicts or NumPy arrays.</p> <pre><code>from siapy.entities.signatures import Signals\n\n# Create from iterable (e.g. list, array)\nsignals = Signals.from_iterable([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n</code></pre> <p>However, direct initialization of <code>Signals</code> is typically not necessary in practice. When you create a <code>Signatures</code> instance, the underlying <code>Signals</code> object is automatically generated and managed for you. This section demonstrates the <code>Signals</code> class primarily to illustrate how the <code>Signatures</code> class (discussed next) is composed internally and to provide insight into the data structure that powers spectral analysis.</p>"},{"location":"concepts/entities/#signatures","title":"Signatures","text":"API Documentation <p><code>siapy.entities.Signatures</code></p> <p>The <code>Signatures</code> class represents spectral data collections by combining spatial coordinates (<code>Pixels</code>) with their corresponding spectral values (<code>Signals</code>). It provides a unified container that maintains the spatial-spectral relationship, allowing for analysis of spectral information at specific image locations. Internally, the data is stored as pandas DataFrames for efficient operations and indexing.</p> <p><code>Signatures</code> can be initialized in multiple ways. The explicit approach creates each component separately before combining them, providing clarity about the composition:</p> <pre><code>import pandas as pd\nfrom rich import print\n\nfrom siapy.entities import Pixels, Signatures\nfrom siapy.entities.signatures import Signals\n\n# Option 1: Step-by-step initialization\n# Initialize Pixels object from a DataFrame\npixels_df = pd.DataFrame({\"x\": [10, 30], \"y\": [20, 40]})\npixels = Pixels(pixels_df)\n\n# Initialize Signals object from a DataFrame\nsignals_df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\nsignals = Signals(signals_df)\n\n# Create Signatures object from Pixels and Signals objects\nsignatures1 = Signatures(pixels, signals)\n</code></pre> <p>For more concise code, you can initialize a <code>Signatures</code> object directly from coordinate and signal values:</p> <pre><code># Option 2: Direct initialization with raw data\n# Initialize Signatures directly from raw signals and coordinates data\nsignatures2 = Signatures.from_signals_and_pixels(\n    signals=[[1, 2, 3], [4, 5, 6]],\n    pixels=[[10, 20], [30, 40]],\n)\n</code></pre> <p>Both approaches yield equivalent results when initialized with the same data. You can access and work with the data using various DataFrame operations and conversion methods:</p> <pre><code># Verify that both approaches produce equivalent results\nassert signatures1 == signatures2\n\n# Print the DataFrame representation of Pixels and Signals\ndf_multi = signatures2.to_dataframe_multiindex()\nprint(f\"MultiIndex DataFrame:\\n{df_multi}\")\nprint(f\"Signals DataFrame:\\n{signatures2.signals.df}\")\nprint(f\"Pixels DataFrame:\\n{signatures2.pixels.df}\")\n</code></pre>"},{"location":"concepts/entities/#shape","title":"Shape","text":"API Documentation <p><code>siapy.entities.Shape</code></p> <p>The <code>Shape</code> class represents geometric shapes that can be associated with images, such as points, lines, and polygons.</p> <pre><code>from siapy.entities import Pixels, Shape\n\n# Create a point\npoint = Shape.from_point(10, 20)\n\n# Create a polygon from pixels\npixels = Pixels.from_iterable([(0, 0), (10, 0), (10, 10), (0, 10)])\npolygon = Shape.from_polygon(pixels)\n\n# Load from shapefile\nshape = Shape.open_shapefile(\"path/to/shapefile.shp\")\n</code></pre>"},{"location":"concepts/entities/#spectral-image","title":"Spectral Image","text":"API Documentation <p><code>siapy.entities.SpectralImage</code></p> <p>A <code>SpectralImage</code> is the primary container for spectral image data. It's a generic class that can wrap different image backends, allowing you to work with various file formats through a unified interface.</p>"},{"location":"concepts/entities/#image-initialization-options","title":"Image Initialization Options","text":""},{"location":"concepts/entities/#1-load-from-envi-format-using-spectral-python","title":"1. Load from ENVI format (using spectral python)","text":"<p>This is commonly used for hyperspectral imagery from airborne or satellite sensors.</p> <pre><code>from siapy.entities import SpectralImage\nfrom siapy.entities.images import SpectralLibImage\n\n# Load from ENVI format (uses spectral python library)\nimage_sp = SpectralLibImage.open(\n    header_path=\"path/to/header.hdr\",\n    image_path=\"path/to/image.img\",\n)\nimage = SpectralImage(image_sp)\n\n# Or you can use the class method to load the image directly\nimage = SpectralImage.spy_open(\n    header_path=\"path/to/header.hdr\",\n    image_path=\"path/to/image.img\",\n)\n</code></pre>"},{"location":"concepts/entities/#2-load-from-geotiff-or-other-geospatial-formats-using-rasterio","title":"2. Load from GeoTIFF or other geospatial formats (using rasterio)","text":"<p>Perfect for georeferenced data with spatial information.</p> <pre><code>from siapy.entities import SpectralImage\nfrom siapy.entities.images import RasterioLibImage\n\n# Load from GeoTIFF or other raster formats (uses rioxarray/rasterio python library)\nimage_rio = RasterioLibImage.open(\n    filepath=\"path/to/image.tif\",\n)\nimage = SpectralImage(image_rio)\n\n# Or you can use the class method to load the image directly\nimage = SpectralImage.rasterio_open(filepath=\"path/to/image.tif\")\n</code></pre>"},{"location":"concepts/entities/#3-create-from-numpy-array","title":"3. Create from numpy array","text":"<p>Useful for testing or when you already have image data in memory.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import SpectralImage\n\n# Create a SpectralImage from a numpy array - mostly for testing\narray = np.zeros((100, 100, 10))  # height, width, bands\nimage = SpectralImage.from_numpy(array)\n</code></pre>"},{"location":"concepts/entities/#4-create-your-own-custom-image-class","title":"4. Create your own custom image class","text":"<p>For specialized file formats or custom processing needs, you can extend the ImageBase class.</p> <pre><code>from pathlib import Path\nfrom typing import TYPE_CHECKING, Any, cast\n\nimport numpy as np\nimport xarray as xr\nfrom numpy.typing import NDArray\nfrom PIL import Image\n\nfrom siapy.core.exceptions import InvalidFilepathError\nfrom siapy.entities import SpectralImage\nfrom siapy.entities.images import ImageBase\n\nif TYPE_CHECKING:\n    from siapy.core.types import XarrayType\n\n\nclass MyImage(ImageBase):\n    \"\"\"\n    # Create your own image class by extending ImageBase\n    # This example demonstrates how to implement a custom image loader\n    \"\"\"\n\n    def __init__(self, data: NDArray[np.floating[Any]], file_path: Path) -&gt; None:\n        self._data = data\n        self._filepath = file_path\n\n        # Define metadata with required fields:\n        # - camera_id: unique identifier for the imaging device\n        # - wavelengths: list of spectral band centers in nanometers\n        # - default_bands: which bands to use for RGB visualization\n        self._meta: dict[str, Any] = {\n            \"camera_id\": \"my_camera\",\n            \"wavelengths\": [450.0, 550.0, 650.0],  # RGB wavelengths in nm\n            \"default_bands\": [0, 1, 2],  # Band indices for RGB display\n        }\n\n    @classmethod\n    def open(cls, filepath: str) -&gt; \"MyImage\":\n        \"\"\"Load an image from a file path\"\"\"\n        path = Path(filepath)\n        if not path.exists():\n            raise InvalidFilepathError(f\"File not found: {filepath}\")\n\n        try:\n            # This is a simplified example - in a real implementation,\n            # you would read the actual image data using an appropriate library\n            # For example purposes, creating a small random array\n            data = np.random.random((100, 100, 3)).astype(np.float32)\n            return cls(data, path)\n        except Exception as e:\n            raise InvalidFilepathError(f\"Failed to open {filepath}: {str(e)}\")\n\n    # Required properties (all must be implemented)\n\n    @property\n    def filepath(self) -&gt; Path:\n        \"\"\"Path to the source file\"\"\"\n        return self._filepath\n\n    @property\n    def metadata(self) -&gt; dict[str, Any]:\n        \"\"\"Image metadata dictionary\"\"\"\n        return self._meta\n\n    @property\n    def shape(self) -&gt; tuple[int, int, int]:\n        \"\"\"Image dimensions as (height, width, bands)\"\"\"\n        return cast(tuple[int, int, int], self._data.shape)\n\n    @property\n    def bands(self) -&gt; int:\n        \"\"\"Number of spectral bands\"\"\"\n        return self.shape[2]\n\n    @property\n    def default_bands(self) -&gt; list[int]:\n        \"\"\"Indices of bands to use for RGB visualization\"\"\"\n        return self._meta[\"default_bands\"]\n\n    @property\n    def wavelengths(self) -&gt; list[float]:\n        \"\"\"Center wavelengths of each band in nanometers\"\"\"\n        return self._meta[\"wavelengths\"]\n\n    @property\n    def camera_id(self) -&gt; str:\n        \"\"\"Unique identifier for the imaging device\"\"\"\n        return self._meta[\"camera_id\"]\n\n    # Required methods (all must be implemented)\n\n    def to_display(self, equalize: bool = True) -&gt; Image.Image:\n        \"\"\"Convert to PIL Image for display\"\"\"\n        # Extract the default bands for RGB visualization\n        rgb_data = self._data[:, :, self.default_bands].copy()\n\n        if equalize:\n            # Apply linear contrast stretching to each band\n            for i in range(rgb_data.shape[2]):\n                band = rgb_data[:, :, i]\n                min_val = np.min(band)\n                max_val = np.max(band)\n                if max_val &gt; min_val:\n                    rgb_data[:, :, i] = (band - min_val) / (max_val - min_val)\n\n        # Convert to 8-bit for PIL\n        rgb_uint8 = (rgb_data * 255).astype(np.uint8)\n        return Image.fromarray(rgb_uint8)\n\n    def to_numpy(self, nan_value: float | None = None) -&gt; NDArray[np.floating[Any]]:\n        \"\"\"Convert to numpy array\"\"\"\n        result = self._data.copy()\n        if nan_value is not None:\n            result[np.isnan(result)] = nan_value\n        return result\n\n    def to_xarray(self) -&gt; \"XarrayType\":\n        \"\"\"Convert to xarray DataArray with coordinates\"\"\"\n        return xr.DataArray(\n            self._data,\n            dims=[\"y\", \"x\", \"band\"],\n            coords={\n                \"y\": np.arange(self.shape[0]),\n                \"x\": np.arange(self.shape[1]),\n                \"band\": self.wavelengths,\n            },\n            attrs=self.metadata,\n        )\n\n\n# Example: Using your custom image class with SiaPy\n# 1. Create an instance of your custom image class\ncustom_image = MyImage.open(\"path/to/your/image.dat\")\n\n# 2. Wrap it in a SpectralImage for use with SiaPy's analysis tools\nspectral_image = SpectralImage(custom_image)\n\n# 3. Now you can use all SiaPy functionality\n# spectral_image.to_signatures(pixels)\n# etc.\n</code></pre>"},{"location":"concepts/entities/#data-conversion-methods","title":"Data conversion methods","text":"<p>The example below demonstrates two key conversion methods of <code>SpectralImage</code> instance:</p> <ol> <li><code>to_signatures()</code>: Extracts spectral data from specific pixel coordinates and returns a <code>Signatures</code> object that maintains the spatial-spectral relationship</li> <li><code>to_subarray()</code>: Converts selected pixel data to a NumPy array for numerical processing or integration with other scientific libraries</li> </ol> <pre><code>import numpy as np\nfrom rich import print\n\nfrom siapy.entities import Pixels, SpectralImage\n\n# Create mock image\nrng = np.random.default_rng(seed=42)\narray = rng.random((100, 100, 10))  # height, width, bands\nimage = SpectralImage.from_numpy(array)\n\n# Define pixels\niterable = [(1, 2), (3, 4), (2, 4)]\npixels = Pixels.from_iterable(iterable)\n\n# Get signatures\nsignatures = image.to_signatures(pixels)\nprint(f\"Signatures:\\n{signatures}\")\n\n# Get numpy array\nsubarray = image.to_subarray(pixels)\nprint(f\"Subarray:\\n{subarray}\")\n\"\"\"\n? Note:\n    The extracted block has shape (3, 3, 10): a 3 \u00d7 3 pixel window across 10 spectral bands.\n    Values are populated only at the requested pixel coordinates; all other elements are set to NaN.\n\"\"\"\n</code></pre>"},{"location":"concepts/entities/#manipulation-of-shapes","title":"Manipulation of Shapes","text":"<p>Each <code>SpectralImage</code> instance automatically initializes a <code>GeometricShapes</code> object as a property called <code>geometric_shapes</code>. This property provides a container for managing shape objects associated with the image. It lets you work with image regions while maintaining the connection between spatial geometries and their spectral data. This is particularly useful for region-based analysis, masking, and feature extraction from specific areas of interest.</p> <p>The <code>GeometricShapes</code> class provides a list-like interface that wraps a standard Python list, enhancing it with specialized functionality for manipulating geometric shapes while preserving standard list behavior. The list of shapes can be accessed via the <code>image.geometric_shapes.shapes</code> property.</p> <pre><code>import numpy as np\nfrom rich import print\n\nfrom siapy.entities import Shape, SpectralImage\nfrom siapy.entities.shapes import GeometricShapes\n\n# Create a mock spectral image\nrng = np.random.default_rng(seed=42)\narray = rng.random((100, 100, 10))  # height, width, bands\nimage = SpectralImage.from_numpy(array)\n\n# SpectralImage automatically initializes GeometricShapes\nassert isinstance(image.geometric_shapes, GeometricShapes)\n# You can access the underlying list via the shapes property\nassert isinstance(image.geometric_shapes.shapes, list)\n\n# GeometricShapes implements common list operations directly, i.e. number of shapes:\nlength_via_geometric_shapes = len(image.geometric_shapes)\nlength_via_raw_list = len(image.geometric_shapes.shapes)\n</code></pre> <p>As a result, shapes can be added to the spectral image using standard list operations. The example below demonstrates how this can be done:</p> <pre><code># Create two Shape objects with distinct spatial coordinates and semantic labels\ncoords1 = [(1, 2), (3, 4), (2, 4)]\nshape1 = Shape.from_multipoint(coords1, label=\"coords1\")\ncoords2 = [(19, 20), (21, 22), (20, 22)]\nshape2 = Shape.from_multipoint(coords2, label=\"coords2\")\n\n# Add multiple shapes to the SpectralImage's geometric_shapes container at once\nimage.geometric_shapes.extend([shape1, shape2])\n\n# Display the current collection of shapes stored in the image\n# Each shape will be shown with its type and label\nprint(f\"Shapes in GeometricShapes: {image.geometric_shapes}\")\n</code></pre>"},{"location":"concepts/entities/#spectral-image-set","title":"Spectral Image Set","text":"API Documentation <p><code>siapy.entities.SpectralImageSet</code></p> <p>The <code>SpectralImageSet</code> class manages a collection of spectral images.</p> <pre><code>from pathlib import Path\n\nfrom siapy.entities import SpectralImageSet\n\n# Load multiple images\nheader_paths = list(Path(\"data_dir\").glob(\"*.hdr\"))\nimage_paths = list(Path(\"data_dir\").glob(\"*.img\"))\nimage_set = SpectralImageSet.spy_open(header_paths=header_paths, image_paths=image_paths)\n\n# Iterate over the images\nfor image in image_set:\n    print(image)\n</code></pre>"},{"location":"concepts/features/","title":"Features","text":"API Documentation <p><code>siapy.features</code></p> <p>The features module provides automated feature engineering and selection capabilities specifically designed for spectral data analysis.</p>"},{"location":"concepts/features/#spectral-indices","title":"Spectral Indices","text":"API Documentation <p><code>siapy.features.spectral_indices</code></p> <p>Spectral indices are mathematical combinations of spectral bands that highlight specific characteristics of materials or conditions. The module provides functions to discover available indices and compute them from spectral data.</p>"},{"location":"concepts/features/#getting-available-indices","title":"Getting available indices","text":"<p>The <code>get_spectral_indices()</code> function returns all spectral indices that can be computed from the available bands:</p> <pre><code>from siapy.features.spectral_indices import get_spectral_indices\n\n# Get indices computable from Red and Green bands\nbands = [\"R\", \"G\"]\navailable_indices = get_spectral_indices(bands)\nprint(f\"Found {len(available_indices)} indices\")\n\n# Display the names and long names of the available indices\nfor name, index in list(available_indices.items()):\n    print(f\"{name}: {index.long_name}\")\n</code></pre>"},{"location":"concepts/features/#computing-spectral-indices","title":"Computing spectral indices","text":"<p>The <code>compute_spectral_indices()</code> function calculates spectral indices from DataFrame data:</p> <pre><code>import numpy as np\nimport pandas as pd\n\nfrom siapy.features.spectral_indices import compute_spectral_indices\n\n# Create sample spectral data\nnp.random.seed(42)\ndata = pd.DataFrame(\n    {\n        \"R\": np.random.random(100),\n        \"G\": np.random.random(100),\n    }\n)\n\nindices_df = compute_spectral_indices(\n    data=data,\n    spectral_indices=[\"BIXS\", \"RI\"],  # Indices to compute\n)\nprint(f\"Computed indices\\n: {indices_df.head()}\")\n</code></pre>"},{"location":"concepts/features/#band-mapping","title":"Band mapping","text":"<p>When your data uses non-standard column names, use the <code>bands_map</code> parameter:</p> <pre><code># Data with custom column names\ncustom_data = pd.DataFrame(\n    {\"red_band\": np.random.random(100), \"green_band\": np.random.random(100), \"nir_band\": np.random.random(100)}\n)\n\n# Map custom names to standard band acronyms\nbands_map = {\"red_band\": \"R\", \"green_band\": \"G\", \"nir_band\": \"N\"}\n\nindices_df = compute_spectral_indices(data=custom_data, spectral_indices=[\"NDVI\", \"GNDVI\"], bands_map=bands_map)\n</code></pre>"},{"location":"concepts/features/#automatic-features-generation","title":"Automatic features generation","text":"API Documentation <p><code>siapy.features.AutoFeatClassification</code> <code>siapy.features.AutoFeatRegression</code> <code>siapy.features.AutoSpectralIndicesClassification</code> <code>siapy.features.AutoSpectralIndicesRegression</code></p>"},{"location":"concepts/features/#mathematically-extracted-features","title":"Mathematically extracted features","text":"<p>The AutoFeat classes provide deterministic wrappers around the AutoFeat library, which automatically generates and selects engineered features through symbolic regression.</p> <pre><code>import pandas as pd\nfrom sklearn.datasets import make_classification\n\nfrom siapy.features import AutoFeatClassification\n\n# Generate sample data\nX, y = make_classification(n_samples=200, n_features=5, random_state=42)\ndata = pd.DataFrame(X, columns=[f\"f{i}\" for i in range(5)])\ntarget = pd.Series(y)\n\n# Create and configure AutoFeat\nautofeat = AutoFeatClassification(\n    random_seed=42,  # For reproducibility\n    verbose=1,  # Show progress\n)\n\n# Fit and transform\nfeatures_engineered = autofeat.fit_transform(data, target)\nprint(f\"Original features: {data.shape[1]}\")\nprint(f\"Engineered features: {features_engineered.shape[1]}\")\n</code></pre>"},{"location":"concepts/features/#features-extracted-using-spectral-indices","title":"Features extracted using spectral indices","text":"<p>These classes integrate spectral index computation with automated feature selection, offering end-to-end pipelines for identifying the most relevant spectral indices.</p> <pre><code>import pandas as pd\nfrom sklearn.datasets import make_classification\n\nfrom siapy.features import AutoSpectralIndicesClassification\nfrom siapy.features.helpers import FeatureSelectorConfig\nfrom siapy.features.spectral_indices import get_spectral_indices\n\n# Create spectral-like data\nX, y = make_classification(n_samples=300, n_features=4, random_state=42)\ndata = pd.DataFrame(X, columns=[\"R\", \"G\", \"B\", \"N\"])  # Red, Green, Blue, NIR\ntarget = pd.Series(y)\n\n# Get available spectral indices\navailable_indices = get_spectral_indices([\"R\", \"G\", \"B\", \"N\"])\nprint(f\"Available indices: {len(available_indices)}\")\n\n# Configure feature selection\nconfig = FeatureSelectorConfig(\n    k_features=(5, 20),  # Select 5-20 best indices\n    cv=5,  # Cross-validation for feature selection\n    verbose=1,\n)\n\n# Create automated spectral indices classifier\nauto_spectral = AutoSpectralIndicesClassification(\n    spectral_indices=list(available_indices.keys()),\n    selector_config=config,\n    merge_with_original=True,  # Include original bands\n)\n\n# Fit and transform\nenhanced_features = auto_spectral.fit_transform(data, target)\nprint(f\"\\nOriginal features: {data.shape[1]}\")\nprint(f\"Enhanced features: {enhanced_features.shape[1]}\")\n</code></pre>"},{"location":"concepts/features/#integration-with-siapy-enitites","title":"Integration with siapy enitites","text":"<p>The features module integrates seamlessly with siapy entity system.</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_classification\n\nfrom siapy.entities import Pixels, Signatures, SpectralImage\nfrom siapy.features import AutoSpectralIndicesClassification\nfrom siapy.features.helpers import FeatureSelectorConfig\nfrom siapy.features.spectral_indices import compute_spectral_indices, get_spectral_indices\n\n# Create a mock spectral image with 4 bands (Red, Green, Blue, Near-infrared)\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((50, 50, 4))  # height, width, bands (R, G, B, N)\nimage = SpectralImage.from_numpy(image_array)\n\n# Define region of interest (ROI) pixels for sampling\nroi_pixels = Pixels.from_iterable(\n    [(10, 15), (12, 18), (15, 20), (18, 22), (20, 25), (25, 30), (28, 32), (30, 35), (32, 38), (35, 40)]\n)\n\n# Extract spectral signatures from ROI pixels\nsignatures = image.to_signatures(roi_pixels)\nprint(f\"Extracted {len(signatures)} signatures from the image\")\n\n# Convert signatures to DataFrame and assign standard band names\nspectral_data = signatures.signals.df.copy()\nspectral_data = spectral_data.rename(columns=dict(zip(spectral_data.columns, [\"R\", \"G\", \"B\", \"N\"])))\n\n# Create synthetic classification labels for demonstration purposes\n_, y = make_classification(n_samples=len(spectral_data), n_features=4, random_state=42)\ntarget = pd.Series(y[: len(spectral_data)])\n\n# Get all spectral indices that can be computed with available bands\navailable_indices = get_spectral_indices([\"R\", \"G\", \"B\", \"N\"])\nprint(f\"Found {len(available_indices)} computable spectral indices\")\n\n# Method 1: Manually compute spectral indices\nindices_df = compute_spectral_indices(\n    data=spectral_data,\n    spectral_indices=list(available_indices.keys())[:10],  # Use first 10 indices\n)\nprint(f\"Computed {indices_df.shape[1]} spectral indices\")\n\n# Method 2: Automated feature selection with spectral indices\n# Configure the feature selector\nconfig = FeatureSelectorConfig(\n    k_features=5,  # Select 5 best performing indices\n    cv=3,  # Use 3-fold cross-validation\n    verbose=0,\n)\n\n# Create automated selector that finds optimal spectral indices\nauto_spectral = AutoSpectralIndicesClassification(\n    spectral_indices=list(available_indices.keys())[:15],  # Use first 15 indices as candidates\n    selector_config=config,\n    merge_with_original=False,  # Return only selected indices, not original bands\n)\n\n# Apply feature selection to find the best spectral indices\nselected_features = auto_spectral.fit_transform(spectral_data, target)\nprint(f\"Selected {selected_features.shape[1]} optimal spectral indices\")\n\n# Create new signatures object with selected features\nenhanced_signatures = Signatures.from_signals_and_pixels(signals=selected_features, pixels=signatures.pixels)\nprint(f\"Created enhanced signatures with shape: {enhanced_signatures.signals.df.shape}\")\n\n# Display results - the enhanced signatures contain only the most informative spectral indices\nprint(f\"Enhanced signatures DataFrame:\\n{enhanced_signatures.to_dataframe().head()}\")\n</code></pre>"},{"location":"concepts/optimizers/","title":"Optimizers","text":"API Documentation <p><code>siapy.optimizers</code></p> <p>The optimizers module provides hyperparameter optimization capabilities for machine learning models used in spectral data analysis. It integrates with Optuna for efficient hyperparameter search and includes other evaluation tools.</p>"},{"location":"concepts/optimizers/#tabular-optimizer","title":"Tabular Optimizer","text":"API Documentation <p><code>siapy.optimizers.optimizers.TabularOptimizer</code> <code>siapy.optimizers.configs.TabularOptimizerConfig</code></p> <p>The <code>TabularOptimizer</code> class provides automated hyperparameter optimization for sklearn-compatible models using tabular spectral data.</p> <pre><code>from sklearn.datasets import make_regression\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom siapy.optimizers.configs import OptimizeStudyConfig, TabularOptimizerConfig\nfrom siapy.optimizers.optimizers import TabularOptimizer\nfrom siapy.optimizers.parameters import TrialParameters\nfrom siapy.optimizers.scorers import Scorer\n\n# Create a simple model\nmodel = RandomForestRegressor(random_state=42)\n\n# Choose a scoring strategy for model evaluation\n# Option 1: Use cross-validation (recommended for small datasets)\nscorer = Scorer.init_cross_validator_scorer(\n    scoring=\"neg_mean_squared_error\",\n    cv=3,  # 3-fold cross-validation\n)\n\n# Option 2: Use a hold-out validation set (recommended for larger datasets)\n# scorer = Scorer.init_hold_out_scorer(\n#     scoring=\"neg_mean_squared_error\",\n#     test_size=0.2,  # 20% of data used for validation\n# )\n\n# Define trial parameters for hyperparameter optimization\ntrial_parameters = TrialParameters.from_dict(\n    {\n        \"int_parameters\": [\n            {\"name\": \"n_estimators\", \"low\": 10, \"high\": 100},\n            {\"name\": \"max_depth\", \"low\": 3, \"high\": 10},\n        ]\n    }\n)\n\n# Create configuration for optimization\nconfig = TabularOptimizerConfig(\n    scorer=scorer,\n    trial_parameters=trial_parameters,\n    optimize_study=OptimizeStudyConfig(\n        n_trials=10,  # Number of trials to run\n        timeout=300.0,  # 5 minutes\n        n_jobs=1,  # Use a single processor for simplicity\n    ),\n)\n\n# Mock dataset\nX, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\n\n# Create optimizer from dataset\noptimizer = TabularOptimizer(model=model, configs=config, X=X, y=y)\n\n# Run optimization\nstudy = optimizer.run()\nbest_model = optimizer.get_best_model()\n</code></pre>"},{"location":"concepts/optimizers/#trial-parameters","title":"Trial Parameters","text":"API Documentation <p><code>siapy.optimizers.parameters.TrialParameters</code> <code>siapy.optimizers.parameters.IntParameter</code> <code>siapy.optimizers.parameters.FloatParameter</code> <code>siapy.optimizers.parameters.CategoricalParameter</code></p> <p>Trial parameters define the hyperparameter search space for optimization. You can specify integer, float, and categorical parameters:</p> <pre><code>from siapy.optimizers.parameters import (\n    CategoricalParameter,\n    FloatParameter,\n    IntParameter,\n    TrialParameters,\n)\n\n# Define individual parameters\nn_estimators_param = IntParameter(name=\"n_estimators\", low=10, high=200, step=10)\nlearning_rate_param = FloatParameter(name=\"learning_rate\", low=0.01, high=0.3, log=True)\nalgorithm_param = CategoricalParameter(name=\"algorithm\", choices=[\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"])\n\n# Create trial parameters\ntrial_parameters = TrialParameters(\n    int_parameters=[n_estimators_param],\n    float_parameters=[learning_rate_param],\n    categorical_parameters=[algorithm_param],\n)\n\n# Alternative: create from dictionary\ntrial_parameters_from_dict = TrialParameters.from_dict(\n    {\n        \"int_parameters\": [{\"name\": \"n_estimators\", \"low\": 10, \"high\": 200, \"step\": 10}],\n        \"float_parameters\": [{\"name\": \"learning_rate\", \"low\": 0.01, \"high\": 0.3, \"log\": True}],\n        \"categorical_parameters\": [{\"name\": \"algorithm\", \"choices\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]}],\n    }\n)\n</code></pre>"},{"location":"concepts/optimizers/#scorers","title":"Scorers","text":"API Documentation <p><code>siapy.optimizers.scorers.Scorer</code></p> <p>Scorers define how model performance is evaluated during optimization.</p>"},{"location":"concepts/optimizers/#cross-validation-scorer","title":"Cross-validation scorer","text":"<p>Use cross-validation for robust model evaluation:</p> <pre><code>from sklearn.model_selection import RepeatedKFold\n\nfrom siapy.optimizers.scorers import Scorer\n\n# Basic cross-validation scorer\ncv_scorer = Scorer.init_cross_validator_scorer(scoring=\"accuracy\", cv=5)\n\n# Advanced cross-validation with custom CV strategy\nrepeated_cv = RepeatedKFold(n_splits=3, n_repeats=5, random_state=42)\nadvanced_scorer = Scorer.init_cross_validator_scorer(\n    scoring=\"f1_weighted\",\n    cv=repeated_cv,\n    n_jobs=-1,  # Use all processors\n)\n\n# Cross-validation with repeated splits (string shortcut)\nrepeated_scorer = Scorer.init_cross_validator_scorer(scoring=\"neg_mean_squared_error\", cv=\"RepeatedKFold\")\n</code></pre>"},{"location":"concepts/optimizers/#hold-out-scorer","title":"Hold-out scorer","text":"<p>Use hold-out validation for faster evaluation:</p> <pre><code>from siapy.optimizers.scorers import Scorer\n\n# Classification hold-out scorer\nholdout_scorer = Scorer.init_hold_out_scorer(scoring=\"accuracy\", test_size=0.2)\n\n# Regression hold-out scorer\nregression_scorer = Scorer.init_hold_out_scorer(scoring=\"neg_mean_absolute_error\", test_size=0.25)\n</code></pre>"},{"location":"concepts/optimizers/#integration-with-siapy-entities","title":"Integration with siapy entities","text":"<p>The optimizers module integrates seamlessly with the siapy entity system.</p> <pre><code>import numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\n\nfrom siapy.datasets.schemas import RegressionTarget\nfrom siapy.datasets.tabular import TabularDataset\nfrom siapy.entities import Shape, SpectralImage, SpectralImageSet\nfrom siapy.optimizers.configs import CreateStudyConfig, OptimizeStudyConfig, TabularOptimizerConfig\nfrom siapy.optimizers.optimizers import TabularOptimizer\nfrom siapy.optimizers.parameters import TrialParameters\nfrom siapy.optimizers.scorers import Scorer\n\n# ========================================================================\n# STEP 1: Create Mock Spectral Data for Demonstration\n# ========================================================================\n\n# Initialize random number generator for reproducible results\nrng = np.random.default_rng(seed=42)\n\n# Define a rectangular region of interest (ROI) within our images\n# This simulates selecting a specific area for analysis (e.g., crop field, water body)\nrectangle = Shape.from_rectangle(x_min=10, y_min=15, x_max=20, y_max=30)\n\n# Generate two mock spectral images with 4 spectral bands each\n# In real applications, these would be actual hyperspectral/multispectral images\n# Shape: (height=50, width=50, bands=4)\nimage1 = SpectralImage.from_numpy(rng.random((50, 50, 4)))\nimage2 = SpectralImage.from_numpy(rng.random((50, 50, 4)))\n\n# Attach the same region of interest to both images\n# This ensures we analyze the same spatial area across all images\nimage1.geometric_shapes.append(rectangle)\nimage2.geometric_shapes.append(rectangle)\n\n# Combine individual images into a spectral image set\n# This allows us to process multiple images together\nimage_set = SpectralImageSet([image1, image2])\n\n# ========================================================================\n# STEP 2: Convert Spectral Images to Tabular Dataset\n# ========================================================================\n\n# Create a tabular dataset from our spectral image set\n# This extracts pixel values from the ROI and organizes them in a table format\ndataset = TabularDataset(image_set)\n\n# Process the image data to extract spectral signatures from the defined ROI\n# This step converts spatial pixel data into a structured format for analysis\ndataset.process_image_data()\n\n# Generate the actual dataset with individual pixel signatures (not averaged)\n# Setting mean_signatures=False keeps each pixel as a separate data point\ndataset_data = dataset.generate_dataset_data(mean_signatures=False)\n\n# Display the structure of our extracted data\n# This shows how spectral values are organized in tabular format\nprint(f\"Dataframe: {dataset_data.to_dataframe().head()}\")\n\n# ========================================================================\n# STEP 3: Create Target Variables for Regression\n# ========================================================================\n\n# Create synthetic regression target values for demonstration\n# In real applications, these would be actual measurements (e.g., soil moisture, vegetation health)\nvalues = pd.Series(rng.random(len(dataset_data.signatures.signals)))\ntarget = RegressionTarget(value=values)\n\n# Attach the target values to our dataset\n# This creates a complete supervised learning dataset\ndataset_data = dataset_data.set_attributes(target=target)\n\n# ========================================================================\n# STEP 4: Setup Machine Learning Model, Parameters, Scorer and Configs\n# ========================================================================\n\n# Choose a machine learning model for regression\nmodel = RandomForestRegressor(random_state=42)\n\n# Define the hyperparameter search space for optimization\n# We'll optimize the number of estimators (trees) in the forest\n# The optimizer will try values from 10 to 100 in steps of 10\ntrial_parameters = TrialParameters.from_dict(\n    {\n        \"int_parameters\": [\n            {\"name\": \"n_estimators\", \"low\": 10, \"high\": 100, \"step\": 10},\n        ],\n    }\n)\n\n# Configure the scoring method for model evaluation\n# We use cross-validation with negative mean squared error (higher is better)\n# CV=3 means 3-fold cross-validation for more robust performance estimates\nscorer = Scorer.init_cross_validator_scorer(scoring=\"neg_mean_squared_error\", cv=3)\n\n# Create comprehensive optimizer configuration\nconfig = TabularOptimizerConfig(\n    scorer=scorer,  # How to evaluate model performance\n    trial_parameters=trial_parameters,  # What hyperparameters to optimize\n    optimize_study=OptimizeStudyConfig(\n        n_trials=50,  # Try 50 different hyperparameter combinations\n        n_jobs=-1,  # Use all available CPU cores for parallel processing\n    ),\n    create_study=CreateStudyConfig(\n        direction=\"maximize\",  # We want to maximize the score (minimize error)\n        study_name=\"RandomForestOptimizationStudy\",  # Name for tracking this optimization\n    ),\n)\n\n# ========================================================================\n# STEP 5: Execute Optimization and Retrieve Results\n# ========================================================================\n\n# Create the optimizer instance with our model, configuration, and data\n# This sets up everything needed for hyperparameter optimization\noptimizer = TabularOptimizer.from_tabular_dataset_data(model=model, configs=config, data=dataset_data)\n\n# Run the optimization process\n# This will test 50 different hyperparameter combinations and find the best one\nstudy = optimizer.run()\n\n# Get the best performing model with optimized hyperparameters\nbest_model = optimizer.get_best_model()\n\n# Display the optimization results\nprint(f\"Best trial: {optimizer.best_trial}\")\nif optimizer.best_trial is not None:\n    print(f\"Best parameters: {optimizer.best_trial.params}\")\n    print(f\"Best score: {optimizer.best_trial.value}\")\nelse:\n    print(\"No best trial found - optimization may have failed\")\n</code></pre>"},{"location":"concepts/overview/","title":"Library overview","text":""},{"location":"concepts/overview/#api-design-principles","title":"API design principles","text":"<p>SiaPy follows consistent method naming conventions to make the API intuitive and predictable. Understanding these conventions helps you navigate the library more effectively and write code that aligns with the project's style.</p> <p>Simple properties: Noun form for direct attribute access</p> <ul> <li>Examples: <code>image.geometric_shapes</code>, <code>pixels.df</code></li> <li>When to use: For quick, computationally inexpensive property access</li> </ul> <p>Expensive computations: Prefixed with <code>get_</code> for methods that require significant processing</p> <ul> <li>Examples: <code>pixels.get_coordinate()</code></li> <li>When to use: When the operation involves complex calculations or data retrieval</li> </ul> <p>Alternative constructors: Prefixed with <code>from_</code> for methods that create objects from different data sources</p> <ul> <li>Examples: <code>from_numpy()</code>, <code>from_dataframe()</code>, <code>from_shapefile()</code></li> <li>When to use: When creating an object from an existing data structure</li> </ul> <p>Data converters: Prefixed with <code>to_</code> for methods that transform data to another format</p> <ul> <li>Examples: <code>to_numpy()</code>, <code>to_dataframe()</code>, <code>to_geojson()</code></li> <li>When to use: When exporting data to another representation</li> </ul> <p>File operations:</p> <p>Prefixed with <code>open_</code> for reading data from file</p> <ul> <li>Examples: <code>open_envi()</code>, <code>open_shapefile()</code>, <code>open_csv()</code></li> </ul> <p>Prefixed with <code>save_</code> for writing data to file</p> <ul> <li>Examples: <code>save_to_csv()</code>, <code>save_to_geotiff()</code>, <code>save_as_json()</code></li> </ul> <p>Actions and processing:</p> <p>Verbs for operations that modify data or perform calculations</p> <ul> <li>Examples: <code>normalize()</code>, <code>calculate_ndvi()</code>, <code>extract_features()</code></li> </ul> <p>Plural forms for batch operations on multiple items</p> <ul> <li>Examples: <code>process_images()</code>, <code>extract_signatures()</code>, <code>calculate_indices()</code></li> </ul> <p>Boolean queries: Prefixed with <code>is_</code>, <code>has_</code>, or <code>can_</code> for methods returning boolean values</p> <ul> <li>Examples: <code>is_valid()</code>, <code>has_metadata()</code>, <code>can_transform()</code></li> <li>When to use: For methods that check conditions or properties</li> </ul> <p>Factory methods: Prefixed with <code>create_</code> for methods that generate new instances</p> <ul> <li>Examples: <code>create_mask()</code>, <code>create_subset()</code>, <code>create_transformer()</code></li> <li>When to use: When creating new objects based on specific parameters</li> </ul>"},{"location":"concepts/overview/#architecture","title":"Architecture","text":"<p>SiaPy follows a modular architecture organized around key components that work together to provide a comprehensive toolkit for spectral image analysis.</p>"},{"location":"concepts/overview/#core","title":"Core","text":"API Documentation <p><code>siapy.core</code></p> <p>The foundation of the library providing essential functionality:</p> <ul> <li>Logging: Centralized logging functionality</li> <li>Exception handling: Custom exceptions for consistent error handling</li> <li>Type definitions: Common types used throughout the library</li> <li>Configuration: System paths and global configuration settings</li> </ul>"},{"location":"concepts/overview/#entities","title":"Entities","text":"API Documentation <p><code>siapy.entities</code></p> <p>Fundamental data structures that represent spectral imaging data:</p> <ul> <li>Spectral image: An abstraction for various image formats</li> <li>Spectral image set: Collection of spectral images with batch operations</li> <li>Pixels: Representation of pixel coordinates and groups</li> <li>Shapes: Geometric shapes for images' regions selection and masking</li> <li>Signatures: Spectral signatures extracted from images</li> </ul>"},{"location":"concepts/overview/#datasets","title":"Datasets","text":"API Documentation <p><code>siapy.datasets</code></p> <p>Tools for managing and working with datasets:</p> <ul> <li>Tabular datasets: Handling tabular data with spectral information</li> </ul>"},{"location":"concepts/overview/#features","title":"Features","text":"API Documentation <p><code>siapy.features</code></p> <p>Functionality for working with spectral features:</p> <ul> <li>Features: Abstractions for feature extraction and selection</li> <li>Spectral indices: Calculation of various spectral indices</li> </ul>"},{"location":"concepts/overview/#transformations","title":"Transformations","text":"API Documentation <p><code>siapy.transformations</code></p> <p>Transformation capabilities:</p> <ul> <li>Co-registration: Aligning images from different sources</li> <li>Image processing: Functions for image manipulation</li> </ul>"},{"location":"concepts/overview/#optimizers","title":"Optimizers","text":"API Documentation <p><code>siapy.optimizers</code></p> <p>Optimization, hyperparameter tuning and evaluation:</p> <ul> <li>Optimization: Machine learning training and optimization of hyperparameters</li> <li>Evaluation metrics and scoring mechanisms: Tools for assessing model performance</li> </ul>"},{"location":"concepts/overview/#utils","title":"Utils","text":"API Documentation <p><code>siapy.utils</code></p> <p>Utility and plotting functions:</p> <ul> <li>Plotting: Visualization tools for spectral data</li> <li>Image utilities: Helper functions for image processing</li> <li>Signature utilities: Functions for working with spectral signatures</li> </ul>"},{"location":"concepts/transformations/","title":"Transformations","text":"API Documentation <p><code>siapy.transformations</code></p> <p>The transformations module provides essential image processing and co-registration capabilities. It includes functions for spatial image manipulation, data augmentation, and geometric transformations between different camera coordinate systems.</p>"},{"location":"concepts/transformations/#image-transformations","title":"Image transformations","text":"API Documentation <p><code>siapy.transformations.image</code></p>"},{"location":"concepts/transformations/#basic-transformations","title":"Basic transformations","text":"<pre><code>import numpy as np\n\nfrom siapy.entities import SpectralImage\nfrom siapy.transformations.image import (\n    random_crop,\n    random_mirror,\n    random_rotation,\n    rescale,\n)\n\n# Create a sample spectral image for demonstration\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((100, 100, 10))  # height, width, bands\nimage = SpectralImage.from_numpy(image_array)\n\n# Convert to numpy array for transformations\n# image = image.to_numpy() # Not needed, as transformations work directly with SpectralImage\n\n# Resize image to new dimensions\nresized_image = rescale(image, (150, 150))\nprint(f\"Original shape: {image.shape}\")\nprint(f\"Resized shape: {resized_image.shape}\")\n\n# Crop a random section of the image\ncropped_image = random_crop(image, (80, 80))\nprint(f\"Cropped shape: {cropped_image.shape}\")\n\n# Apply horizontal/vertical mirroring\nmirrored_image = random_mirror(image)\nprint(f\"Mirrored shape: {mirrored_image.shape}\")\n\n# Rotate image by specified angle (in degrees)\nrotated_image = random_rotation(image, angle=30)\nprint(f\"Rotated shape: {rotated_image.shape}\")\n</code></pre>"},{"location":"concepts/transformations/#data-augmentation","title":"Data augmentation","text":"<p>Data augmentation transformations are useful for expanding training datasets and testing algorithm robustness.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import SpectralImage\nfrom siapy.transformations.image import add_gaussian_noise\n\n# Create a sample spectral image\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((100, 100, 10))\nimage = SpectralImage.from_numpy(image_array)\n\n# Add Gaussian noise to the image\nnoisy_image = add_gaussian_noise(\n    image,\n    mean=0.0,  # Center the noise around zero\n    std=0.1,  # Standard deviation of the noise\n    clip_to_max=True,  # Prevent values from exceeding the original range\n)\n\nimage_np = image.to_numpy()\n\nprint(f\"Original image range: [{image_np.min():.3f}, {image_np.max():.3f}]\")\nprint(f\"Noisy image range: [{noisy_image.min():.3f}, {noisy_image.max():.3f}]\")\n\n# Compare signal-to-noise ratio\nsignal_power = np.mean(image_np**2)\nnoise_power = np.mean((noisy_image - image) ** 2)\nsnr_db = 10 * np.log10(signal_power / noise_power)\nprint(f\"Signal-to-Noise Ratio: {snr_db:.2f} dB\")\n</code></pre>"},{"location":"concepts/transformations/#normalization","title":"Normalization","text":"<p>The <code>area_normalization</code> function normalizes spectral signals by their area under the curve, which is particularly useful for comparing spectral shapes regardless of overall intensity.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import SpectralImage\nfrom siapy.transformations.image import area_normalization\n\n# Create a sample spectral image\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((100, 100, 10))\nimage = SpectralImage.from_numpy(image_array)\n\n# Apply area normalization to standardize spectral intensities\n# This normalizes each pixel's spectrum by its total area under the curve\nnormalized_image = area_normalization(image)\n\n# Compare before and after normalization (e.g., pixel at (25, 25))\noriginal_pixel = image.to_numpy()[25, 25, :]\nnormalized_pixel = normalized_image[25, 25, :]\n\nprint(f\"Original pixel spectrum area: {np.trapz(original_pixel):.4f}\")\nprint(f\"Normalized pixel spectrum area: {np.trapz(normalized_pixel):.4f}\")\nprint(f\"Original intensity range: [{original_pixel.min():.3f}, {original_pixel.max():.3f}]\")\nprint(f\"Normalized intensity range: [{normalized_pixel.min():.3f}, {normalized_pixel.max():.3f}]\")\n</code></pre>"},{"location":"concepts/transformations/#co-registration","title":"Co-registration","text":"API Documentation <p><code>siapy.transformations.corregistrator</code></p> <p>Co-registration enables alignment and coordinate transformation between different spectral images, particularly useful when working with multiple cameras or sensors viewing the same scene.</p>"},{"location":"concepts/transformations/#alignment-workflow","title":"Alignment workflow","text":"<p>The typical co-registration workflow involves selecting corresponding points in both images and computing a transformation matrix:</p> <pre><code>import numpy as np\n\nfrom siapy.entities import Pixels, SpectralImage\nfrom siapy.transformations import corregistrator\n\n# Create two sample spectral images representing different cameras/sensors\nrng = np.random.default_rng(seed=42)\n\n# VNIR camera image (visible to near-infrared)\nvnir_array = rng.random((100, 120, 50))  # Different dimensions to simulate real cameras\nvnir_image = SpectralImage.from_numpy(vnir_array)\n\n# SWIR camera image (short-wave infrared)\nswir_array = rng.random((90, 110, 30))\nswir_image = SpectralImage.from_numpy(swir_array)\n\n# In practice, you would interactively select corresponding points using:\n# from siapy.utils.plots import pixels_select_click\n# control_points_vnir = pixels_select_click(vnir_image)\n# control_points_swir = pixels_select_click(swir_image)\n\n# For demonstration, create synthetic corresponding points\n# These represent the same physical locations viewed by both cameras\ncontrol_points_vnir = Pixels.from_iterable([(20, 15), (80, 25), (50, 70), (90, 80), (30, 90)])\ncontrol_points_swir = Pixels.from_iterable([(18, 12), (75, 22), (45, 65), (85, 75), (28, 85)])\n\n# Compute transformation matrix that maps VNIR coordinates to SWIR coordinates\ntransformation_matrix, residual_errors = corregistrator.align(\n    control_points_swir,  # Target coordinates (SWIR camera space)\n    control_points_vnir,  # Source coordinates (VNIR camera space)\n    plot_progress=False,\n)\n\nprint(\"Transformation matrix:\")\nprint(transformation_matrix)\nprint(f\"Residual alignment errors: {residual_errors}\")\n</code></pre>"},{"location":"concepts/transformations/#applying-transformations","title":"Applying transformations","text":"<p>Once you have a transformation matrix, you can transform pixel coordinates between image spaces:</p> <pre><code>import numpy as np\n\nfrom siapy.entities import Pixels, SpectralImage\nfrom siapy.transformations import corregistrator\n\n# Assume we have the transformation matrix from the previous example\ntransformation_matrix = np.array(\n    [\n        [9.53012482e-01, 1.36821892e-03, -1.33929429e00],\n        [6.24099856e-04, 9.68410946e-01, -2.46471435e00],\n        [2.20958871e-17, -2.81409517e-18, 1.00000000e00],\n    ]\n)\n\n# Create a VNIR image for demonstration\nrng = np.random.default_rng(seed=42)\nvnir_array = rng.random((100, 120, 50))\nvnir_image = SpectralImage.from_numpy(vnir_array)\n\n# Define pixels of interest in the VNIR image\n# These could be selected regions or any features of interest\nvnir_pixels = Pixels.from_iterable([(25, 30), (45, 50), (65, 70), (80, 85)])\n\n# Transform these pixels to SWIR camera coordinate system\nswir_pixels = corregistrator.transform(vnir_pixels, transformation_matrix)\n\nprint(\"Original VNIR coordinates:\")\nprint(vnir_pixels.df)\nprint(\"\\nTransformed SWIR coordinates:\")\nprint(swir_pixels.df)\n\n\n# Applications of transformed coordinates:\n\n# 1. Extract spectral signatures from corresponding locations in both images\n#    vnir_signatures = vnir_image.get_signatures_from_pixels(vnir_pixels)\n#    swir_signatures = swir_image.get_signatures_from_pixels(swir_pixels)\n\n# 2. Perform cross-spectral analysis of identical physical regions\n#    This enables comparison of vegetation indices, material classification,\n#    or spectral feature analysis across different wavelength ranges\n\n# 3. Create composite analyses combining VNIR and SWIR data\n#    Combined data provides enhanced discrimination capabilities for:\n#    - Mineral identification (clay, carbonate, sulfate detection)\n#    - Vegetation health assessment (water content, chlorophyll)\n#    - Material classification with improved accuracy\n</code></pre>"},{"location":"concepts/utils_image/","title":"Image Utilities","text":"API Documentation <p><code>siapy.utils.images</code></p> <p>The image utilities module provides functions for saving, loading, and processing spectral images with support for both Spectral Python (SPy) and Rasterio backends.</p>"},{"location":"concepts/utils_image/#image-io-operations","title":"Image I/O Operations","text":""},{"location":"concepts/utils_image/#spectral-python-backend","title":"Spectral Python backend","text":"<p>The SPy backend saves images in ENVI format.</p> <pre><code>import numpy as np\n\nfrom siapy.utils.images import spy_create_image, spy_save_image\n\n# Create sample data\nrng = np.random.default_rng(42)\nimage = rng.random((100, 150, 50))  # height, width, bands\n\n# Save image in ENVI format\nspy_save_image(\n    image=image,\n    save_path=\"output/my_image.hdr\",\n    metadata={\"description\": \"Sample hyperspectral image\"},\n    overwrite=True,\n    dtype=np.float32,\n)\n\n# Create image and get SpectralImage object back\nspectral_img = spy_create_image(\n    image=image,\n    save_path=\"output/created_image.hdr\",\n    metadata={\n        \"lines\": image.shape[0],\n        \"samples\": image.shape[1],\n        \"bands\": image.shape[2],\n        \"wavelength\": [400 + i * 5 for i in range(image.shape[2])],\n    },\n)\n</code></pre>"},{"location":"concepts/utils_image/#rasterio-backend","title":"Rasterio backend","text":"<p>The Rasterio backend provides geospatial capabilities and supports various formats.</p> <pre><code>import numpy as np\n\nfrom siapy.utils.images import rasterio_create_image, rasterio_save_image\n\n# Create sample data\nrng = np.random.default_rng(42)\nimage = rng.random((100, 150, 5))\n\n# Save as GeoTIFF with Rasterio\nrasterio_save_image(\n    image=image,\n    save_path=\"output/rasterio_image.tif\",\n    metadata={\"description\": \"Hyperspectral data\", \"wavelength\": [400, 450, 500, 550, 600]},\n)\n\n# Create image and get SpectralImage object back\nspectral_img = rasterio_create_image(\n    image=image,\n    save_path=\"output/created_rasterio.tif\",\n    metadata={\"wavelength\": [400, 450, 500, 550, 600]},\n)\n</code></pre>"},{"location":"concepts/utils_image/#radiance-to-reflectance-conversion","title":"Radiance to Reflectance Conversion","text":"<p>Converting radiance measurements to reflectance using reference panels is essential for quantitative spectral analysis.</p> <pre><code>from siapy.entities import SpectralImage\nfrom siapy.entities.shapes import Shape\nfrom siapy.utils.images import (\n    calculate_correction_factor_from_panel,\n    convert_radiance_image_to_reflectance,\n    spy_save_image,\n)\n\n# Load radiance image\nradiance_img = SpectralImage.spy_open(header_path=\"radiance_data.hdr\")\n\n# Method 1: Using labeled geometric shape for panel area\npanel_shape = Shape.from_rectangle(x_min=200, y_min=350, x_max=300, y_max=400, label=\"reference_panel\")\nradiance_img.geometric_shapes.append(panel_shape)\n\ncorrection_factor = calculate_correction_factor_from_panel(\n    image=radiance_img,\n    panel_reference_reflectance=0.2,  # 20% reflectance panel\n    panel_shape_label=\"reference_panel\",\n)\n\n# Method 2: Using entire image (when image contains only panel)\n# panel_img = SpectralImage.spy_open(header_path=\"panel_only.hdr\")\n# correction_factor = calculate_correction_factor_from_panel(\n#     image=panel_img,\n#     panel_reference_reflectance=0.2\n# )\n\n# Convert radiance to reflectance\nreflectance_img = convert_radiance_image_to_reflectance(image=radiance_img, panel_correction=correction_factor)\n\n# Save reflectance image with enhanced metadata\nmetadata = radiance_img.metadata.copy()\nmetadata.update({\"data_type\": \"reflectance\", \"reference_panel\": \"20% Spectralon\", \"processing_date\": \"2025-06-19\"})\nspy_save_image(image=reflectance_img, save_path=\"output/reflectance.hdr\", metadata=metadata)\n</code></pre>"},{"location":"concepts/utils_image/#additional-utility-functions","title":"Additional Utility Functions","text":"<pre><code>from siapy.entities import SpectralImage\nfrom siapy.utils.images import blockfy_image, calculate_image_background_percentage, spy_merge_images_by_specter\n\n# Merge VNIR and SWIR images\nvnir_image = SpectralImage.spy_open(header_path=\"vnir_data.hdr\")\nswir_image = SpectralImage.spy_open(header_path=\"swir_data.hdr\")\n\nmerged_image = spy_merge_images_by_specter(\n    image_original=vnir_image,\n    image_to_merge=swir_image,\n    save_path=\"output/merged_vnir_swir.hdr\",\n    auto_metadata_extraction=True,\n)\n\n# Image blocking for large dataset processing\nlarge_image = SpectralImage.spy_open(header_path=\"large_image.hdr\")\n\nblocks = blockfy_image(\n    image=large_image,\n    p=50,  # block height\n    q=50,  # block width\n)\n\n# Background analysis\nbg_percentage = calculate_image_background_percentage(large_image)\nprint(f\"Background pixels: {bg_percentage:.2f}%\")\n</code></pre>"},{"location":"concepts/utils_plotting/","title":"Plotting Utilities","text":"API Documentation <p><code>siapy.utils.plots</code></p> <p>The plotting utilities module provides interactive tools for pixel and area selection, as well as visualization functions for spectral images and signals.</p>"},{"location":"concepts/utils_plotting/#interactive-pixel-selection","title":"Interactive Pixel Selection","text":""},{"location":"concepts/utils_plotting/#point-based-selection","title":"Point-based Selection","text":"<p>Select individual pixels from an image by clicking on them.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import SpectralImage\nfrom siapy.utils.plots import pixels_select_click\n\n# Create a mock spectral image with 4 bands\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((50, 50, 4))  # height, width, bands\nimage = SpectralImage.from_numpy(image_array)\n\n# Interactive pixel selection\n# Click on pixels in the displayed image, then press Enter to finish\nselected_pixels = pixels_select_click(image)\n\nprint(f\"Selected {len(selected_pixels)} pixels:\")\nprint(selected_pixels.df)\n</code></pre>"},{"location":"concepts/utils_plotting/#area-based-selection","title":"Area-based Selection","text":"<p>Select irregular areas from an image using lasso selection tool.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import SpectralImage\nfrom siapy.utils.plots import pixels_select_lasso\n\n# Create a mock spectral image\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((50, 50, 4))\nimage = SpectralImage.from_numpy(image_array)\n\n# Interactive area selection with custom selector properties\nselector_props = {\"color\": \"blue\", \"linewidth\": 3, \"linestyle\": \"--\"}\n\n# Draw lasso shapes around areas of interest, then press Enter to finish\nselected_areas = pixels_select_lasso(image, selector_props=selector_props)\n\nprint(f\"Selected {len(selected_areas)} areas:\")\nfor i, area in enumerate(selected_areas):\n    print(f\"Area {i}: {len(area)} pixels\")\n    print(f\"  Sample coordinates: {area.df.head()}\")\n\n# Each area is a separate Pixels object containing all coordinates within the lasso\ntotal_pixels = sum(len(area) for area in selected_areas)\nprint(f\"Total pixels selected across all areas: {total_pixels}\")\n</code></pre>"},{"location":"concepts/utils_plotting/#image-visualization","title":"Image Visualization","text":""},{"location":"concepts/utils_plotting/#display-images-with-selected-areas","title":"Display Images with Selected Areas","text":"<p>Visualize spectral images with overlaid selected pixels or areas.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import Pixels, SpectralImage\nfrom siapy.utils.plots import display_image_with_areas\n\n# Create a mock spectral image\nrng = np.random.default_rng(seed=42)\nimage_array = rng.random((50, 50, 4))\nimage = SpectralImage.from_numpy(image_array)\n\n# Create predefined areas manually\narea1 = Pixels.from_iterable([(10, 15), (12, 18), (15, 20)])\narea2 = Pixels.from_iterable([(i, j) for i in range(20, 25) for j in range(30, 35)])\npredefined_areas = [area1, area2]\n\n# Display image with predefined areas\ndisplay_image_with_areas(image, predefined_areas, color=\"white\")\n</code></pre>"},{"location":"concepts/utils_plotting/#multiple-image-comparison","title":"Multiple Image Comparison","text":"<p>Display multiple images side by side with their corresponding selected areas.</p> <pre><code>import numpy as np\n\nfrom siapy.entities import Pixels, SpectralImage\nfrom siapy.utils.plots import InteractiveButtonsEnum, display_multiple_images_with_areas\n\n# Create two mock spectral images (e.g., simulating VNIR and SWIR)\nrng = np.random.default_rng(seed=42)\n\n# VNIR-like image (4 bands)\nvnir_array = rng.random((50, 50, 4))\nvnir_image = SpectralImage.from_numpy(vnir_array)\n\n# SWIR-like image (6 bands)\nswir_array = rng.random((50, 50, 6))\nswir_image = SpectralImage.from_numpy(swir_array)\n\n# Define corresponding areas for both images\nvnir_areas = [\n    Pixels.from_iterable([(10, 15), (12, 18), (15, 20)]),\n    Pixels.from_iterable([(25, 30), (28, 32), (30, 35)]),\n]\n\nswir_areas = [\n    Pixels.from_iterable([(9, 14), (11, 17), (14, 19)]),  # Slightly offset coordinates\n    Pixels.from_iterable([(24, 29), (27, 31), (29, 34)]),\n]\n\n# Display multiple images with interactive buttons\nresult = display_multiple_images_with_areas(\n    images_with_areas=[\n        (vnir_image, vnir_areas),\n        (swir_image, swir_areas),\n    ],\n    color=\"white\",\n    plot_interactive_buttons=True,\n)\n\n# Handle user interaction result\nif result == InteractiveButtonsEnum.SAVE:\n    print(\"User chose to save the selection\")\nelif result == InteractiveButtonsEnum.REPEAT:\n    print(\"User chose to repeat the process\")\nelif result == InteractiveButtonsEnum.SKIP:\n    print(\"User chose to skip this step\")\n</code></pre>"},{"location":"concepts/utils_plotting/#signal-visualization","title":"Signal Visualization","text":"<p>Plot mean spectral signatures with standard deviation bands for different classes.</p> <pre><code>import numpy as np\n\nfrom siapy.datasets.schemas import TabularDatasetData\nfrom siapy.utils.plots import display_signals\n\n# Create sample spectral signatures dataset\nrng = np.random.default_rng(seed=42)\n\n# Generate synthetic spectral data (simulate 4 bands: R, G, B, NIR)\nn_samples = 50\nn_bands = 4\nspectral_data = rng.normal(0.5, 0.2, (n_samples, n_bands))\nspectral_data = np.clip(spectral_data, 0, 1)  # Ensure valid reflectance values\n\n# Create two classes with different spectral characteristics\nclass_a_indices = np.arange(0, 25)\nclass_b_indices = np.arange(25, 50)\n\n# Modify spectral characteristics for each class\nspectral_data[class_a_indices, 3] += 0.3  # Higher NIR for vegetation-like class\nspectral_data[class_b_indices, 0] += 0.2  # Higher red for soil-like class\n\n# Create dataset structure\ndata_dict = {\n    \"pixels\": {\n        \"x\": list(range(n_samples)),\n        \"y\": [0] * n_samples,  # All from same row for simplicity\n    },\n    \"signals\": {f\"band_{i}\": spectral_data[:, i].tolist() for i in range(n_bands)},\n    \"metadata\": {\n        \"sample_id\": [f\"sample_{i}\" for i in range(n_samples)],\n    },\n    \"target\": {\n        \"label\": [\"vegetation\"] * 25 + [\"soil\"] * 25,\n        \"value\": [0] * 25 + [1] * 25,\n        \"encoding\": {\"vegetation\": 0, \"soil\": 1},\n    },\n}\n\n# Create TabularDatasetData object\ndataset = TabularDatasetData.from_dict(data_dict)\n\n# Basic signal plotting\nprint(\"Displaying basic spectral signals...\")\ndisplay_signals(dataset)\n\n# Customized signal plotting\nprint(\"Displaying customized spectral signals...\")\ndisplay_signals(\n    dataset,\n    figsize=(10, 6),\n    dpi=100,\n    colormap=\"plasma\",\n    x_label=\"Spectral Bands (R, G, B, NIR)\",\n    y_label=\"Reflectance\",\n    label_fontsize=16,\n    tick_params_label_size=14,\n    legend_fontsize=12,\n    legend_frameon=True,\n)\n\n# Additional example with more classes\nprint(\"Creating dataset with multiple classes...\")\n\n# Extend dataset to include a third class\nextended_data = data_dict.copy()\nextended_data[\"pixels\"][\"x\"].extend(list(range(50, 75)))\nextended_data[\"pixels\"][\"y\"].extend([0] * 25)\n\n# Add water-like spectral characteristics (low NIR, moderate blue)\nwater_spectra = rng.normal(0.3, 0.1, (25, n_bands))\nwater_spectra[:, 1] += 0.2  # Higher blue\nwater_spectra[:, 3] -= 0.2  # Lower NIR\nwater_spectra = np.clip(water_spectra, 0, 1)\n\nfor i in range(n_bands):\n    extended_data[\"signals\"][f\"band_{i}\"].extend(water_spectra[:, i].tolist())\n\nextended_data[\"metadata\"][\"sample_id\"].extend([f\"sample_{i}\" for i in range(50, 75)])\nextended_data[\"target\"][\"label\"].extend([\"water\"] * 25)\nextended_data[\"target\"][\"value\"].extend([2] * 25)\nextended_data[\"target\"][\"encoding\"][\"water\"] = 2\n\nextended_dataset = TabularDatasetData.from_dict(extended_data)\n\nprint(\"Displaying multi-class spectral signals...\")\ndisplay_signals(\n    extended_dataset,\n    figsize=(12, 8),\n    colormap=\"viridis\",\n    x_label=\"Spectral Bands\",\n    y_label=\"Reflectance Values\",\n)\n</code></pre>"},{"location":"examples/case_study/","title":"Case Study","text":"<p>This section offers an overview of a case study based on real-world data.</p> <p>Note</p> <p>\ud83d\udca1 All code snippets used in this case study are available in the GitHub repository.</p> <p>To follow along:</p> <ol> <li>Download sample data: Access the hyperspectral image dataset from Zenodo</li> <li>Install SiaPy: Follow our installation instructions</li> </ol>"},{"location":"examples/case_study/#data-overview","title":"\ud83d\udccb Data Overview","text":"<p>The hyperspectral dataset used in this case study was acquired using Hyspex push-broom cameras from Norsk Elektro Optikk (Oslo, Norway), covering two spectral regions:</p> Camera Spectral Range Bands Bandwidth VNIR-1600 Visible to near-infrared (400\u2013988 nm) 160 3.6 nm SWIR-384 Short-wave infrared (950\u20132500 nm) 288 5.4 nm <p>Note</p> <p>All hyperspectral data is provided as calibrated reflectance values, ensuring accuracy and reliability for your analysis.</p>"},{"location":"examples/case_study/#file-naming-convention","title":"\ud83d\udcc1 File Naming Convention","text":"<p>Understanding the file naming convention is crucial for working with the dataset:</p> <pre><code>L1_L2_L3__test__ID_CAM.img   -&gt;  Image file\nL1_L2_L3__test__ID_CAM.hdr   -&gt;  Header file corresponding to the image file\n</code></pre> <p>The file names encode important metadata:</p> Component Description Example V-T-N (Labels; L) Plant identification <code>KK-K-04</code> V (Variety) Plant variety <code>KK</code>: KIS Krka, <code>KS</code>: KIS Savinja T (Treatment) Experimental treatment <code>K</code>: Control, <code>S</code>: Drought N (Index) Plant identifier <code>04</code>: Plant #4 ID Random acquisition ID <code>18T102331</code> CAM Camera type <code>corr</code>: VNIR, <code>corr2</code>: SWIR"},{"location":"examples/case_study/#validation-setup","title":"\ud83d\ude80 Validation Setup","text":"<p>Before diving into the examples, verify that your SiaPy installation and data are correctly configured:</p> <pre><code>try:\n    from pathlib import Path\n\n    from siapy.entities import SpectralImageSet\n\n    print(\"Libraries detected successfully.\")\nexcept ImportError as e:\n    print(f\"Error: {e}. Please ensure that the SiaPy library is installed and the environment is activated.\")\n    exit(1)\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Find all header and image files in the data directory\nheader_paths = sorted(Path(data_dir).rglob(\"*.hdr\"))\nimage_paths = sorted(Path(data_dir).rglob(\"*.img\"))\n\n# Create a SpectralImageSet from the found paths\nimage_set = SpectralImageSet.spy_open(\n    header_paths=header_paths,\n    image_paths=image_paths,\n)\n\n# Check if the data was loaded correctly\nif len(image_set) &gt; 0:\n    print(\"Loading succeeded.\")\nelse:\n    print(\"Loading did not succeed.\")\n</code></pre> <p>Warning</p> <p>If you encounter issues:</p> <ul> <li>Check that SiaPy is properly installed and your environment is activated</li> <li>Verify that you've downloaded the example data</li> <li>Ensure the <code>data_dir</code> variable points to the correct location of your dataset</li> <li>Make sure both <code>.img</code> and <code>.hdr</code> files are present in your data directory</li> </ul>"},{"location":"examples/case_study/#source-code-examples","title":"\ud83e\uddea Source Code Examples","text":""},{"location":"examples/case_study/#working-with-spectralimage-objects","title":"Working with SpectralImage Objects","text":"<p>Example:</p> <pre><code>from pathlib import Path\n\nimport spectral as sp\n\nfrom siapy.entities import SpectralImage\nfrom siapy.entities.images import SpectralLibImage\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Find all header and image files in the data directory\nheader_paths = sorted(Path(data_dir).rglob(\"*.hdr\"))\nimage_paths = sorted(Path(data_dir).rglob(\"*.img\"))\n\nheader_path_img0 = header_paths[0]\nimage_path_img0 = image_paths[0]\n\n# Load the image using spectral library and then wrap over SpectralImage object\nsp_file = sp.envi.open(file=header_path_img0, image=image_path_img0)\nassert not isinstance(sp_file, sp.io.envi.SpectralLibrary)\nimage = SpectralImage(SpectralLibImage(sp_file))\n\n# or you can do the same just by running\nimage = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\n\n# Now you can easily use various property and util functions of the SpectralImage object\n# Get the shape of the image\nprint(\"Image shape:\", image.shape)\n\n# Get the number of bands\nprint(\"Number of bands:\", image.bands)\n\n# Get the wavelength information\nprint(\"Wavelengths:\", image.wavelengths)\n\n# Get the file path\nprint(\"File path:\", image.filepath)\n\n# Get the metadata\nprint(\"Metadata:\", image.metadata)\n\n# Get the number of rows\nprint(\"Number of rows:\", image.image.rows)\n\n# Get the number of columns\nprint(\"Number of columns:\", image.image.cols)\n\n# Get the default bands\nprint(\"Default bands:\", image.default_bands)\n\n# Get the description\nprint(\"Description:\", image.image.description)\n\n# Get the camera ID\nprint(\"Camera ID:\", image.camera_id)\n\n# Get the geometric shapes\nprint(\"Geometric shapes:\", image.geometric_shapes)\n</code></pre> <p>Source: <code>spectral_image_01.py</code></p> <p>Key Concepts:</p> <ul> <li>Multiple Loading Methods: The script demonstrates two ways to load a hyperspectral image:</li> <li>Using the SpectralPython library directly and wrapping with SiaPy</li> <li>Using SiaPy's simplified <code>spy_open()</code> method</li> <li>Property Access: Shows how to access fundamental image properties through the SpectralImage interface:</li> <li>Shape, dimensions (rows, columns), and spectral bands</li> <li>Wavelength information for each band</li> <li>File metadata and path information</li> <li>Camera identification and associated geometric data</li> </ul> Implementation Details <p>This script uses decorators for read-only access to image attributes, following the library's design pattern for consistent data access.</p> <p>Example:</p> <pre><code>from pathlib import Path\n\nimport matplotlib.pyplot as plt\n\nfrom siapy.entities import Pixels, SpectralImage\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Get first image\nheader_path_img0 = sorted(Path(data_dir).rglob(\"*.hdr\"))[1]\nimage_path_img0 = sorted(Path(data_dir).rglob(\"*.img\"))[1]\n\n# Load spectral image\nimage = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\n\n# Convert to numpy\nimage_np = image.to_numpy(nan_value=0.0)\nprint(\"Image shape:\", image_np.shape)\n\n# Calculate mean\nmean_val = image.average_intensity(axis=(0, 1))\nprint(\"Mean value per band:\", mean_val)\n\n# Create a Pixels object from an iterable with pixels coordinates\n# The iterable should be a list of tuples representing (x, y) coordinates\n# iterable == [(x1, y1), (x2, y2), ...] -&gt; list of pixels\niterable = [(1, 2), (3, 4), (5, 6)]\npixels = Pixels.from_iterable(iterable)\n\n# Convert the pixel coordinates to spectral signatures\nsignatures = image.to_signatures(pixels)\nprint(\"Signatures:\", signatures)\n\n# Extract a subarray from the image using the pixel coordinates\nsubarray = image.to_subarray(pixels)\nprint(\"Subarray shape:\", subarray.shape)\n\n# Convert to displayable image\ndisplay_image = image.to_display(equalize=True)\n\n# Display the image using matplotlib\nplt.figure()\nplt.imshow(display_image)\nplt.axis(\"off\")  # Hide axes for better visualization\nplt.show()\n</code></pre> <p>Source: <code>spectral_image_02.py</code></p> <p>Key Concepts:</p> <ul> <li>Array Conversion: Converting a SpectralImage to NumPy arrays for numerical processing</li> <li>Statistical Analysis: Computing band-wise statistics like mean intensity values</li> <li>Pixel Handling: Creating and manipulating Pixels objects from coordinate data</li> <li>Data Extraction: Methods for extracting spectral signatures and subarrays from specific image regions</li> <li>Visualization: Converting hyperspectral data to displayable RGB images with optional histogram equalization</li> </ul> Implementation Details <p>Notice how methods follow SiaPy's naming convention: converters use <code>to_</code> prefix (e.g., <code>to_numpy()</code>, <code>to_signatures()</code>, <code>to_display()</code>), while calculation methods use descriptive verbs.</p>"},{"location":"examples/case_study/#managing-image-collections","title":"Managing Image Collections","text":"<p>Example:</p> <pre><code>from pathlib import Path\n\nfrom siapy.entities import SpectralImageSet\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Find all header and image files in the data directory\nheader_paths = sorted(Path(data_dir).rglob(\"*.hdr\"))\nimage_paths = sorted(Path(data_dir).rglob(\"*.img\"))\n\n# Create a SpectralImageSet from the found paths\nimageset = SpectralImageSet.spy_open(\n    header_paths=header_paths,\n    image_paths=image_paths,\n)\n\n# Now you can easily use various properties and utility functions of the SpectralImageSet object.\n# First, let's sort the images:\nprint(\"Unsorted: \", imageset.images)\nimageset.sort()\nprint(\"Sorted: \", imageset.images)\n\n# Get the number of images in the set\nprint(\"Number of images in the set:\", len(imageset))\n\n# Get the cameras ID\nprint(\"Cameras ID:\", imageset.cameras_id)\n\n# Iterate over images and print their shapes\nfor idx, image in enumerate(imageset):\n    print(f\"Image {idx} shape:\", image.shape)\n\n# Get images by camera ID\ncamera_id = imageset.cameras_id[0]\nimages_by_camera = imageset.images_by_camera_id(camera_id)\nprint(f\"Number of images by camera {camera_id}:\", len(images_by_camera))\n</code></pre> <p>Source: <code>spectral_imageset_01.py</code></p> <p>Key Concepts:</p> <ul> <li>Batch Loading: Loading multiple spectral images into a unified SpectralImageSet container</li> <li>Collection Management: Organizing and sorting images within the set</li> <li>Metadata Access: Efficient access to collection properties (size, camera IDs)</li> <li>Iteration Patterns: Iterating through the image collection with standard Python iteration</li> <li>Filtering and Selection: Selecting images by specific criteria (e.g., camera ID)</li> </ul> Implementation Details <p><code>SpectralImageSet</code> implements standard Python container interfaces, making it behave like a familiar collection type with additional hyperspectral-specific functionality.</p>"},{"location":"examples/case_study/#interactive-pixel-and-area-selection","title":"Interactive Pixel and Area Selection","text":"<p>Example:</p> <pre><code>from pathlib import Path\n\nfrom siapy.entities import SpectralImage\nfrom siapy.utils.plots import pixels_select_click\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Get arbitrary image\nheader_path_img0 = sorted(Path(data_dir).rglob(\"*.hdr\"))[1]\nimage_path_img0 = sorted(Path(data_dir).rglob(\"*.img\"))[1]\n\n# Load spectral image\nimage = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\n\n# Select pixels from the image\npixels = pixels_select_click(image)\n# ? Press enter to finish the selection\nprint(\"Pixels:\", pixels.df)\n</code></pre> <p>Source: <code>visualization_01.py</code></p> <p>The selected pixels are highlighted in the image below.</p> <p></p> <p>Key Concepts:</p> <ul> <li>Interactive Selection: Using SiaPy's interactive tools to select specific pixels from displayed images</li> <li>Point-Based Analysis: Selecting individual points for detailed spectral analysis</li> <li>User Interaction: Simple keyboard-based interaction model (press Enter to finish selection)</li> <li>Results Access: Accessing the resulting Pixels object and its DataFrame representation</li> </ul> Implementation Details <p>The <code>pixels_select_click</code> function handles the display, interaction, and collection of pixel coordinates in a single operation, simplifying user interaction code.</p> <p>Example:</p> <pre><code>from pathlib import Path\n\nfrom siapy.entities import SpectralImage\nfrom siapy.utils.plots import pixels_select_lasso\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Get arbitrary image\nheader_path_img0 = sorted(Path(data_dir).rglob(\"*.hdr\"))[1]\nimage_path_img0 = sorted(Path(data_dir).rglob(\"*.img\"))[1]\n\n# Load spectral image\nimage = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\n\n# Select areas from the image\nareas = pixels_select_lasso(image)\n# ? Press enter to finish the selection\n\n# Print the selected areas\nfor i, area in enumerate(areas):\n    print(f\"Area {i}:\", area)\n</code></pre> <p>Source: <code>visualization_02.py</code></p> <p>The selected areas are highlighted in the image below.</p> <p></p> <p>Key Concepts:</p> <ul> <li>Region Selection: Using SiaPy's lasso tool to define irregular regions of interest</li> <li>Multiple Areas: Creating and managing multiple selected areas within a single image</li> <li>Polygon-Based Selection: Defining complex shapes for region-based analysis</li> <li>Selection Management: Organized representation of selected areas for further processing</li> </ul> Implementation Details <p>Selected areas are returned as a list of <code>Pixels</code> objects, each representing a distinct region that can be separately analyzed or processed.</p>"},{"location":"examples/case_study/#image-transformation-and-processing","title":"Image Transformation and Processing","text":"<p>Example:</p> <pre><code>from pathlib import Path\n\nfrom siapy.entities import SpectralImage\nfrom siapy.transformations import corregistrator\nfrom siapy.utils.plots import pixels_select_click\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Get first image\nheader_path_img0 = sorted(Path(data_dir).rglob(\"coregister*corr2_rad_f32.hdr\"))[0]\nimage_path_img0 = sorted(Path(data_dir).rglob(\"coregister*corr2_rad_f32.img\"))[0]\nheader_path_img1 = sorted(Path(data_dir).rglob(\"coregister*corr_rad_f32.hdr\"))[0]\nimage_path_img1 = sorted(Path(data_dir).rglob(\"coregister*corr_rad_f32.img\"))[0]\n\n# Load VNIR and SWIR spectral images\nimage_swir = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\nimage_vnir = SpectralImage.spy_open(\n    header_path=header_path_img1,\n    image_path=image_path_img1,\n)\n\n# Select the same pixels in both images.\n# The more points you select, the better the transformation between image spaces will be.\n# Click enter to finish the selection.\npixels_vnir = pixels_select_click(image_vnir)\npixels_swir = pixels_select_click(image_swir)\n\n# Perform the transformation and transform the selected pixels from the VNIR image to the space of the SWIR image.\nmatx, _ = corregistrator.align(pixels_swir, pixels_vnir, plot_progress=False)\nprint(\"Transformation matrix:\", matx)\n</code></pre> <p>Source: <code>transformations_01.py</code></p> <p>Key Concepts:</p> <ul> <li>Control Point Selection: Interactive selection of corresponding points in VNIR and SWIR images</li> <li>Coordinate Mapping: Establishing relationships between points in different spectral spaces</li> <li>Transformation Calculation: Computing the mathematical transformation between coordinate systems</li> <li>Spatial Alignment: Creating a foundation for aligning multi-sensor hyperspectral data</li> </ul> Implementation Details <p>The <code>corregistrator.align()</code> function computes a transformation matrix that can transform coordinates from one image space to another, essential for multi-sensor data fusion.</p> <p>Example:</p> <pre><code>from pathlib import Path\n\nimport numpy as np\n\nfrom siapy.entities import SpectralImage\nfrom siapy.transformations import corregistrator\nfrom siapy.utils.plots import display_multiple_images_with_areas, pixels_select_lasso\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Get first image\nheader_path_img0 = sorted(Path(data_dir).rglob(\"*.hdr\"))[0]\nimage_path_img0 = sorted(Path(data_dir).rglob(\"*.img\"))[0]\nheader_path_img1 = sorted(Path(data_dir).rglob(\"*.hdr\"))[1]\nimage_path_img1 = sorted(Path(data_dir).rglob(\"*.img\"))[1]\n\n# Load VNIR and SWIR spectral images\nimage_swir = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\nimage_vnir = SpectralImage.spy_open(\n    header_path=header_path_img1,\n    image_path=image_path_img1,\n)\n\n# Transformation matrix was calculated in previous example\nmatx = np.array(\n    [\n        [5.10939099e-01, -3.05286868e-03, -1.48283389e00],\n        [-2.15777211e-03, 5.17836773e-01, -2.50694723e01],\n        [3.02412467e-18, 7.36518494e-18, 1.00000000e00],\n    ]\n)\n\n# Select area of the image\n# Click enter to finish the selection.\nselected_areas_vnir = pixels_select_lasso(image_vnir)\n\n# Transform the selected areas from the VNIR image to the space of the SWIR image.\nselected_areas_swir = [corregistrator.transform(pixels_vnir, matx) for pixels_vnir in selected_areas_vnir]\n\n# Display the selected areas in both images\ndisplay_multiple_images_with_areas(\n    [\n        (image_vnir, selected_areas_vnir),\n        (image_swir, selected_areas_swir),\n    ],\n    plot_interactive_buttons=False,\n)\n</code></pre> <p>Source: <code>transformations_02.py</code></p> <p>Key Concepts:</p> <ul> <li>Area Selection: Using the lasso tool to select regions in one spectral range</li> <li>Coordinate Transformation: Applying the transformation matrix to map selected areas between images</li> <li>Cross-Spectral Analysis: Enabling analysis of the same physical regions across different spectral data</li> <li>Visual Verification: Displaying both images with highlighted areas to verify correct transformation</li> </ul> Implementation Details <p>The transformation is applied to the <code>Pixels</code> objects directly, allowing selected regions to be mapped between different spectral ranges while preserving their shape relationships.</p> <p>Example:</p> <pre><code>from pathlib import Path\n\nfrom siapy.entities import SpectralImage\nfrom siapy.transformations.image import (\n    add_gaussian_noise,\n    area_normalization,\n    random_crop,\n    random_mirror,\n    random_rotation,\n    rescale,\n)\n\n# Set the path to the directory containing the data\n# !! ADJUST THIS PATH TO YOUR DATA DIRECTORY !!\ndata_dir = \"./docs/examples/data\"\n\n# Get first image\nheader_path_img0 = sorted(Path(data_dir).rglob(\"*.hdr\"))[0]\nimage_path_img0 = sorted(Path(data_dir).rglob(\"*.img\"))[0]\n\n# Load VNIR and SWIR spectral images\nimage_swir = SpectralImage.spy_open(\n    header_path=header_path_img0,\n    image_path=image_path_img0,\n)\n\n# Convert image to numpy array\nimage_swir_np = image_swir.to_numpy()\n\n# Apply transformations to image_swir\n# Add Gaussian noise\nnoisy_image = add_gaussian_noise(image_swir_np, mean=0.0, std=1.0, clip_to_max=True)\n\n# Random crop\ncropped_image = random_crop(image_swir_np, output_size=(100, 100))\n\n# Random mirror\nmirrored_image = random_mirror(image_swir_np)\n\n# Random rotation\nrotated_image = random_rotation(image_swir_np, angle=45)\n\n# Rescale\nrescaled_image = rescale(image_swir_np, output_size=(200, 200))\n\n# Area normalization\nnormalized_image = area_normalization(image_swir_np)\n</code></pre> <p>Source: <code>transformations_03.py</code></p> <p>Key Concepts:</p> <ul> <li>Noise Injection: Adding controlled Gaussian noise for robustness testing or data augmentation</li> <li>Spatial Transformations: Applying geometric operations including</li> <li>Normalization: Area-based normalization for standardizing image intensity distributions</li> <li>Data Augmentation: Creating modified versions of images for machine learning training</li> </ul> Implementation Details <p>All transformation functions follow a consistent input/output pattern, taking NumPy arrays as input and returning the transformed arrays, making them easily composable for complex processing pipelines.</p> <p>This case study was created with SiaPy latest version. If you encounter any issues, please check for updates or report them on GitHub.</p>"},{"location":"examples/external_sources/","title":"External repositories","text":""},{"location":"examples/external_sources/#siapy-command-line-tool-cli","title":"\ud83d\ude80 SiaPy command line tool (CLI)","text":"<p>To facilitate the use of some of the SiaPy library's functionality, a command line interface (CLI) has been implemented.</p> <p>The CLI currently supports the following commands:</p> <ul> <li>Display images from two cameras.</li> <li>Co-register cameras and compute the transformation from one camera's space to another.</li> <li>Select regions in images for training machine learning (ML) models.</li> <li>Perform image segmentation using a pre-trained ML model.</li> <li>Convert radiance images to reflectance by utilizing a reference panel.</li> <li>Display spectral signatures for in-depth analysis.</li> </ul> <p>Info</p> <p>\ud83d\udcbb Code Repository</p>"},{"location":"examples/external_sources/#hyperspectral-data-utilization-in-research","title":"\ud83d\ude80 Hyperspectral data utilization in research","text":"<p>This use case demonstrates how to utilize extracted data from hyperspectral images in research. The project integrates a machine learning (ML) pipeline workflow with the SiaPy library to classify spectral signatures.</p> <p>Key features:</p> <ul> <li>Provides a structured approach to train and test models.</li> <li>Features an integrated modular architecture for easy modification of models and data.</li> <li>Includes an optimization process with hyperparameter tuning.</li> <li>Utilizes Explainable AI techniques to understand the model, the data on which the model is trained, and the most relevant spectral bands (important features) for the model.</li> <li>Covers the entire process with visualization of results.</li> </ul> <p>Info</p> <p>\ud83d\udcbb Code Repository</p>"}]}